{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Analysis Length Of Patterns Retained \n",
    "In this notebook we will evaluate the results form the experiments executed. For each experiment, one parameter is changed and all others were kept constant as to determine the effect of one variable. \n",
    "\n",
    "**The goals of this analysis are:**\n",
    "1. Determine the relationship of the number of parameters in the neural network and length of the patterns that can be retained \n",
    "2. Investigate which activation function lead to the retention of longest patterns\n",
    "3. Determine what effect bidirectional RNNs has on this relationship\n",
    "4. Determine the effect of increasing the number of layers has on pattern length retention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine whether a relationshop exists between the variable being investigated and the number of required parameters in each respective neural network, the Pearson correlation coefficient is used. The domain of this metric lies between -1 and +1 or in mathematical notation $P \\in [-1, 1]$. If there exists a strong positive relationship between variables, the Pearson coefficient will approach +1 and for the negative case -1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T06:25:32.024270Z",
     "start_time": "2018-11-16T06:25:25.576937Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from sqlalchemy import Column, Integer, String\n",
    "from sqlalchemy import create_engine, Column\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Length of Patterns Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "779 /home/danielp/Documents/Masters/Code/memory_capacity_retention_rnns/danny_masters/100_0_False_longest_sequence.log\r\n"
     ]
    }
   ],
   "source": [
    "! wc -l /home/danielp/Documents/Masters/Code/memory_capacity_retention_rnns/danny_masters/100_0_False_longest_sequence.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(\"INFO:root:bidirgru;linear;4536;[216];3;4;282961;1;{'val_loss': [0.28120091557502747, 0.1132935956120491], 'loss': [0.41719042882323265, 0.19011458661407232], 'lr': [0.001, 0.001]};1.0\".count(\";\"))\n",
    "print(\"INFO:root:lstm;softmax;504;[420, 42];0;5;786787;699;{'val_loss': [0.3983786255121231, 0.38453641533851624, 0.37102413177490234, 0.35796700417995453, 0.3453146666288376, 0.3330612927675247, 0.32121409475803375, 0.3097362518310547, 0.2987896651029587, 0.2881261706352234, 0.2778322100639343, 0.26803746819496155, 0.25844745337963104, 0.2492733672261238, 0.24045316129922867, 0.2320057973265648, 0.22390616685152054, 0.21603740751743317, 0.20860742777585983, 0.20134034752845764, 0.19443238526582718, 0.18777956068515778, 0.18148573487997055, 0.17552954703569412, 0.16970320791006088, 0.16423241794109344, 0.15901590138673782, 0.15400884300470352, 0.14939148724079132, 0.14484168589115143, 0.14052481949329376, 0.1363724321126938, 0.13253740966320038, 0.12893234938383102, 0.12547318637371063, 0.12218526750802994, 0.11913982406258583, 0.11624228209257126, 0.1134972907602787, 0.11090944707393646, 0.10857299715280533, 0.10638427734375, 0.10427320003509521, 0.10227495804429054, 0.10043990612030029, 0.09870023652911186, 0.09711764380335808, 0.09561265632510185, 0.09424823522567749, 0.09297456219792366, 0.09179184213280678, 0.09071826562285423, 0.08970387652516365, 0.08881306275725365, 0.08799967914819717, 0.08725852891802788, 0.08655820786952972, 0.08593429252505302, 0.08534976840019226, 0.08481515944004059, 0.08431608602404594, 0.08388398215174675, 0.08351462334394455, 0.08317387104034424, 0.0828644409775734, 0.08258114755153656, 0.08232851326465607, 0.08212883770465851, 0.08193894848227501, 0.08175777271389961, 0.08162573724985123, 0.08149046450853348, 0.08138538524508476, 0.08129540458321571, 0.0812181867659092, 0.08114006742835045, 0.08108066767454147, 0.0810345746576786, 0.08099574595689774, 0.08096638694405556, 0.08094511553645134, 0.08092690259218216, 0.08091053366661072, 0.08090177178382874, 0.08089762926101685, 0.08089552447199821, 0.08089630678296089, 0.08089904859662056, 0.08090488985180855, 0.08091182634234428, 0.08091302961111069, 0.08091454952955246, 0.08091641962528229, 0.08091770485043526, 0.08091961964964867, 0.08092164620757103, 0.08092299476265907, 0.08092446997761726, 0.08092684671282768, 0.08092834427952766, 0.0809287540614605, 0.08092892915010452, 0.08092926815152168, 0.08092979341745377, 0.08093004673719406, 0.08093057945370674, 0.08093081787228584, 0.08093129843473434, 0.08093157783150673, 0.08093202114105225, 0.08093208819627762, 0.08093219250440598, 0.08093225210905075, 0.0809323601424694, 0.08093240484595299, 0.08093249797821045, 0.08093256875872612, 0.08093263953924179, 0.08093273639678955, 0.08093282207846642, 0.08093284070491791, 0.0809328518807888, 0.08093288540840149, 0.08093288168311119, 0.08093291521072388, 0.08093293383717537, 0.08093294501304626, 0.08093294873833656, 0.08093296363949776, 0.08093299344182014, 0.08093298971652985, 0.08093299344182014, 0.08093300834298134, 0.08093300461769104, 0.08093301206827164, 0.08093301951885223, 0.08093303442001343, 0.08093303442001343, 0.08093302696943283, 0.08093303442001343, 0.08093303442001343, 0.08093304932117462, 0.08093304932117462, 0.08093303814530373, 0.08093303814530373, 0.08093303814530373, 0.08093303814530373, 0.08093303814530373, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313, 0.08093303069472313], 'loss': [0.4252263940870762, 0.4107074700295925, 0.3967253491282463, 0.38293588161468506, 0.36963945627212524, 0.3567313514649868, 0.3442135415971279, 0.332243625074625, 0.3203633688390255, 0.3092553988099098, 0.29840399138629436, 0.28772095777094364, 0.27783876843750477, 0.2680079285055399, 0.25859800539910793, 0.24951045960187912, 0.24078041687607765, 0.23254163190722466, 0.22432496584951878, 0.21680372022092342, 0.2093129064887762, 0.20227103307843208, 0.19535507448017597, 0.18873452208936214, 0.18268926441669464, 0.17658725008368492, 0.17087750602513552, 0.16547849215567112, 0.16006775572896004, 0.15532528050243855, 0.15059258230030537, 0.14619070943444967, 0.141777235083282, 0.13768674992024899, 0.13391122221946716, 0.13030045479536057, 0.1267700418829918, 0.12354664504528046, 0.12049439549446106, 0.11760237347334623, 0.11472619976848364, 0.11214588209986687, 0.1098040072247386, 0.10755961108952761, 0.10537664964795113, 0.10342059750109911, 0.10149191226810217, 0.09979743976145983, 0.0981165124103427, 0.09661287069320679, 0.09520806930959225, 0.09386604651808739, 0.09269081987440586, 0.09149063471704721, 0.09043796733021736, 0.0894637955352664, 0.08860537083819509, 0.08775858674198389, 0.08702118322253227, 0.0863319132477045, 0.08572038356214762, 0.08510104939341545, 0.0845292704179883, 0.08405588008463383, 0.08361594937741756, 0.08322273939847946, 0.08285888936370611, 0.08247195463627577, 0.08219191990792751, 0.08195182774215937, 0.08164077997207642, 0.08146057510748506, 0.08122800383716822, 0.0810420410707593, 0.08087771385908127, 0.08076748717576265, 0.08061439078301191, 0.08048516372218728, 0.0803829119540751, 0.0802813982591033, 0.08019027253612876, 0.08012297190725803, 0.08008034806698561, 0.08000371139496565, 0.07993494253605604, 0.07989795226603746, 0.07986167585477233, 0.07981726806610823, 0.07979537919163704, 0.0797615172341466, 0.07973967865109444, 0.0797355636022985, 0.07973307836800814, 0.07972606178373098, 0.07972454372793436, 0.07972064521163702, 0.07971310615539551, 0.07970941811800003, 0.07970907352864742, 0.07970144506543875, 0.07969885319471359, 0.07969758287072182, 0.07969713397324085, 0.07969695469364524, 0.0796954408288002, 0.07969550974667072, 0.07969386968761683, 0.07969370391219854, 0.07969241961836815, 0.07969203032553196, 0.07969123683869839, 0.07969117723405361, 0.07969095185399055, 0.07969091832637787, 0.07969061937183142, 0.07969056814908981, 0.07969034183770418, 0.07969018816947937, 0.07969008106738329, 0.07968989200890064, 0.07968981750309467, 0.07968976814299822, 0.07968974905088544, 0.07968970481306314, 0.07968969456851482, 0.07968964707106352, 0.07968961307778955, 0.0796895595267415, 0.07968956138938665, 0.07968950178474188, 0.07968947943300009, 0.07968947011977434, 0.0796894608065486, 0.07968946825712919, 0.07968945428729057, 0.0796894459053874, 0.07968944404274225, 0.0796894347295165, 0.07968943193554878, 0.07968941843137145, 0.07968942169100046, 0.07968941982835531, 0.07968942914158106, 0.07968942448496819, 0.07968942262232304, 0.07968942262232304, 0.0796894240193069, 0.07968941982835531, 0.07968941237777472, 0.07968940772116184, 0.07968940865248442, 0.07968940958380699, 0.07968940678983927, 0.07968940958380699, 0.07968940958380699, 0.07968941051512957, 0.07968940958380699, 0.07968940678983927, 0.07968940958380699, 0.07968940865248442, 0.07968940958380699, 0.07968940958380699, 0.07968940865248442, 0.07968941051512957, 0.07968940865248442, 0.07968940818682313, 0.07968941144645214, 0.07968940958380699, 0.07968941098079085, 0.07968940772116184, 0.07968941051512957, 0.07968940865248442, 0.07968940958380699, 0.07968940678983927, 0.07968940958380699, 0.07968940772116184, 0.07968940865248442, 0.07968940865248442, 0.0796894058585167, 0.07968940958380699, 0.07968940958380699, 0.07968941051512957, 0.07968941098079085, 0.07968941051512957, 0.07968940958380699, 0.07968940958380699, 0.07968941144645214, 0.07968940958380699, 0.07968940772116184, 0.0796894058585167, 0.07968940958380699, 0.0796894058585167, 0.07968940958380699, 0.07968940958380699, 0.07968941144645214, 0.0796894091181457, 0.07968940958380699, 0.07968940678983927, 0.07968941051512957, 0.07968940865248442, 0.07968940958380699, 0.07968940958380699, 0.07968940958380699, 0.07968940725550056, 0.07968940958380699, 0.07968940678983927, 0.07968940958380699, 0.07968940772116184, 0.07968941051512957, 0.07968940865248442, 0.07968940958380699, 0.07968940865248442, 0.07968940865248442, 0.07968940865248442, 0.07968940772116184, 0.07968940958380699, 0.07968940772116184, 0.07968940865248442, 0.07968940772116184, 0.07968940772116184, 0.07968941051512957, 0.07968940678983927, 0.07968941237777472, 0.07968940678983927, 0.07968940772116184, 0.07968940865248442, 0.0796894058585167, 0.07968940865248442, 0.07968940865248442, 0.07968940958380699, 0.07968940772116184, 0.07968940958380699, 0.07968940772116184, 0.07968940865248442, 0.07968941051512957, 0.07968941051512957, 0.07968940958380699, 0.07968940958380699, 0.07968940772116184, 0.07968940865248442, 0.07968940865248442, 0.07968941051512957, 0.07968941051512957, 0.07968940865248442, 0.07968940865248442, 0.07968941051512957, 0.07968940865248442, 0.0796894058585167, 0.07968940678983927, 0.0796894091181457, 0.07968940865248442, 0.07968941051512957, 0.07968941051512957, 0.07968940772116184, 0.07968941051512957, 0.07968940772116184, 0.07968941051512957, 0.07968940865248442, 0.07968941051512957, 0.07968940678983927, 0.07968940678983927, 0.07968940958380699, 0.0796894091181457, 0.07968941051512957, 0.07968940772116184, 0.07968940865248442, 0.07968940958380699, 0.07968941051512957, 0.07968941004946828, 0.07968940958380699, 0.07968941004946828, 0.07968941144645214, 0.07968940865248442, 0.07968940865248442, 0.07968940678983927, 0.07968940678983927, 0.0796894058585167, 0.07968940958380699, 0.07968940772116184, 0.07968940678983927, 0.07968941051512957, 0.07968941051512957, 0.07968941051512957, 0.07968940772116184, 0.07968941051512957, 0.07968940772116184, 0.07968940678983927, 0.07968940772116184, 0.07968940818682313, 0.07968940772116184, 0.07968940678983927, 0.07968940958380699, 0.07968940865248442, 0.07968941051512957, 0.07968941144645214, 0.07968940772116184, 0.07968940865248442, 0.07968940865248442, 0.07968940818682313, 0.07968940958380699, 0.07968940772116184, 0.07968940772116184, 0.07968940958380699, 0.07968940865248442, 0.07968940772116184, 0.07968940958380699, 0.07968940772116184, 0.07968940865248442, 0.07968940958380699, 0.07968941144645214, 0.07968941144645214, 0.07968941330909729, 0.0796894058585167, 0.07968941098079085, 0.07968940632417798, 0.07968941051512957, 0.07968940865248442, 0.07968940958380699, 0.07968940772116184, 0.07968941237777472, 0.07968940958380699, 0.07968941144645214, 0.07968940772116184, 0.07968940678983927, 0.07968940958380699, 0.07968940958380699, 0.07968940958380699, 0.07968941051512957, 0.07968940678983927, 0.07968940865248442, 0.0796894058585167, 0.07968940865248442, 0.07968941144645214, 0.07968940958380699, 0.07968940958380699, 0.0796894058585167, 0.07968940958380699, 0.0796894058585167, 0.07968941237777472, 0.07968941051512957, 0.07968940958380699, 0.07968940865248442, 0.07968940958380699, 0.07968940865248442, 0.07968940678983927, 0.07968941237777472, 0.07968941144645214, 0.07968940958380699, 0.07968940772116184, 0.07968941051512957, 0.07968940958380699, 0.07968940865248442, 0.07968941051512957, 0.07968940678983927, 0.07968940772116184, 0.07968940865248442, 0.07968941051512957, 0.07968940865248442, 0.07968940958380699, 0.07968941330909729, 0.07968940958380699, 0.07968940818682313, 0.07968941144645214, 0.07968940678983927, 0.07968940958380699, 0.07968940772116184, 0.07968940865248442, 0.07968940772116184, 0.0796894091181457, 0.07968940772116184, 0.07968941051512957, 0.07968940678983927, 0.07968941051512957, 0.07968940865248442, 0.07968940772116184, 0.07968940958380699, 0.07968940865248442, 0.07968941330909729, 0.07968941144645214, 0.07968940865248442, 0.07968940772116184, 0.07968940958380699, 0.07968940865248442, 0.07968941330909729, 0.07968940958380699, 0.07968940865248442, 0.07968940772116184, 0.07968940958380699, 0.07968940678983927, 0.07968940865248442, 0.0796894058585167, 0.07968941051512957, 0.07968940865248442, 0.07968941051512957, 0.07968940958380699, 0.07968940772116184, 0.07968941144645214, 0.07968940958380699, 0.07968940958380699, 0.07968940865248442, 0.07968941051512957, 0.07968940865248442, 0.07968940958380699, 0.07968940772116184, 0.07968940865248442, 0.07968941051512957, 0.07968941051512957, 0.07968941098079085, 0.07968941051512957, 0.07968940958380699, 0.07968940865248442, 0.07968940492719412, 0.07968940865248442, 0.07968941144645214, 0.07968941144645214, 0.07968940772116184, 0.07968940958380699, 0.07968940865248442, 0.07968940958380699, 0.07968940958380699, 0.07968940865248442, 0.07968941051512957, 0.07968940492719412, 0.07968941144645214, 0.07968941237777472, 0.07968940958380699, 0.07968941237777472, 0.07968941144645214, 0.07968941051512957, 0.07968940958380699, 0.07968940958380699, 0.07968940865248442, 0.07968940958380699, 0.07968940958380699, 0.07968940865248442, 0.07968941051512957, 0.07968940958380699, 0.07968941144645214, 0.0796894091181457, 0.0796894058585167, 0.0796894058585167, 0.07968940865248442, 0.07968940772116184, 0.07968940958380699, 0.07968941144645214, 0.07968941144645214, 0.07968941051512957, 0.07968940958380699, 0.07968940865248442, 0.07968940865248442, 0.07968940865248442, 0.07968941051512957, 0.07968940772116184, 0.07968940958380699, 0.07968940772116184, 0.07968940772116184, 0.07968940958380699, 0.07968941237777472, 0.07968940678983927, 0.07968941144645214, 0.07968940492719412, 0.07968940772116184, 0.07968940865248442, 0.07968940678983927, 0.07968940865248442, 0.07968940678983927, 0.0796894091181457, 0.07968940772116184, 0.07968940958380699, 0.07968941144645214, 0.07968941051512957, 0.07968941051512957, 0.07968940958380699, 0.07968940865248442, 0.07968941051512957, 0.07968940958380699, 0.07968940678983927, 0.07968940958380699, 0.07968940865248442, 0.07968940678983927, 0.07968941051512957, 0.07968940772116184, 0.07968940865248442, 0.07968941004946828, 0.07968940865248442, 0.07968940772116184, 0.07968941098079085, 0.07968940958380699, 0.07968940772116184, 0.07968940958380699, 0.07968940772116184, 0.07968940772116184, 0.07968940958380699, 0.07968941237777472, 0.07968941051512957, 0.07968940772116184, 0.07968941144645214, 0.07968940772116184, 0.07968941051512957, 0.07968940772116184, 0.07968940865248442, 0.07968940865248442, 0.07968940958380699, 0.07968940958380699, 0.07968940725550056, 0.07968940725550056, 0.07968941144645214, 0.07968940958380699, 0.07968940678983927, 0.07968940958380699, 0.07968940958380699, 0.07968941051512957, 0.07968940958380699, 0.07968941144645214, 0.07968940772116184, 0.07968940865248442, 0.07968940818682313, 0.07968940958380699, 0.07968941144645214, 0.07968940772116184, 0.07968940958380699, 0.07968941330909729, 0.07968940772116184, 0.07968940865248442, 0.07968941051512957, 0.07968941237777472, 0.07968940958380699, 0.07968940865248442, 0.07968940772116184, 0.07968940865248442, 0.07968940772116184, 0.07968940865248442, 0.07968940958380699, 0.07968941051512957, 0.07968940958380699, 0.07968941051512957, 0.07968940492719412, 0.0796894091181457, 0.07968940865248442, 0.07968940772116184, 0.07968941051512957, 0.07968940958380699, 0.07968940958380699, 0.07968940678983927, 0.07968941144645214, 0.07968940772116184, 0.07968940865248442, 0.07968941051512957, 0.07968941144645214, 0.07968941051512957, 0.07968940958380699, 0.07968940772116184, 0.07968940958380699, 0.07968941144645214, 0.07968940772116184, 0.07968940492719412, 0.07968940958380699, 0.0796894091181457, 0.07968940678983927, 0.07968941051512957, 0.07968940865248442, 0.07968940865248442, 0.07968940772116184, 0.07968940958380699, 0.07968940678983927, 0.07968941144645214, 0.07968941051512957, 0.0796894091181457, 0.07968940772116184, 0.07968940865248442, 0.07968940772116184, 0.07968941144645214, 0.07968940772116184, 0.07968941144645214, 0.07968941237777472, 0.07968940492719412, 0.07968940772116184, 0.07968941144645214, 0.07968941051512957, 0.07968940958380699, 0.07968941051512957, 0.07968940865248442, 0.07968940865248442, 0.07968940865248442, 0.07968940865248442, 0.07968940958380699, 0.07968941051512957, 0.07968940725550056, 0.07968940772116184, 0.07968941051512957, 0.07968940772116184, 0.07968941051512957, 0.07968940678983927, 0.07968941051512957, 0.07968941051512957, 0.07968940865248442, 0.07968940865248442, 0.07968940818682313, 0.0796894058585167, 0.07968940865248442, 0.07968940865248442, 0.07968940958380699, 0.07968940958380699, 0.07968940772116184, 0.07968941051512957, 0.07968940865248442, 0.07968941144645214, 0.07968940958380699, 0.07968941144645214, 0.07968941051512957, 0.07968940865248442, 0.07968940865248442, 0.07968940958380699, 0.0796894058585167, 0.07968940772116184, 0.07968940725550056, 0.07968940678983927, 0.07968940678983927, 0.07968941051512957, 0.07968940678983927, 0.07968940678983927, 0.07968940678983927, 0.07968941237777472, 0.07968940958380699, 0.07968940678983927, 0.07968940958380699, 0.07968941051512957, 0.07968941144645214, 0.07968940958380699, 0.07968941051512957, 0.07968940772116184, 0.07968940865248442, 0.07968941051512957, 0.07968940958380699, 0.07968940772116184, 0.07968940958380699, 0.07968941237777472, 0.0796894058585167, 0.07968940865248442, 0.07968940958380699, 0.07968941144645214, 0.07968940958380699, 0.07968940678983927, 0.07968940958380699, 0.07968940958380699, 0.07968941051512957, 0.07968941051512957, 0.07968940958380699, 0.07968940772116184, 0.07968940772116184, 0.07968941051512957, 0.07968940772116184, 0.07968940865248442, 0.07968940958380699, 0.07968940958380699, 0.07968940865248442, 0.07968940958380699, 0.07968941144645214, 0.07968940772116184, 0.07968940865248442, 0.07968940678983927, 0.07968940865248442, 0.07968941144645214, 0.07968940772116184, 0.0796894058585167, 0.07968941144645214, 0.07968941051512957, 0.07968941144645214, 0.07968940958380699, 0.07968940772116184, 0.07968940678983927, 0.07968941144645214, 0.07968940865248442, 0.07968941051512957, 0.0796894058585167, 0.07968940772116184, 0.07968940772116184, 0.07968940958380699, 0.07968940772116184, 0.07968940678983927, 0.07968940958380699, 0.0796894091181457, 0.07968940865248442, 0.07968940772116184, 0.07968940772116184, 0.07968940772116184, 0.07968941051512957, 0.07968940865248442, 0.07968940772116184, 0.07968941144645214, 0.07968941051512957, 0.07968940865248442, 0.07968940958380699, 0.07968940958380699, 0.0796894091181457, 0.07968941051512957, 0.07968941051512957, 0.07968940958380699, 0.07968940958380699, 0.07968941237777472], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.00020000001, 0.00020000001, 0.00020000001, 0.00020000001, 0.00020000001, 0.00020000001, 0.00020000001, 0.00020000001, 0.00020000001, 0.00020000001, 4.0000003e-05, 4.0000003e-05, 4.0000003e-05, 4.0000003e-05, 4.0000003e-05, 4.0000003e-05, 4.0000003e-05, 4.0000003e-05, 4.0000003e-05, 4.0000003e-05, 8.000001e-06, 8.000001e-06, 8.000001e-06, 8.000001e-06, 8.000001e-06, 8.000001e-06, 8.000001e-06, 8.000001e-06, 8.000001e-06, 8.000001e-06, 1.6000001e-06, 1.6000001e-06, 1.6000001e-06, 1.6000001e-06, 1.6000001e-06, 1.6000001e-06, 1.6000001e-06, 1.6000001e-06, 1.6000001e-06, 1.6000001e-06, 3.2000003e-07, 3.2000003e-07, 3.2000003e-07, 3.2000003e-07, 3.2000003e-07, 3.2000003e-07, 3.2000003e-07, 3.2000003e-07, 3.2000003e-07, 3.2000003e-07, 6.4000005e-08, 6.4000005e-08, 6.4000005e-08, 6.4000005e-08, 6.4000005e-08, 6.4000005e-08, 6.4000005e-08, 6.4000005e-08, 6.4000005e-08, 6.4000005e-08, 1.2800001e-08, 1.2800001e-08, 1.2800001e-08, 1.2800001e-08, 1.2800001e-08, 1.2800001e-08, 1.2800001e-08, 1.2800001e-08, 1.2800001e-08, 1.2800001e-08, 2.5600002e-09, 2.5600002e-09, 2.5600002e-09, 2.5600002e-09, 2.5600002e-09, 2.5600002e-09, 2.5600002e-09, 2.5600002e-09, 2.5600002e-09, 2.5600002e-09, 5.1200005e-10, 5.1200005e-10, 5.1200005e-10, 5.1200005e-10, 5.1200005e-10, 5.1200005e-10, 5.1200005e-10, 5.1200005e-10, 5.1200005e-10, 5.1200005e-10, 1.0240001e-10, 1.0240001e-10, 1.0240001e-10, 1.0240001e-10, 1.0240001e-10, 1.0240001e-10, 1.0240001e-10, 1.0240001e-10, 1.0240001e-10, 1.0240001e-10, 2.0480003e-11, 2.0480003e-11, 2.0480003e-11, 2.0480003e-11, 2.0480003e-11, 2.0480003e-11, 2.0480003e-11, 2.0480003e-11, 2.0480003e-11, 2.0480003e-11, 4.0960004e-12, 4.0960004e-12, 4.0960004e-12, 4.0960004e-12, 4.0960004e-12, 4.0960004e-12, 4.0960004e-12, 4.0960004e-12, 4.0960004e-12, 4.0960004e-12, 8.1920007e-13, 8.1920007e-13, 8.1920007e-13, 8.1920007e-13, 8.1920007e-13, 8.1920007e-13, 8.1920007e-13, 8.1920007e-13, 8.1920007e-13, 8.1920007e-13, 1.6384001e-13, 1.6384001e-13, 1.6384001e-13, 1.6384001e-13, 1.6384001e-13, 1.6384001e-13, 1.6384001e-13, 1.6384001e-13, 1.6384001e-13, 1.6384001e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13]};0.6\".count(\";\"))\n",
    "print(\"INFO:root:lstm;softmax;504;[420, 42];0;2;786787;699;{'val_loss': [0.692264586687088, 0.6728518605232239, 0.6537942290306091, 0.6349968016147614, 0.6168437004089355, 0.5989132821559906, 0.5815097689628601, 0.5645691156387329, 0.5478562712669373, 0.5317398011684418, 0.5159025192260742, 0.5005050748586655, 0.4855778217315674, 0.470770463347435, 0.45669853687286377, 0.4428652375936508, 0.4293307512998581, 0.4162876009941101, 0.40348581969738007, 0.39117057621479034, 0.3789701461791992, 0.3672144412994385, 0.3557344079017639, 0.34449970722198486, 0.33364708721637726, 0.3231334537267685, 0.31297294795513153, 0.3029703199863434, 0.2933391034603119, 0.2840083986520767, 0.27498701214790344, 0.2663957178592682, 0.2577584907412529, 0.24962542951107025, 0.2416173294186592, 0.2339610531926155, 0.22651827335357666, 0.21936434507369995, 0.21249397844076157, 0.20571515709161758, 0.1992669701576233, 0.19321629405021667, 0.18719889968633652, 0.18140313774347305, 0.17578165978193283, 0.17054304480552673, 0.16534630954265594, 0.16039365530014038, 0.15563255548477173, 0.15115492790937424, 0.14675720036029816, 0.1426539421081543, 0.138633094727993, 0.13485825806856155, 0.1312158778309822, 0.1276954524219036, 0.12429976835846901, 0.12122372165322304, 0.11814893782138824, 0.11528777331113815, 0.11263982951641083, 0.11003580316901207, 0.10746631026268005, 0.10508771613240242, 0.10289902985095978, 0.10071289539337158, 0.09871361777186394, 0.09690633416175842, 0.09494754672050476, 0.09326542913913727, 0.0917048454284668, 0.09009574353694916, 0.08874957263469696, 0.08727524802088737, 0.08602619916200638, 0.08483206480741501, 0.08365482091903687, 0.08260226622223854, 0.08157964050769806, 0.08058273792266846, 0.07959915697574615, 0.07879029586911201, 0.07795252278447151, 0.07716524973511696, 0.07649614289402962, 0.07581100985407829, 0.07521096989512444, 0.07454393431544304, 0.07403041794896126, 0.0734880305826664, 0.0729784406721592, 0.07247760891914368, 0.07205909863114357, 0.07160364091396332, 0.07123466953635216, 0.07086759433150291, 0.07050895318388939, 0.07022949680685997, 0.06992213428020477, 0.06960899755358696, 0.06933682039380074, 0.0690443217754364, 0.06890014931559563, 0.06872967630624771, 0.06848245859146118, 0.06823094189167023, 0.06805144622921944, 0.06789520010352135, 0.06771188974380493, 0.06755925342440605, 0.0673341155052185, 0.06725715473294258, 0.06709527224302292, 0.06697875633835793, 0.06682437285780907, 0.06678761541843414, 0.06672659888863564, 0.0665416419506073, 0.06637173146009445, 0.066279336810112, 0.06627336144447327, 0.06621242687106133, 0.06616439297795296, 0.06602293252944946, 0.06595757231116295, 0.06589305773377419, 0.06581268459558487, 0.06572281196713448, 0.06568167731165886, 0.06563541293144226, 0.06559982150793076, 0.06554965302348137, 0.06556375324726105, 0.06557313352823257, 0.06550070643424988, 0.06538034975528717, 0.0653417743742466, 0.06530030071735382, 0.0652681477367878, 0.06525479257106781, 0.06523960828781128, 0.06519636884331703, 0.06521301716566086, 0.06520490348339081, 0.06514887511730194, 0.06509527564048767, 0.06510274112224579, 0.06505642458796501, 0.06502475216984749, 0.06505850702524185, 0.06500178202986717, 0.0649917759001255, 0.06497826799750328, 0.06500091031193733, 0.06498857587575912, 0.06490057706832886, 0.06489717960357666, 0.0648229829967022, 0.06486405432224274, 0.06482822448015213, 0.06483915448188782, 0.06489592790603638, 0.06478406116366386, 0.06472115591168404, 0.06473585590720177, 0.06467972695827484, 0.0646900050342083, 0.06461984664201736, 0.06463943421840668, 0.06466827541589737, 0.06471636891365051, 0.06465944647789001, 0.06467822566628456, 0.06469512730836868, 0.06463580578565598, 0.06456303596496582, 0.0645919069647789, 0.0646786279976368, 0.06463231518864632, 0.06454766914248466, 0.06448833271861076, 0.06453464180231094, 0.06454937160015106, 0.06453320384025574, 0.06447531655430794, 0.06442787870764732, 0.06441519781947136, 0.06440586596727371, 0.06450652703642845, 0.06448526680469513, 0.06448811292648315, 0.06443092226982117, 0.06438378989696503, 0.06446905806660652, 0.06444629654288292, 0.06441006064414978, 0.06439933180809021, 0.06439012289047241, 0.06438679993152618, 0.06437429785728455, 0.0643768310546875, 0.06438210234045982, 0.06438241899013519, 0.06438378244638443, 0.06437018513679504, 0.06436214596033096, 0.06436033174395561, 0.06436026096343994, 0.06435933336615562, 0.06436166539788246, 0.064358901232481, 0.06436130031943321, 0.06436247006058693, 0.06436223536729813, 0.06436246261000633, 0.06435996294021606, 0.0643601268529892, 0.06435877084732056, 0.0643596351146698, 0.06435970216989517, 0.06435978785157204, 0.06435896083712578, 0.06435950100421906, 0.06435859575867653, 0.06435887143015862, 0.06435820460319519, 0.06435812264680862, 0.0643581710755825, 0.06435810029506683, 0.06435804069042206, 0.06435805559158325, 0.06435811519622803, 0.06435810029506683, 0.06435808911919594, 0.064358189702034, 0.06435805559158325, 0.06435805559158325, 0.06435804069042206, 0.06435805559158325, 0.06435803696513176, 0.06435805559158325, 0.06435805559158325, 0.06435803323984146, 0.06435805559158325, 0.06435805559158325, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997, 0.06435801461338997], 'loss': [0.5876753404736519, 0.5700119845569134, 0.5525041967630386, 0.5357609838247299, 0.518819659948349, 0.5028991028666496, 0.4868825525045395, 0.4714743234217167, 0.45676111429929733, 0.4419415183365345, 0.42792442068457603, 0.4140820913016796, 0.4005451500415802, 0.38786424323916435, 0.37473947554826736, 0.3625703789293766, 0.3506751097738743, 0.3388835061341524, 0.3277031220495701, 0.3165533021092415, 0.30614939890801907, 0.29569633677601814, 0.2857394888997078, 0.2761324364691973, 0.26666413620114326, 0.2575349174439907, 0.24867320992052555, 0.24032256565988064, 0.23200547322630882, 0.22403862327337265, 0.2163277268409729, 0.20874075777828693, 0.20193153247237206, 0.19477589800953865, 0.18827957846224308, 0.18177971802651882, 0.1756659559905529, 0.16970103979110718, 0.16396370716392994, 0.15865539014339447, 0.15331661608070135, 0.1481201220303774, 0.14348838943988085, 0.13887810986489058, 0.13451774418354034, 0.13013651128858328, 0.12627833243459463, 0.1224061194807291, 0.11876305472105742, 0.11519856657832861, 0.11199724487960339, 0.10875008162111044, 0.10586169548332691, 0.10296329949051142, 0.10031863767653704, 0.09782600589096546, 0.09546782728284597, 0.09305630065500736, 0.09105723537504673, 0.08898501377552748, 0.08703123172745109, 0.085324892308563, 0.08374257851392031, 0.08212192030623555, 0.08059875201433897, 0.0793210887350142, 0.0779789132066071, 0.0767189571633935, 0.07581115188077092, 0.07462552934885025, 0.07363874558359385, 0.07285420829430223, 0.07189182890579104, 0.07126767514273524, 0.07044574758037925, 0.06979530956596136, 0.06921983044594526, 0.06862518424168229, 0.06812417833134532, 0.06766551686450839, 0.06725845905020833, 0.06678262446075678, 0.0664607030339539, 0.06611676001921296, 0.06576722580939531, 0.06551252212375402, 0.06522974744439125, 0.0650498983450234, 0.06477313954383135, 0.06459950283169746, 0.06442168587818742, 0.064265928696841, 0.06409266265109181, 0.06398702412843704, 0.06383415823802352, 0.06372844893485308, 0.06363447662442923, 0.06352402316406369, 0.06344601279124618, 0.06337579758837819, 0.06329536391422153, 0.06325468607246876, 0.06315814889967442, 0.06311222491785884, 0.06307174218818545, 0.06303230533376336, 0.06297913799062371, 0.06293554604053497, 0.0629043192602694, 0.06286900769919157, 0.06286286376416683, 0.06280866079032421, 0.06279368326067924, 0.06276052026078105, 0.06274656532332301, 0.06271897489205003, 0.06271223071962595, 0.06269358051940799, 0.06268123723566532, 0.0626477007754147, 0.0626334766857326, 0.06261177873238921, 0.06260395608842373, 0.06259420234709978, 0.06257159914821386, 0.06255693966522813, 0.0625471118837595, 0.06254123291000724, 0.06252158060669899, 0.0625089081004262, 0.0624979343265295, 0.06249070819467306, 0.062478207051754, 0.06247423170134425, 0.06245574587956071, 0.06246033962816, 0.06243369309231639, 0.06242757756263018, 0.06241615582257509, 0.06240680394694209, 0.06239367229864001, 0.0623881365172565, 0.062376228626817465, 0.06236714590340853, 0.0623562796972692, 0.0623513450846076, 0.06233838200569153, 0.062332633417099714, 0.06232014251872897, 0.06231545843183994, 0.0623054257594049, 0.06229612464085221, 0.062282225117087364, 0.06228072941303253, 0.06226402008906007, 0.06226015090942383, 0.062246883288025856, 0.06224349467083812, 0.062232667580246925, 0.062220350839197636, 0.062212527729570866, 0.06222188798710704, 0.06220340169966221, 0.0621897685341537, 0.06217513792216778, 0.062179252970963717, 0.0621565175242722, 0.06216079369187355, 0.06214133137837052, 0.06213201116770506, 0.06212729774415493, 0.06211861688643694, 0.062108364421874285, 0.0621008793823421, 0.06209163321182132, 0.0620917365886271, 0.06207100860774517, 0.06208707531914115, 0.06205339357256889, 0.06205146200954914, 0.06204713322222233, 0.062030785251408815, 0.06202196329832077, 0.06201188964769244, 0.06200442695990205, 0.061997882556170225, 0.06198930507525802, 0.061977487057447433, 0.06198592251166701, 0.06195758655667305, 0.06195157486945391, 0.06194559810683131, 0.06194149004295468, 0.06194043951109052, 0.061914867255836725, 0.061910320073366165, 0.061898961663246155, 0.0618973458185792, 0.061895512510091066, 0.06189511762931943, 0.061891531106084585, 0.06189005263149738, 0.06188833760097623, 0.061886623967438936, 0.06188525725156069, 0.0618840497918427, 0.06188145838677883, 0.06188100855797529, 0.061880781315267086, 0.06188042415305972, 0.06188053451478481, 0.06188003160059452, 0.061879293993115425, 0.061878891196101904, 0.061878602020442486, 0.061878152657300234, 0.06187787186354399, 0.06187813216820359, 0.06187784532085061, 0.06187765719369054, 0.06187763577327132, 0.0618775449693203, 0.061877507250756025, 0.061877443455159664, 0.0618773614987731, 0.061877287458628416, 0.06187715893611312, 0.0618771412409842, 0.0618771375156939, 0.061877123080193996, 0.06187711050733924, 0.06187709793448448, 0.061877075117081404, 0.06187707278877497, 0.06187708396464586, 0.06187704158946872, 0.0618770238943398, 0.061877028085291386, 0.06187701504677534, 0.061877022963017225, 0.06187702342867851, 0.06187701225280762, 0.061876998748630285, 0.06187700945883989, 0.06187701318413019, 0.061877002008259296, 0.06187699502333999, 0.06187699316069484, 0.0618769945576787, 0.06187699595466256, 0.0618769945576787, 0.06187699502333999, 0.06187699595466256, 0.06187699409201741, 0.061876995489001274, 0.06187699502333999, 0.0618769945576787, 0.06187699502333999, 0.06187699409201741, 0.06187699595466256, 0.06187699222937226, 0.06187699502333999, 0.061876993626356125, 0.06187699502333999, 0.06187699735164642, 0.06187699502333999, 0.06187699595466256, 0.06187699642032385, 0.06187699502333999, 0.0618769945576787, 0.061876996885985136, 0.0618769945576787, 0.061876993626356125, 0.0618769945576787, 0.061876996885985136, 0.061876995489001274, 0.06187699502333999, 0.06187699502333999, 0.06187699735164642, 0.061876995489001274, 0.061876993626356125, 0.061876995489001274, 0.061876995489001274, 0.0618769945576787, 0.06187699502333999, 0.06187699502333999, 0.061876995489001274, 0.061876995489001274, 0.06187699502333999, 0.0618769945576787, 0.06187699502333999, 0.0618769945576787, 0.0618769945576787, 0.061876995489001274, 0.061876995489001274, 0.06187699502333999, 0.06187699502333999, 0.0618769945576787, 0.061876993626356125, 0.061876993626356125, 0.06187699316069484, 0.06187699502333999, 0.06187699409201741, 0.06187699409201741, 0.06187699409201741, 0.06187699502333999, 0.061876995489001274, 0.06187699502333999, 0.06187699595466256, 0.061876993626356125, 0.0618769945576787, 0.061876993626356125, 0.061876995489001274, 0.06187699316069484, 0.06187699595466256, 0.06187699502333999, 0.06187699502333999, 0.06187699595466256, 0.0618769945576787, 0.061876995489001274, 0.0618769945576787, 0.0618769945576787, 0.06187699409201741, 0.061876995489001274, 0.06187699595466256, 0.061876995489001274, 0.061876993626356125, 0.06187699502333999, 0.061876993626356125, 0.06187699409201741, 0.061876995489001274, 0.061876995489001274, 0.06187699595466256, 0.0618769945576787, 0.0618769945576787, 0.0618769945576787, 0.061876995489001274, 0.06187699502333999, 0.06187699595466256, 0.06187699642032385, 0.06187699409201741, 0.061876995489001274, 0.06187699595466256, 0.06187699502333999, 0.0618769945576787, 0.06187699269503355, 0.061876995489001274, 0.06187699502333999, 0.0618769945576787, 0.061876993626356125, 0.0618769945576787, 0.06187699502333999, 0.06187699502333999, 0.06187699269503355, 0.06187699642032385, 0.0618769945576787, 0.061876995489001274, 0.0618769945576787, 0.06187699502333999, 0.0618769945576787, 0.06187699502333999, 0.0618769945576787, 0.061876995489001274, 0.06187699502333999, 0.06187699316069484, 0.061876993626356125, 0.061876995489001274, 0.061876993626356125, 0.0618769945576787, 0.06187699502333999, 0.061876995489001274, 0.06187699502333999, 0.06187699502333999, 0.061876995489001274, 0.0618769945576787, 0.0618769945576787, 0.06187699502333999, 0.061876996885985136, 0.06187699595466256, 0.06187699409201741, 0.061876993626356125, 0.06187699642032385, 0.06187699502333999, 0.06187699409201741, 0.061876995489001274, 0.06187699409201741, 0.06187699502333999, 0.0618769945576787, 0.061876995489001274, 0.06187699409201741, 0.061876993626356125, 0.0618769945576787, 0.061876993626356125, 0.061876995489001274, 0.0618769945576787, 0.061876995489001274, 0.06187699502333999, 0.06187699595466256, 0.06187699502333999, 0.06187699409201741, 0.06187699502333999, 0.06187699502333999, 0.061876995489001274, 0.06187699316069484, 0.06187699595466256, 0.06187699409201741, 0.06187699409201741, 0.061876995489001274, 0.06187699502333999, 0.06187699502333999, 0.06187699409201741, 0.061876995489001274, 0.06187699502333999, 0.061876993626356125, 0.06187699595466256, 0.06187699502333999, 0.06187699502333999, 0.06187699642032385, 0.0618769945576787, 0.06187699316069484, 0.061876993626356125, 0.061876995489001274, 0.0618769945576787, 0.061876995489001274, 0.06187699595466256, 0.06187699595466256, 0.0618769945576787, 0.06187699502333999, 0.06187699409201741, 0.06187699502333999, 0.06187699595466256, 0.06187699409201741, 0.06187699502333999, 0.0618769945576787, 0.0618769945576787, 0.06187699642032385, 0.06187699409201741, 0.06187699502333999, 0.0618769945576787, 0.06187699502333999, 0.061876995489001274, 0.06187699502333999, 0.06187699409201741, 0.061876995489001274, 0.06187699502333999, 0.06187699502333999, 0.0618769945576787, 0.06187699502333999, 0.0618769945576787, 0.06187699316069484, 0.06187699409201741, 0.0618769945576787, 0.06187699502333999, 0.06187699502333999, 0.06187699502333999, 0.06187699502333999, 0.06187699642032385, 0.06187699409201741, 0.06187699409201741, 0.06187699502333999, 0.06187699222937226, 0.06187699595466256, 0.06187699502333999, 0.06187699502333999, 0.06187699502333999, 0.06187699409201741, 0.06187699502333999, 0.061876995489001274, 0.0618769945576787, 0.06187699595466256, 0.061876995489001274, 0.06187699502333999, 0.06187699595466256, 0.0618769945576787, 0.061876995489001274, 0.0618769945576787, 0.06187699595466256, 0.061876993626356125, 0.0618769945576787, 0.06187699642032385, 0.06187699502333999, 0.06187699409201741, 0.061876993626356125, 0.0618769945576787, 0.0618769945576787, 0.06187699502333999, 0.0618769945576787, 0.0618769945576787, 0.061876995489001274, 0.061876993626356125, 0.06187699595466256, 0.06187699409201741, 0.06187699502333999, 0.06187699316069484, 0.061876995489001274, 0.06187699502333999, 0.06187699502333999, 0.061876995489001274, 0.0618769945576787, 0.06187699502333999, 0.0618769945576787, 0.0618769945576787, 0.06187699502333999, 0.061876995489001274, 0.06187699502333999, 0.061876995489001274, 0.0618769945576787, 0.061876995489001274, 0.06187699502333999, 0.0618769945576787, 0.06187699502333999, 0.06187699595466256, 0.06187699595466256, 0.06187699595466256, 0.06187699409201741, 0.06187699502333999, 0.06187699502333999, 0.061876995489001274, 0.06187699502333999, 0.06187699502333999, 0.06187699502333999, 0.06187699316069484, 0.0618769945576787, 0.0618769945576787, 0.06187699409201741, 0.061876993626356125, 0.06187699409201741, 0.061876996885985136, 0.06187699595466256, 0.06187699502333999, 0.061876995489001274, 0.06187699502333999, 0.06187699642032385, 0.06187699409201741, 0.061876995489001274, 0.06187699502333999, 0.06187699642032385, 0.06187699502333999, 0.061876993626356125, 0.061876995489001274, 0.06187699409201741, 0.06187699409201741, 0.06187699502333999, 0.0618769945576787, 0.06187699316069484, 0.06187699595466256, 0.06187699595466256, 0.0618769945576787, 0.06187699502333999, 0.061876995489001274, 0.06187699502333999, 0.06187699502333999, 0.061876995489001274, 0.061876995489001274, 0.061876995489001274, 0.06187699316069484, 0.061876995489001274, 0.06187699502333999, 0.06187699409201741, 0.061876995489001274, 0.06187699409201741, 0.06187699502333999, 0.0618769945576787, 0.0618769945576787, 0.06187699409201741, 0.0618769945576787, 0.06187699642032385, 0.0618769945576787, 0.061876996885985136, 0.06187699409201741, 0.061876995489001274, 0.0618769945576787, 0.06187699409201741, 0.0618769945576787, 0.06187699409201741, 0.06187699316069484, 0.06187699642032385, 0.06187699316069484, 0.061876995489001274, 0.0618769945576787, 0.06187699409201741, 0.06187699409201741, 0.0618769945576787, 0.061876996885985136, 0.06187699409201741, 0.0618769945576787, 0.06187699595466256, 0.06187699409201741, 0.0618769945576787, 0.061876995489001274, 0.061876993626356125, 0.0618769945576787, 0.06187699502333999, 0.06187699269503355, 0.061876995489001274, 0.06187699502333999, 0.06187699409201741, 0.06187699502333999, 0.061876993626356125, 0.061876995489001274, 0.0618769945576787, 0.06187699502333999, 0.06187699409201741, 0.06187699595466256, 0.06187699502333999, 0.06187699409201741, 0.061876995489001274, 0.06187699642032385, 0.06187699595466256, 0.0618769945576787, 0.0618769945576787, 0.06187699502333999, 0.061876996885985136, 0.061876995489001274, 0.06187699502333999, 0.0618769945576787, 0.061876993626356125, 0.0618769945576787, 0.061876995489001274, 0.0618769945576787, 0.06187699502333999, 0.0618769945576787, 0.06187699595466256, 0.0618769945576787, 0.061876995489001274, 0.0618769945576787, 0.06187699409201741, 0.06187699502333999, 0.061876993626356125, 0.061876995489001274, 0.06187699595466256, 0.0618769945576787, 0.06187699409201741, 0.0618769945576787, 0.061876996885985136, 0.06187699502333999, 0.061876993626356125, 0.0618769945576787, 0.0618769945576787, 0.061876995489001274, 0.0618769945576787, 0.061876995489001274, 0.0618769945576787, 0.06187699502333999, 0.06187699502333999, 0.0618769945576787, 0.06187699502333999, 0.06187699595466256, 0.06187699409201741, 0.06187699642032385, 0.06187699502333999, 0.061876995489001274, 0.0618769945576787, 0.06187699316069484, 0.06187699316069484, 0.061876993626356125, 0.061876995489001274, 0.06187699502333999, 0.06187699409201741, 0.0618769945576787, 0.061876993626356125, 0.06187699502333999, 0.06187699595466256, 0.06187699409201741, 0.06187699502333999, 0.0618769945576787, 0.061876995489001274, 0.061876993626356125, 0.06187699269503355, 0.06187699409201741, 0.061876995489001274, 0.06187699502333999, 0.06187699502333999, 0.06187699502333999, 0.061876991763710976, 0.061876995489001274, 0.0618769945576787, 0.0618769945576787, 0.06187699595466256, 0.06187699595466256, 0.06187699316069484, 0.061876995489001274, 0.06187699269503355, 0.06187699595466256, 0.06187699502333999, 0.06187699502333999, 0.061876993626356125, 0.06187699502333999, 0.0618769945576787, 0.0618769945576787, 0.06187699502333999, 0.0618769945576787, 0.06187699502333999, 0.06187699595466256, 0.06187699409201741, 0.06187699409201741, 0.06187699409201741, 0.06187699502333999, 0.061876993626356125, 0.06187699502333999], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.00020000001, 0.00020000001, 0.00020000001, 0.00020000001, 0.00020000001, 0.00020000001, 0.00020000001, 0.00020000001, 0.00020000001, 0.00020000001, 4.0000003e-05, 4.0000003e-05, 4.0000003e-05, 4.0000003e-05, 4.0000003e-05, 4.0000003e-05, 4.0000003e-05, 4.0000003e-05, 4.0000003e-05, 4.0000003e-05, 8.000001e-06, 8.000001e-06, 8.000001e-06, 8.000001e-06, 8.000001e-06, 8.000001e-06, 8.000001e-06, 8.000001e-06, 8.000001e-06, 8.000001e-06, 1.6000001e-06, 1.6000001e-06, 1.6000001e-06, 1.6000001e-06, 1.6000001e-06, 1.6000001e-06, 1.6000001e-06, 1.6000001e-06, 1.6000001e-06, 1.6000001e-06, 3.2000003e-07, 3.2000003e-07, 3.2000003e-07, 3.2000003e-07, 3.2000003e-07, 3.2000003e-07, 3.2000003e-07, 3.2000003e-07, 3.2000003e-07, 3.2000003e-07, 6.4000005e-08, 6.4000005e-08, 6.4000005e-08, 6.4000005e-08, 6.4000005e-08, 6.4000005e-08, 6.4000005e-08, 6.4000005e-08, 6.4000005e-08, 6.4000005e-08, 1.2800001e-08, 1.2800001e-08, 1.2800001e-08, 1.2800001e-08, 1.2800001e-08, 1.2800001e-08, 1.2800001e-08, 1.2800001e-08, 1.2800001e-08, 1.2800001e-08, 2.5600002e-09, 2.5600002e-09, 2.5600002e-09, 2.5600002e-09, 2.5600002e-09, 2.5600002e-09, 2.5600002e-09, 2.5600002e-09, 2.5600002e-09, 2.5600002e-09, 5.1200005e-10, 5.1200005e-10, 5.1200005e-10, 5.1200005e-10, 5.1200005e-10, 5.1200005e-10, 5.1200005e-10, 5.1200005e-10, 5.1200005e-10, 5.1200005e-10, 1.0240001e-10, 1.0240001e-10, 1.0240001e-10, 1.0240001e-10, 1.0240001e-10, 1.0240001e-10, 1.0240001e-10, 1.0240001e-10, 1.0240001e-10, 1.0240001e-10, 2.0480003e-11, 2.0480003e-11, 2.0480003e-11, 2.0480003e-11, 2.0480003e-11, 2.0480003e-11, 2.0480003e-11, 2.0480003e-11, 2.0480003e-11, 2.0480003e-11, 4.0960004e-12, 4.0960004e-12, 4.0960004e-12, 4.0960004e-12, 4.0960004e-12, 4.0960004e-12, 4.0960004e-12, 4.0960004e-12, 4.0960004e-12, 4.0960004e-12, 8.1920007e-13, 8.1920007e-13, 8.1920007e-13, 8.1920007e-13, 8.1920007e-13, 8.1920007e-13, 8.1920007e-13, 8.1920007e-13, 8.1920007e-13, 8.1920007e-13, 1.6384001e-13, 1.6384001e-13, 1.6384001e-13, 1.6384001e-13, 1.6384001e-13, 1.6384001e-13, 1.6384001e-13, 1.6384001e-13, 1.6384001e-13, 1.6384001e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13, 1e-13]};0.5\".count(\";\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM=\"lstm\"\n",
    "ELMAN_RNN=\"elman\"\n",
    "JORDAN_RNN=\"jordan\"\n",
    "GRU=\"gru\"\n",
    "BIDIRECTIONAL_RNN=\"bidirelamn\"\n",
    "BIDIRECTIONAL_LSTM=\"bidirlstm\"\n",
    "BIDIRECTIONAL_GRU=\"bidirgru\"\n",
    "\n",
    "def determine_model_parameters(row):\n",
    "    nodes_in_layers = eval(row[\"nodes_in_layer\"])\n",
    "    nn_type = row[\"nn_type\"]\n",
    "    if nn_type == BIDIRECTIONAL_RNN:\n",
    "        return sum(nodes_in_layers) * 6\n",
    "    if nn_type == BIDIRECTIONAL_GRU:\n",
    "        return sum(nodes_in_layers) * 21\n",
    "    if nn_type == BIDIRECTIONAL_LSTM:\n",
    "        return sum(nodes_in_layers) * 24\n",
    "    if nn_type == LSTM:\n",
    "        return sum(nodes_in_layers) *12\n",
    "    if nn_type == GRU:\n",
    "        return sum(nodes_in_layers) *9\n",
    "    return sum(nodes_in_layers) * 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T06:25:32.380301Z",
     "start_time": "2018-11-16T06:25:32.028455Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nn_type</th>\n",
       "      <th>activation_func</th>\n",
       "      <th>parameters</th>\n",
       "      <th>nodes_in_layer</th>\n",
       "      <th>largest_retained</th>\n",
       "      <th>smallest_not_retained</th>\n",
       "      <th>model_params</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>model_score</th>\n",
       "      <th>highest_F1</th>\n",
       "      <th>diff_small_large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstm</td>\n",
       "      <td>elu</td>\n",
       "      <td>504</td>\n",
       "      <td>[42]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.4946219176054001, 0.2408708184...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lstm</td>\n",
       "      <td>selu</td>\n",
       "      <td>504</td>\n",
       "      <td>[42]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>504</td>\n",
       "      <td>7</td>\n",
       "      <td>{'val_loss': [0.0819605402648449, 0.0693724751...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softplus</td>\n",
       "      <td>504</td>\n",
       "      <td>[42]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.20116198807954788, 0.206449702...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softsign</td>\n",
       "      <td>504</td>\n",
       "      <td>[42]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.40316881239414215, 0.251443207...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lstm</td>\n",
       "      <td>tanh</td>\n",
       "      <td>504</td>\n",
       "      <td>[42]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>504</td>\n",
       "      <td>44</td>\n",
       "      <td>{'val_loss': [0.3318553566932678, 0.1949969530...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>lstm</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[42]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.08133256807923317, 0.071514669...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lstm</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[42]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.07580393180251122, 0.075959742...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>lstm</td>\n",
       "      <td>relu</td>\n",
       "      <td>504</td>\n",
       "      <td>[42]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.25778841227293015, 0.227367028...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lstm</td>\n",
       "      <td>linear</td>\n",
       "      <td>504</td>\n",
       "      <td>[42]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.3624194860458374, 0.1538776010...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>gru</td>\n",
       "      <td>softmax</td>\n",
       "      <td>504</td>\n",
       "      <td>[56]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5448723286390305, 0.5204579234...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>gru</td>\n",
       "      <td>elu</td>\n",
       "      <td>504</td>\n",
       "      <td>[56]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.4465404450893402, 0.2424310073...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>gru</td>\n",
       "      <td>selu</td>\n",
       "      <td>504</td>\n",
       "      <td>[56]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.3945378214120865, 0.0874072089...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>gru</td>\n",
       "      <td>softplus</td>\n",
       "      <td>504</td>\n",
       "      <td>[56]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5819623172283173, 0.0856886133...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>gru</td>\n",
       "      <td>softsign</td>\n",
       "      <td>504</td>\n",
       "      <td>[56]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.36055484414100647, 0.208033062...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>gru</td>\n",
       "      <td>tanh</td>\n",
       "      <td>504</td>\n",
       "      <td>[56]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.4152391701936722, 0.1948228254...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>gru</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[56]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.34265419840812683, 0.085719957...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>gru</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[56]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.26553022116422653, 0.064528800...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>gru</td>\n",
       "      <td>relu</td>\n",
       "      <td>504</td>\n",
       "      <td>[56]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.3832283616065979, 0.2987566590...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>gru</td>\n",
       "      <td>linear</td>\n",
       "      <td>504</td>\n",
       "      <td>[56]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>504</td>\n",
       "      <td>43</td>\n",
       "      <td>{'val_loss': [0.31459513306617737, 0.157367624...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>elman</td>\n",
       "      <td>softmax</td>\n",
       "      <td>504</td>\n",
       "      <td>[168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.7038005292415619, 0.6762956678...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>elman</td>\n",
       "      <td>elu</td>\n",
       "      <td>504</td>\n",
       "      <td>[168]</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>504</td>\n",
       "      <td>35</td>\n",
       "      <td>{'val_loss': [0.01022288529202342, 0.004784897...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>elman</td>\n",
       "      <td>selu</td>\n",
       "      <td>504</td>\n",
       "      <td>[168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>elman</td>\n",
       "      <td>softplus</td>\n",
       "      <td>504</td>\n",
       "      <td>[168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.11724359542131424, 0.067714590...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>elman</td>\n",
       "      <td>softsign</td>\n",
       "      <td>504</td>\n",
       "      <td>[168]</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.0036327834241092205, 0.0023907...</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>elman</td>\n",
       "      <td>tanh</td>\n",
       "      <td>504</td>\n",
       "      <td>[168]</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>504</td>\n",
       "      <td>16</td>\n",
       "      <td>{'val_loss': [0.006719990400597453, 0.00462339...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>elman</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[168]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.09701669961214066, 0.126788254...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>elman</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.08693477883934975, 0.089432314...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>elman</td>\n",
       "      <td>relu</td>\n",
       "      <td>504</td>\n",
       "      <td>[168]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>504</td>\n",
       "      <td>26</td>\n",
       "      <td>{'val_loss': [0.21049391478300095, 0.160464845...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>elman</td>\n",
       "      <td>linear</td>\n",
       "      <td>504</td>\n",
       "      <td>[168]</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.07618581131100655, 0.023449786...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softmax</td>\n",
       "      <td>504</td>\n",
       "      <td>[84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5991988778114319, 0.5611424148...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>elu</td>\n",
       "      <td>504</td>\n",
       "      <td>[84]</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.038599710911512375, 0.00683762...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>selu</td>\n",
       "      <td>504</td>\n",
       "      <td>[84]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softplus</td>\n",
       "      <td>504</td>\n",
       "      <td>[84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.11677606776356697, 0.247338593...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softsign</td>\n",
       "      <td>504</td>\n",
       "      <td>[84]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.05220537260174751, 0.007052829...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>tanh</td>\n",
       "      <td>504</td>\n",
       "      <td>[84]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>504</td>\n",
       "      <td>16</td>\n",
       "      <td>{'val_loss': [0.0015075012343004346, 0.0012468...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.09947529435157776, 0.067808486...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[84]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.09018612280488014, 0.084832493...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>relu</td>\n",
       "      <td>504</td>\n",
       "      <td>[84]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>504</td>\n",
       "      <td>16</td>\n",
       "      <td>{'val_loss': [0.2869787886738777, 0.1159043312...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>linear</td>\n",
       "      <td>504</td>\n",
       "      <td>[84]</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>504</td>\n",
       "      <td>26</td>\n",
       "      <td>{'val_loss': [0.04190049506723881, 0.013597493...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softmax</td>\n",
       "      <td>504</td>\n",
       "      <td>[21]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.663487434387207, 0.63724201917...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>elu</td>\n",
       "      <td>504</td>\n",
       "      <td>[21]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.37372808158397675, 0.234386362...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>selu</td>\n",
       "      <td>504</td>\n",
       "      <td>[21]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>504</td>\n",
       "      <td>20</td>\n",
       "      <td>{'val_loss': [0.08483178168535233, 0.083788037...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softplus</td>\n",
       "      <td>504</td>\n",
       "      <td>[21]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [1.1596860885620117, 0.6694509088...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softsign</td>\n",
       "      <td>504</td>\n",
       "      <td>[21]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>504</td>\n",
       "      <td>26</td>\n",
       "      <td>{'val_loss': [0.38953451812267303, 0.287065491...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>tanh</td>\n",
       "      <td>504</td>\n",
       "      <td>[21]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>504</td>\n",
       "      <td>21</td>\n",
       "      <td>{'val_loss': [0.36916880309581757, 0.244283460...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[21]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.08764307200908661, 0.093582563...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[21]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.06540227681398392, 0.072437830...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>relu</td>\n",
       "      <td>504</td>\n",
       "      <td>[21]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5630137622356415, 0.5116415321...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>linear</td>\n",
       "      <td>504</td>\n",
       "      <td>[21]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>504</td>\n",
       "      <td>24</td>\n",
       "      <td>{'val_loss': [0.3195510804653168, 0.2121522054...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softmax</td>\n",
       "      <td>504</td>\n",
       "      <td>[24]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5863576531410217, 0.5471096634...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>elu</td>\n",
       "      <td>504</td>\n",
       "      <td>[24]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.21432245522737503, 0.148047141...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>selu</td>\n",
       "      <td>504</td>\n",
       "      <td>[24]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>504</td>\n",
       "      <td>42</td>\n",
       "      <td>{'val_loss': [0.16468828171491623, 0.084260262...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softplus</td>\n",
       "      <td>504</td>\n",
       "      <td>[24]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.14249546825885773, 0.081475466...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softsign</td>\n",
       "      <td>504</td>\n",
       "      <td>[24]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.23640096187591553, 0.172316953...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>tanh</td>\n",
       "      <td>504</td>\n",
       "      <td>[24]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.22417141497135162, 0.159498237...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[24]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [1.2608646154403687, 0.6526324152...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[24]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.062262656167149544, 0.06187883...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>relu</td>\n",
       "      <td>504</td>\n",
       "      <td>[24]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>504</td>\n",
       "      <td>32</td>\n",
       "      <td>{'val_loss': [0.3938422203063965, 0.3493473976...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>linear</td>\n",
       "      <td>504</td>\n",
       "      <td>[24]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.39541734755039215, 0.286482445...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1008</td>\n",
       "      <td>[84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5860611498355865, 0.5686147511...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>lstm</td>\n",
       "      <td>elu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.3213348537683487, 0.0622036941...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>lstm</td>\n",
       "      <td>selu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[84]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.082134660333395, 0.07523649185...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1008</td>\n",
       "      <td>[84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [268828656.0, 2638.9259033203125,...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softsign</td>\n",
       "      <td>1008</td>\n",
       "      <td>[84]</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.12340161576867104, 0.087142843...</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>lstm</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1008</td>\n",
       "      <td>[84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.4119742661714554, 0.0623351633...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>lstm</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1008</td>\n",
       "      <td>[84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.24947072565555573, 0.177885144...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>lstm</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>1008</td>\n",
       "      <td>[84]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.08953189849853516, 0.084065947...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>lstm</td>\n",
       "      <td>relu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[84]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.28199198842048645, 0.172666959...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>lstm</td>\n",
       "      <td>linear</td>\n",
       "      <td>1008</td>\n",
       "      <td>[84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5073779076337814, 0.1312993690...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>gru</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1008</td>\n",
       "      <td>[112]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.4611859917640686, 0.4403687864...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>gru</td>\n",
       "      <td>elu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[112]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1008</td>\n",
       "      <td>57</td>\n",
       "      <td>{'val_loss': [0.15789251774549484, 0.100181289...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>gru</td>\n",
       "      <td>selu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[112]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.2656393200159073, 0.0625933408...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>gru</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1008</td>\n",
       "      <td>[112]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.19934426248073578, 0.164807543...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>gru</td>\n",
       "      <td>softsign</td>\n",
       "      <td>1008</td>\n",
       "      <td>[112]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.1598307117819786, 0.1143907159...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>gru</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1008</td>\n",
       "      <td>[112]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.36135047674179077, 0.153671763...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>gru</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1008</td>\n",
       "      <td>[112]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.18420275300741196, 0.219889968...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>gru</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>1008</td>\n",
       "      <td>[112]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.09764796495437622, 0.106708198...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>gru</td>\n",
       "      <td>relu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[112]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.2867846190929413, 0.2018932849...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>gru</td>\n",
       "      <td>linear</td>\n",
       "      <td>1008</td>\n",
       "      <td>[112]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1008</td>\n",
       "      <td>13</td>\n",
       "      <td>{'val_loss': [0.3135805055499077, 0.1072222068...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>elman</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1008</td>\n",
       "      <td>[336]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5816648006439209, 0.5579436123...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>elman</td>\n",
       "      <td>elu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[336]</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.020651287399232388, 0.02092381...</td>\n",
       "      <td>0.463636</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>elman</td>\n",
       "      <td>selu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[336]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1008</td>\n",
       "      <td>111</td>\n",
       "      <td>{'val_loss': [5.416930913925171, 6.54799103736...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>elman</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1008</td>\n",
       "      <td>[336]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.06226687505841255, 0.085654135...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>elman</td>\n",
       "      <td>softsign</td>\n",
       "      <td>1008</td>\n",
       "      <td>[336]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.19459501653909683, 0.090871986...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>elman</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1008</td>\n",
       "      <td>[336]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.19768443703651428, 0.112147681...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>elman</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1008</td>\n",
       "      <td>[336]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.31805236637592316, 0.123786017...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>elman</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>1008</td>\n",
       "      <td>[336]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.1331797093153, 0.2433587089180...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>elman</td>\n",
       "      <td>relu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[336]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1008</td>\n",
       "      <td>27</td>\n",
       "      <td>{'val_loss': [0.19364318996667862, 0.281179100...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>elman</td>\n",
       "      <td>linear</td>\n",
       "      <td>1008</td>\n",
       "      <td>[336]</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1008</td>\n",
       "      <td>25</td>\n",
       "      <td>{'val_loss': [0.10409671068191528, 0.011606377...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1008</td>\n",
       "      <td>[168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5831093788146973, 0.5467988848...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>elu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[168]</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1008</td>\n",
       "      <td>7</td>\n",
       "      <td>{'val_loss': [0.00752157554961741, 0.002374779...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>selu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1008</td>\n",
       "      <td>[168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.38378164172172546, 0.167550429...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softsign</td>\n",
       "      <td>1008</td>\n",
       "      <td>[168]</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1008</td>\n",
       "      <td>20</td>\n",
       "      <td>{'val_loss': [0.11835330352187157, 0.016519774...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1008</td>\n",
       "      <td>[168]</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.013515153899788857, 0.00489697...</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1008</td>\n",
       "      <td>[168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.07628345862030983, 0.075613573...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>1008</td>\n",
       "      <td>[168]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.08203767612576485, 0.081810921...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>relu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[168]</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>1008</td>\n",
       "      <td>26</td>\n",
       "      <td>{'val_loss': [0.08343203365802765, 0.061957057...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>linear</td>\n",
       "      <td>1008</td>\n",
       "      <td>[168]</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1008</td>\n",
       "      <td>10</td>\n",
       "      <td>{'val_loss': [0.031909072771668434, 0.01060177...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1008</td>\n",
       "      <td>[42]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5742955207824707, 0.5506151318...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>elu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[42]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.19192027300596237, 0.080607317...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>selu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[42]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1008</td>\n",
       "      <td>14</td>\n",
       "      <td>{'val_loss': [0.08378606662154198, 0.045127406...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1008</td>\n",
       "      <td>[42]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [1.956240952014923, 1.18634587526...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softsign</td>\n",
       "      <td>1008</td>\n",
       "      <td>[42]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1008</td>\n",
       "      <td>34</td>\n",
       "      <td>{'val_loss': [0.3328246772289276, 0.1508720666...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1008</td>\n",
       "      <td>[42]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1008</td>\n",
       "      <td>41</td>\n",
       "      <td>{'val_loss': [0.23154982924461365, 0.099558405...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1008</td>\n",
       "      <td>[42]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.08095728978514671, 0.079912036...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>1008</td>\n",
       "      <td>[42]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.090056411921978, 0.06298577971...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>relu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[42]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1008</td>\n",
       "      <td>23</td>\n",
       "      <td>{'val_loss': [0.4220045804977417, 0.3409764468...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>linear</td>\n",
       "      <td>1008</td>\n",
       "      <td>[42]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1008</td>\n",
       "      <td>25</td>\n",
       "      <td>{'val_loss': [0.35160012543201447, 0.162914074...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1008</td>\n",
       "      <td>[48]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.52736896276474, 0.491251945495...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>elu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[48]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.1889338567852974, 0.0947050563...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>selu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[48]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1008</td>\n",
       "      <td>23</td>\n",
       "      <td>{'val_loss': [0.1820697784423828, 0.0868976265...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1008</td>\n",
       "      <td>[48]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.17352259159088135, 0.250410512...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softsign</td>\n",
       "      <td>1008</td>\n",
       "      <td>[48]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.4706859290599823, 0.2493391856...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1008</td>\n",
       "      <td>[48]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.48316994309425354, 0.220022402...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1008</td>\n",
       "      <td>[48]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.08081924915313721, 0.081035375...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>1008</td>\n",
       "      <td>[48]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.0731609147042036, 0.0796012505...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>relu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[48]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.2339080199599266, 0.1816009655...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>linear</td>\n",
       "      <td>1008</td>\n",
       "      <td>[48]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1008</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.523583322763443, 0.26535367965...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1512</td>\n",
       "      <td>[126]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.7079771757125854, 0.6884715557...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>lstm</td>\n",
       "      <td>elu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[126]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.12273064255714417, 0.133944019...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>lstm</td>\n",
       "      <td>selu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[126]</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.06311207823455334, 0.056659523...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1512</td>\n",
       "      <td>[126]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.07627357542514801, 0.069885056...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softsign</td>\n",
       "      <td>1512</td>\n",
       "      <td>[126]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.11888939514756203, 0.075811943...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>lstm</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1512</td>\n",
       "      <td>[126]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1512</td>\n",
       "      <td>14</td>\n",
       "      <td>{'val_loss': [0.21564581245183945, 0.128354802...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>lstm</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1512</td>\n",
       "      <td>[126]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.0816057026386261, 0.0817841328...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>lstm</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>1512</td>\n",
       "      <td>[126]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.14025737345218658, 0.084550738...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>lstm</td>\n",
       "      <td>relu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[126]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1512</td>\n",
       "      <td>27</td>\n",
       "      <td>{'val_loss': [0.29207732528448105, 0.065406829...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>lstm</td>\n",
       "      <td>linear</td>\n",
       "      <td>1512</td>\n",
       "      <td>[126]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.2260839343070984, 0.1597735956...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>gru</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1512</td>\n",
       "      <td>[168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.55178302526474, 0.528354778885...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>gru</td>\n",
       "      <td>elu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.24351449310779572, 0.062652064...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>gru</td>\n",
       "      <td>selu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[168]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1512</td>\n",
       "      <td>21</td>\n",
       "      <td>{'val_loss': [0.07909475639462471, 0.078506682...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>gru</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1512</td>\n",
       "      <td>[168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.09527260810136795, 0.064762115...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>gru</td>\n",
       "      <td>softsign</td>\n",
       "      <td>1512</td>\n",
       "      <td>[168]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1512</td>\n",
       "      <td>19</td>\n",
       "      <td>{'val_loss': [0.15457211807370186, 0.074653293...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>gru</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1512</td>\n",
       "      <td>[168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.2985825389623642, 0.0906578712...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>gru</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1512</td>\n",
       "      <td>[168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.3303014785051346, 0.0683123171...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>gru</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>1512</td>\n",
       "      <td>[168]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.18618952482938766, 0.086407568...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>gru</td>\n",
       "      <td>relu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[168]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.19655141234397888, 0.089618325...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>gru</td>\n",
       "      <td>linear</td>\n",
       "      <td>1512</td>\n",
       "      <td>[168]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1512</td>\n",
       "      <td>44</td>\n",
       "      <td>{'val_loss': [0.15859699994325638, 0.082411210...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>elman</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1512</td>\n",
       "      <td>[504]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.6385711133480072, 0.6138663291...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>elman</td>\n",
       "      <td>elu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[504]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5868909955024719, 0.0408654585...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>elman</td>\n",
       "      <td>selu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[504]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.21002423763275146, 3.544219255...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>elman</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1512</td>\n",
       "      <td>[504]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.14464852958917618, 1.424128174...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>elman</td>\n",
       "      <td>softsign</td>\n",
       "      <td>1512</td>\n",
       "      <td>[504]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.60403011739254, 2.137657582759...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>elman</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1512</td>\n",
       "      <td>[504]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1512</td>\n",
       "      <td>32</td>\n",
       "      <td>{'val_loss': [0.4077098071575165, 0.3493980020...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>elman</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1512</td>\n",
       "      <td>[504]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.36824576556682587, 0.426040157...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>elman</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>1512</td>\n",
       "      <td>[504]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.10015429183840752, 0.236748464...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>elman</td>\n",
       "      <td>relu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[504]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1512</td>\n",
       "      <td>23</td>\n",
       "      <td>{'val_loss': [0.23025226593017578, 0.223041549...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>elman</td>\n",
       "      <td>linear</td>\n",
       "      <td>1512</td>\n",
       "      <td>[504]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1512</td>\n",
       "      <td>7</td>\n",
       "      <td>{'val_loss': [0.5303019285202026, 0.1517066881...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1512</td>\n",
       "      <td>[252]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.6727247834205627, 0.6337536573...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>elu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[252]</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1512</td>\n",
       "      <td>20</td>\n",
       "      <td>{'val_loss': [0.015925960149616003, 0.00527865...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>selu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[252]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [5.224201202392578, 1.22818577289...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1512</td>\n",
       "      <td>[252]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.33148498833179474, 0.088401209...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softsign</td>\n",
       "      <td>1512</td>\n",
       "      <td>[252]</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.006480877287685871, 0.00360835...</td>\n",
       "      <td>0.718182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1512</td>\n",
       "      <td>[252]</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5083888918161392, 1.3063552975...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1512</td>\n",
       "      <td>[252]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.33735139667987823, 0.135450154...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>1512</td>\n",
       "      <td>[252]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.1081976555287838, 0.0705663934...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>relu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[252]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1512</td>\n",
       "      <td>14</td>\n",
       "      <td>{'val_loss': [0.35353904962539673, 9.345939636...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>linear</td>\n",
       "      <td>1512</td>\n",
       "      <td>[252]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1512</td>\n",
       "      <td>7</td>\n",
       "      <td>{'val_loss': [0.0900944322347641, 0.0164098795...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1512</td>\n",
       "      <td>[63]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5915727019309998, 0.5678694546...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>elu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[63]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1512</td>\n",
       "      <td>14</td>\n",
       "      <td>{'val_loss': [0.33732305467128754, 0.094319980...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>selu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[63]</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.05769358202815056, 0.057522859...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1512</td>\n",
       "      <td>[63]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.1571088656783104, 0.2060238346...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softsign</td>\n",
       "      <td>1512</td>\n",
       "      <td>[63]</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.11059226095676422, 0.094340045...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1512</td>\n",
       "      <td>[63]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1512</td>\n",
       "      <td>13</td>\n",
       "      <td>{'val_loss': [0.257699191570282, 0.11426969245...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1512</td>\n",
       "      <td>[63]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.2906939685344696, 0.1470634713...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>1512</td>\n",
       "      <td>[63]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.10220537707209587, 0.085428446...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>relu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[63]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1512</td>\n",
       "      <td>36</td>\n",
       "      <td>{'val_loss': [0.38034193217754364, 0.239430114...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>linear</td>\n",
       "      <td>1512</td>\n",
       "      <td>[63]</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.14405367150902748, 0.098101798...</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1512</td>\n",
       "      <td>[72]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.555176854133606, 0.51963733136...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>elu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[72]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.3632999509572983, 0.1286262869...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>selu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[72]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.12293258681893349, 0.091081894...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1512</td>\n",
       "      <td>[72]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.0650656707584858, 0.0627639796...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softsign</td>\n",
       "      <td>1512</td>\n",
       "      <td>[72]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.4623904675245285, 0.1463238522...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1512</td>\n",
       "      <td>[72]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.17595795542001724, 0.066540349...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1512</td>\n",
       "      <td>[72]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1512</td>\n",
       "      <td>81</td>\n",
       "      <td>{'val_loss': [0.11252160742878914, 0.090491417...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>1512</td>\n",
       "      <td>[72]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1512</td>\n",
       "      <td>83</td>\n",
       "      <td>{'val_loss': [0.10815582796931267, 0.101258069...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>relu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[72]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1512</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5921664535999298, 0.4735741168...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>linear</td>\n",
       "      <td>1512</td>\n",
       "      <td>[72]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1512</td>\n",
       "      <td>43</td>\n",
       "      <td>{'val_loss': [0.13811229169368744, 0.076083686...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softmax</td>\n",
       "      <td>2016</td>\n",
       "      <td>[168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5310638248920441, 0.5145939588...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>lstm</td>\n",
       "      <td>elu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.25635115802288055, 0.112963806...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>lstm</td>\n",
       "      <td>selu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.12132997810840607, 0.098686829...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softplus</td>\n",
       "      <td>2016</td>\n",
       "      <td>[168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softsign</td>\n",
       "      <td>2016</td>\n",
       "      <td>[168]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>34</td>\n",
       "      <td>{'val_loss': [0.08660119771957397, 0.101037941...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>lstm</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2016</td>\n",
       "      <td>[168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.16473206132650375, 0.067782949...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>lstm</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>2016</td>\n",
       "      <td>[168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.11378348618745804, 0.121088098...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>lstm</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>2016</td>\n",
       "      <td>[168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.09497181326150894, 0.097594346...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>lstm</td>\n",
       "      <td>relu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.4853818565607071, 0.2198217511...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>lstm</td>\n",
       "      <td>linear</td>\n",
       "      <td>2016</td>\n",
       "      <td>[168]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.8070533573627472, 0.2166182845...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>gru</td>\n",
       "      <td>softmax</td>\n",
       "      <td>2016</td>\n",
       "      <td>[224]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5738425850868225, 0.5500681102...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>gru</td>\n",
       "      <td>elu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[224]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.12236658483743668, 0.080177463...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>gru</td>\n",
       "      <td>selu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[224]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.10072934255003929, 0.178373135...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>gru</td>\n",
       "      <td>softplus</td>\n",
       "      <td>2016</td>\n",
       "      <td>[224]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.366757869720459, 0.15220645070...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>gru</td>\n",
       "      <td>softsign</td>\n",
       "      <td>2016</td>\n",
       "      <td>[224]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.10945373773574829, 0.106763426...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>gru</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2016</td>\n",
       "      <td>[224]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.12065264582633972, 0.090794235...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>gru</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>2016</td>\n",
       "      <td>[224]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.43898291885852814, 0.135307580...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>gru</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>2016</td>\n",
       "      <td>[224]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.1364227756857872, 0.1014339849...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>gru</td>\n",
       "      <td>relu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[224]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5105425715446472, 0.0659330114...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>gru</td>\n",
       "      <td>linear</td>\n",
       "      <td>2016</td>\n",
       "      <td>[224]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.07688941434025764, 0.091145664...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>elman</td>\n",
       "      <td>softmax</td>\n",
       "      <td>2016</td>\n",
       "      <td>[672]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5403292775154114, 0.5178883969...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>elman</td>\n",
       "      <td>elu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[672]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.7729886770248413, 2.8914053440...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>elman</td>\n",
       "      <td>selu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[672]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [3.69827401638031, 0.522785633802...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>elman</td>\n",
       "      <td>softplus</td>\n",
       "      <td>2016</td>\n",
       "      <td>[672]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [1.2315192222595215, 2.0352772474...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>elman</td>\n",
       "      <td>softsign</td>\n",
       "      <td>2016</td>\n",
       "      <td>[672]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.08825328573584557, 0.266041800...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>elman</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2016</td>\n",
       "      <td>[672]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.18953587114810944, 0.084268633...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>elman</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>2016</td>\n",
       "      <td>[672]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.7230202555656433, 0.6256767511...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>elman</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>2016</td>\n",
       "      <td>[672]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.44950659573078156, 0.591275930...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>elman</td>\n",
       "      <td>relu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[672]</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.061833128333091736, 0.04938700...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>elman</td>\n",
       "      <td>linear</td>\n",
       "      <td>2016</td>\n",
       "      <td>[672]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>{'val_loss': [0.015212945640087128, 0.01460808...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softmax</td>\n",
       "      <td>2016</td>\n",
       "      <td>[336]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5613326728343964, 0.5266576111...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>selu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[336]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softplus</td>\n",
       "      <td>2016</td>\n",
       "      <td>[336]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.07410337775945663, 0.074415724...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>elu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[336]</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>{'val_loss': [0.05427826754748821, 0.007906206...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softsign</td>\n",
       "      <td>2016</td>\n",
       "      <td>[336]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>13</td>\n",
       "      <td>{'val_loss': [0.04462978430092335, 0.028002463...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>2016</td>\n",
       "      <td>[336]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5871401727199554, 0.3280586153...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2016</td>\n",
       "      <td>[336]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>30</td>\n",
       "      <td>{'val_loss': [0.29632212221622467, 0.050634915...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>2016</td>\n",
       "      <td>[336]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.4878322333097458, 0.0719946511...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>relu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[336]</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.08910251781344414, 0.072274720...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>linear</td>\n",
       "      <td>2016</td>\n",
       "      <td>[336]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>19</td>\n",
       "      <td>{'val_loss': [0.1273687407374382, 0.0232365578...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softmax</td>\n",
       "      <td>2016</td>\n",
       "      <td>[84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5862846374511719, 0.5628803968...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>selu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[84]</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>{'val_loss': [0.08488580211997032, 0.065190382...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>elu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[84]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>48</td>\n",
       "      <td>{'val_loss': [0.11712664738297462, 0.080607995...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softplus</td>\n",
       "      <td>2016</td>\n",
       "      <td>[84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [4746356.25, 26787851.0, nan, nan...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softsign</td>\n",
       "      <td>2016</td>\n",
       "      <td>[84]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>24</td>\n",
       "      <td>{'val_loss': [0.26589587330818176, 0.122616596...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>2016</td>\n",
       "      <td>[84]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.0991985835134983, 0.0838311053...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2016</td>\n",
       "      <td>[84]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.11625007167458534, 0.088152725...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>2016</td>\n",
       "      <td>[84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.1918892338871956, 0.0804009027...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>linear</td>\n",
       "      <td>2016</td>\n",
       "      <td>[84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.38908204436302185, 0.140204340...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softmax</td>\n",
       "      <td>2016</td>\n",
       "      <td>[96]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5315047353506088, 0.4967368692...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>relu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[84]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.3540915548801422, 0.2288026511...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>selu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[96]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.19112471491098404, 0.062748592...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>elu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[96]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.14729488641023636, 0.101810671...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softplus</td>\n",
       "      <td>2016</td>\n",
       "      <td>[96]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>102</td>\n",
       "      <td>{'val_loss': [0.31372465193271637, 0.543935537...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softsign</td>\n",
       "      <td>2016</td>\n",
       "      <td>[96]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>20</td>\n",
       "      <td>{'val_loss': [0.21943537890911102, 0.099840700...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>2016</td>\n",
       "      <td>[96]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.15585985779762268, 0.066754486...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2016</td>\n",
       "      <td>[96]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>31</td>\n",
       "      <td>{'val_loss': [0.1623019203543663, 0.1118274591...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>relu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[96]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>19</td>\n",
       "      <td>{'val_loss': [0.33869603276252747, 0.202489979...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>2016</td>\n",
       "      <td>[96]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.08537391945719719, 0.085241772...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softmax</td>\n",
       "      <td>2520</td>\n",
       "      <td>[210]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2520</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.624767541885376, 0.60677421092...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>linear</td>\n",
       "      <td>2016</td>\n",
       "      <td>[96]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.1515767052769661, 0.1162242256...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>lstm</td>\n",
       "      <td>elu</td>\n",
       "      <td>2520</td>\n",
       "      <td>[210]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2520</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.06147446669638157, 0.119858343...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softplus</td>\n",
       "      <td>2520</td>\n",
       "      <td>[210]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2520</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>lstm</td>\n",
       "      <td>selu</td>\n",
       "      <td>2520</td>\n",
       "      <td>[210]</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2520</td>\n",
       "      <td>21</td>\n",
       "      <td>{'val_loss': [0.08853099122643471, 0.069400615...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softsign</td>\n",
       "      <td>2520</td>\n",
       "      <td>[210]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2520</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.12820779532194138, 0.156860418...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>lstm</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>2520</td>\n",
       "      <td>[210]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2520</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.15856315195560455, 0.138273537...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>lstm</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2520</td>\n",
       "      <td>[210]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2520</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.11786993965506554, 0.440768748...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>lstm</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>2520</td>\n",
       "      <td>[210]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2520</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.160988487303257, 0.13620035722...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>lstm</td>\n",
       "      <td>linear</td>\n",
       "      <td>2520</td>\n",
       "      <td>[210]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2520</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.07479841262102127, 0.419018417...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>lstm</td>\n",
       "      <td>relu</td>\n",
       "      <td>2520</td>\n",
       "      <td>[210]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2520</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.3286455124616623, 0.0831447616...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>gru</td>\n",
       "      <td>softmax</td>\n",
       "      <td>2520</td>\n",
       "      <td>[280]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2520</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.6408434212207794, 0.6159963011...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softplus</td>\n",
       "      <td>504</td>\n",
       "      <td>[840, 84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.6966229975223541, 0.7000716626...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softsign</td>\n",
       "      <td>504</td>\n",
       "      <td>[840, 84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.18096768110990524, 0.215132914...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[840, 84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.12306655198335648, 0.092874780...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>tanh</td>\n",
       "      <td>504</td>\n",
       "      <td>[840, 84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [3.3048731088638306, 0.5179111212...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>relu</td>\n",
       "      <td>504</td>\n",
       "      <td>[840, 84]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5544</td>\n",
       "      <td>32</td>\n",
       "      <td>{'val_loss': [0.3678734302520752, 0.3776267766...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[840, 84]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.48851917684078217, 0.885215461...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>linear</td>\n",
       "      <td>504</td>\n",
       "      <td>[840, 84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [14.296613693237305, 43.580410003...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softmax</td>\n",
       "      <td>504</td>\n",
       "      <td>[210, 21]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5020935088396072, 0.4786742031...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>elu</td>\n",
       "      <td>504</td>\n",
       "      <td>[210, 21]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.14650917053222656, 0.228505104...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softplus</td>\n",
       "      <td>504</td>\n",
       "      <td>[210, 21]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>selu</td>\n",
       "      <td>504</td>\n",
       "      <td>[210, 21]</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.056628936901688576, 0.05869577...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softsign</td>\n",
       "      <td>504</td>\n",
       "      <td>[210, 21]</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.07241494208574295, 0.046022083...</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[210, 21]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.21714766323566437, 0.124829865...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>tanh</td>\n",
       "      <td>504</td>\n",
       "      <td>[210, 21]</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.07277422025799751, 0.060436032...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[210, 21]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.08768287301063538, 0.064077872...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[210, 21]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.15714696049690247, 0.092264004...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>relu</td>\n",
       "      <td>504</td>\n",
       "      <td>[210, 21]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.36303824186325073, 0.151833266...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softmax</td>\n",
       "      <td>504</td>\n",
       "      <td>[240, 24]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.45490314066410065, 0.415591105...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>linear</td>\n",
       "      <td>504</td>\n",
       "      <td>[210, 21]</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.07830138131976128, 0.068730324...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>elu</td>\n",
       "      <td>504</td>\n",
       "      <td>[240, 24]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5544</td>\n",
       "      <td>9</td>\n",
       "      <td>{'val_loss': [0.14139603078365326, 0.124228831...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softplus</td>\n",
       "      <td>504</td>\n",
       "      <td>[240, 24]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5270393788814545, 0.1848405227...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>selu</td>\n",
       "      <td>504</td>\n",
       "      <td>[240, 24]</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5544</td>\n",
       "      <td>44</td>\n",
       "      <td>{'val_loss': [0.07983892410993576, 0.052296468...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softsign</td>\n",
       "      <td>504</td>\n",
       "      <td>[240, 24]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5544</td>\n",
       "      <td>11</td>\n",
       "      <td>{'val_loss': [0.10343407094478607, 0.061098249...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[240, 24]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.07101438567042351, 0.064784955...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[240, 24]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.12143271416425705, 0.112146645...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>tanh</td>\n",
       "      <td>504</td>\n",
       "      <td>[240, 24]</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.09674326330423355, 0.084594491...</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>relu</td>\n",
       "      <td>504</td>\n",
       "      <td>[240, 24]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5544</td>\n",
       "      <td>19</td>\n",
       "      <td>{'val_loss': [0.13548076152801514, 0.099030070...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1008</td>\n",
       "      <td>[420, 84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.6068264245986938, 0.5888428390...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042</th>\n",
       "      <td>lstm</td>\n",
       "      <td>elu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[420, 84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.1187330037355423, 0.0635951720...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>linear</td>\n",
       "      <td>504</td>\n",
       "      <td>[240, 24]</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.07061218097805977, 0.051096862...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051</th>\n",
       "      <td>lstm</td>\n",
       "      <td>selu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[420, 84]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6048</td>\n",
       "      <td>16</td>\n",
       "      <td>{'val_loss': [0.10412943363189697, 0.074244044...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2053</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1008</td>\n",
       "      <td>[420, 84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softsign</td>\n",
       "      <td>1008</td>\n",
       "      <td>[420, 84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.11680077388882637, 0.064519202...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>lstm</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1008</td>\n",
       "      <td>[420, 84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.1260082609951496, 0.0731949545...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>lstm</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1008</td>\n",
       "      <td>[420, 84]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.1954302415251732, 0.0875136386...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064</th>\n",
       "      <td>lstm</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>1008</td>\n",
       "      <td>[420, 84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.06562408804893494, 0.125232353...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>lstm</td>\n",
       "      <td>linear</td>\n",
       "      <td>1008</td>\n",
       "      <td>[420, 84]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.11236365884542465, 0.103507582...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>lstm</td>\n",
       "      <td>relu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[420, 84]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [11.243340492248535, 0.3278637602...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>gru</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1008</td>\n",
       "      <td>[560, 112]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5207083225250244, 0.4966490864...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>gru</td>\n",
       "      <td>elu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[560, 112]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.17723175138235092, 0.344463855...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>gru</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1008</td>\n",
       "      <td>[560, 112]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.11349379643797874, 0.500800535...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2085</th>\n",
       "      <td>gru</td>\n",
       "      <td>softsign</td>\n",
       "      <td>1008</td>\n",
       "      <td>[560, 112]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.14544736593961716, 0.240502096...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087</th>\n",
       "      <td>gru</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1008</td>\n",
       "      <td>[560, 112]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.18071196228265762, 0.296192735...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>gru</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1008</td>\n",
       "      <td>[560, 112]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.19926133751869202, 0.132511824...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2092</th>\n",
       "      <td>gru</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>1008</td>\n",
       "      <td>[560, 112]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.23749250918626785, 0.122110757...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>gru</td>\n",
       "      <td>relu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[560, 112]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.37027251720428467, 0.087137483...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>gru</td>\n",
       "      <td>linear</td>\n",
       "      <td>1008</td>\n",
       "      <td>[560, 112]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.12047366052865982, 0.073414426...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>gru</td>\n",
       "      <td>selu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[560, 112]</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.061819326132535934, 0.06218323...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2102</th>\n",
       "      <td>elman</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1008</td>\n",
       "      <td>[1680, 336]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.6571272313594818, 0.6314687728...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>elman</td>\n",
       "      <td>elu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[1680, 336]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [475.8356628417969, 2.59876072406...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>elman</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1008</td>\n",
       "      <td>[1680, 336]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [30.458255767822266, 6295.1337890...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2111</th>\n",
       "      <td>elman</td>\n",
       "      <td>selu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[1680, 336]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [38.51159477233887, 345.633377075...</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113</th>\n",
       "      <td>elman</td>\n",
       "      <td>softsign</td>\n",
       "      <td>1008</td>\n",
       "      <td>[1680, 336]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5293747186660767, 0.0578305795...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>elman</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1008</td>\n",
       "      <td>[1680, 336]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.1649644449353218, 0.0772733949...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>elman</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1008</td>\n",
       "      <td>[1680, 336]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.16216256469488144, 0.159378886...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2120</th>\n",
       "      <td>elman</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>1008</td>\n",
       "      <td>[1680, 336]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.6222150325775146, 0.9391079246...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>elman</td>\n",
       "      <td>linear</td>\n",
       "      <td>1008</td>\n",
       "      <td>[1680, 336]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1008</td>\n",
       "      <td>[840, 168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5706239342689514, 0.5330109894...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>elman</td>\n",
       "      <td>relu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[1680, 336]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>elu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[840, 168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [55.58534240722656, 2309.71716308...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>selu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[840, 168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1008</td>\n",
       "      <td>[840, 168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [4.576709270477295, 4.18876028060...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1008</td>\n",
       "      <td>[840, 168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [15.524348258972168, 0.0989822000...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softsign</td>\n",
       "      <td>1008</td>\n",
       "      <td>[840, 168]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.18358035385608673, 0.177182152...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1008</td>\n",
       "      <td>[840, 168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [1.349938154220581, 0.36193910241...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>1008</td>\n",
       "      <td>[840, 168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.6198358535766602, 1.4053142070...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>linear</td>\n",
       "      <td>1008</td>\n",
       "      <td>[840, 168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [4.787649631500244, 453.822784423...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1008</td>\n",
       "      <td>[210, 42]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.671904444694519, 0.64560319483...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>elu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[210, 42]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6048</td>\n",
       "      <td>15</td>\n",
       "      <td>{'val_loss': [0.1149747408926487, 0.1343164779...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>selu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[210, 42]</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6048</td>\n",
       "      <td>27</td>\n",
       "      <td>{'val_loss': [0.08483482524752617, 0.044388677...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2165</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1008</td>\n",
       "      <td>[210, 42]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softsign</td>\n",
       "      <td>1008</td>\n",
       "      <td>[210, 42]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6048</td>\n",
       "      <td>20</td>\n",
       "      <td>{'val_loss': [0.11547976732254028, 0.077761843...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2176</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1008</td>\n",
       "      <td>[210, 42]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6048</td>\n",
       "      <td>8</td>\n",
       "      <td>{'val_loss': [0.09921572729945183, 0.111231882...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1008</td>\n",
       "      <td>[210, 42]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.0998789630830288, 0.0897136703...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2180</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>1008</td>\n",
       "      <td>[210, 42]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.06154952198266983, 0.124688014...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2183</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>relu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[210, 42]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.48099716007709503, 0.099537793...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>linear</td>\n",
       "      <td>1008</td>\n",
       "      <td>[210, 42]</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.10198316723108292, 0.083399645...</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1008</td>\n",
       "      <td>[240, 48]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.600701779127121, 0.55793493986...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>elu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[240, 48]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.13975191488862038, 0.067907575...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2202</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>relu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[840, 168]</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.009454482700675726, 0.00280793...</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>selu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[240, 48]</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.05465235933661461, 0.033692337...</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1008</td>\n",
       "      <td>[240, 48]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.47333911061286926, 0.095392327...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softsign</td>\n",
       "      <td>1008</td>\n",
       "      <td>[240, 48]</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.07203998789191246, 0.062921402...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1008</td>\n",
       "      <td>[240, 48]</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.090444166213274, 0.06542074494...</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>1008</td>\n",
       "      <td>[240, 48]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.06618020497262478, 0.067799944...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1008</td>\n",
       "      <td>[240, 48]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.0820370614528656, 0.1000803373...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>relu</td>\n",
       "      <td>1008</td>\n",
       "      <td>[240, 48]</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6048</td>\n",
       "      <td>22</td>\n",
       "      <td>{'val_loss': [0.11357834935188293, 0.086937371...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1512</td>\n",
       "      <td>[420, 126]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.47188612818717957, 0.456277340...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2244</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>linear</td>\n",
       "      <td>1008</td>\n",
       "      <td>[240, 48]</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6048</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.08894367516040802, 0.080607678...</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2248</th>\n",
       "      <td>lstm</td>\n",
       "      <td>elu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[420, 126]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.10369211062788963, 0.063938289...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2251</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1512</td>\n",
       "      <td>[420, 126]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2256</th>\n",
       "      <td>lstm</td>\n",
       "      <td>selu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[420, 126]</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6552</td>\n",
       "      <td>24</td>\n",
       "      <td>{'val_loss': [0.06291420944035053, 0.022522545...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2258</th>\n",
       "      <td>lstm</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1512</td>\n",
       "      <td>[420, 126]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.06750988587737083, 0.086313582...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2262</th>\n",
       "      <td>lstm</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1512</td>\n",
       "      <td>[420, 126]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.17722100764513016, 0.087378371...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2264</th>\n",
       "      <td>lstm</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>1512</td>\n",
       "      <td>[420, 126]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.13087519630789757, 0.111823756...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softsign</td>\n",
       "      <td>1512</td>\n",
       "      <td>[420, 126]</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.07547434791922569, 0.073706272...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>lstm</td>\n",
       "      <td>relu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[420, 126]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.0789199024438858, 0.3463283181...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>gru</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1512</td>\n",
       "      <td>[560, 168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.6827925145626068, 0.6555613279...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278</th>\n",
       "      <td>gru</td>\n",
       "      <td>elu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[560, 168]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6552</td>\n",
       "      <td>7</td>\n",
       "      <td>{'val_loss': [0.11210501194000244, 0.067371591...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2281</th>\n",
       "      <td>lstm</td>\n",
       "      <td>linear</td>\n",
       "      <td>1512</td>\n",
       "      <td>[420, 126]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.1825798749923706, 0.1694765761...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>gru</td>\n",
       "      <td>selu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[560, 168]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6552</td>\n",
       "      <td>4</td>\n",
       "      <td>{'val_loss': [0.12242581322789192, 0.052730539...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286</th>\n",
       "      <td>gru</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1512</td>\n",
       "      <td>[560, 168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.24126195162534714, 0.562865778...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288</th>\n",
       "      <td>gru</td>\n",
       "      <td>softsign</td>\n",
       "      <td>1512</td>\n",
       "      <td>[560, 168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.15728703141212463, 0.323601275...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>gru</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1512</td>\n",
       "      <td>[560, 168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.15788646042346954, 0.405916213...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2294</th>\n",
       "      <td>gru</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>1512</td>\n",
       "      <td>[560, 168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.45355117321014404, 0.128906067...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296</th>\n",
       "      <td>gru</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1512</td>\n",
       "      <td>[560, 168]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.24089817702770233, 0.129290848...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2298</th>\n",
       "      <td>gru</td>\n",
       "      <td>relu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[560, 168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.2542557641863823, 0.0878030247...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>gru</td>\n",
       "      <td>linear</td>\n",
       "      <td>1512</td>\n",
       "      <td>[560, 168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.0965939536690712, 0.0841231979...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2302</th>\n",
       "      <td>elman</td>\n",
       "      <td>elu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[1680, 504]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [47.95561218261719, 0.05938814207...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304</th>\n",
       "      <td>elman</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1512</td>\n",
       "      <td>[1680, 504]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.6548601388931274, 0.6296121776...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>elman</td>\n",
       "      <td>selu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[1680, 504]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [633.37060546875, 1179.9948730468...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2308</th>\n",
       "      <td>elman</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1512</td>\n",
       "      <td>[1680, 504]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [23.538007736206055, 7.6927015781...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2310</th>\n",
       "      <td>elman</td>\n",
       "      <td>softsign</td>\n",
       "      <td>1512</td>\n",
       "      <td>[1680, 504]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [7.023441314697266, 0.55131703615...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2313</th>\n",
       "      <td>elman</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1512</td>\n",
       "      <td>[1680, 504]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.0625697672367096, 0.0757897570...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2318</th>\n",
       "      <td>elman</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1512</td>\n",
       "      <td>[1680, 504]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [1.3756086826324463, 0.2213354110...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2320</th>\n",
       "      <td>elman</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>1512</td>\n",
       "      <td>[1680, 504]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [1.227897822856903, 1.64721822738...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2322</th>\n",
       "      <td>elman</td>\n",
       "      <td>relu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[1680, 504]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2324</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1512</td>\n",
       "      <td>[840, 252]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.6027048528194427, 0.5654954016...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2326</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>elu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[840, 252]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [64.48777389526367, 3262.76245117...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2328</th>\n",
       "      <td>elman</td>\n",
       "      <td>linear</td>\n",
       "      <td>1512</td>\n",
       "      <td>[1680, 504]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [24504.8173828125, nan, nan, nan,...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>selu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[840, 252]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [120.33261108398438, 2329.1933593...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2333</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softsign</td>\n",
       "      <td>1512</td>\n",
       "      <td>[840, 252]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.3565644323825836, 1.5945081710...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1512</td>\n",
       "      <td>[840, 252]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [11.646546363830566, 0.2651017233...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2339</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1512</td>\n",
       "      <td>[840, 252]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [9.022808074951172, 0.27727264165...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2343</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1512</td>\n",
       "      <td>[840, 252]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.15803233534097672, 0.083446612...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>1512</td>\n",
       "      <td>[840, 252]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [1.3304511904716492, 1.9834116101...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>relu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[840, 252]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.44165556132793427, 0.391929775...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2352</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1512</td>\n",
       "      <td>[210, 63]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.6187992691993713, 0.5943061709...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2355</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>linear</td>\n",
       "      <td>1512</td>\n",
       "      <td>[840, 252]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [3390.8712158203125, 958.81076049...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2361</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>elu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[210, 63]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6552</td>\n",
       "      <td>10</td>\n",
       "      <td>{'val_loss': [0.06434760615229607, 0.058221271...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2363</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1512</td>\n",
       "      <td>[210, 63]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2370</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softsign</td>\n",
       "      <td>1512</td>\n",
       "      <td>[210, 63]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6552</td>\n",
       "      <td>9</td>\n",
       "      <td>{'val_loss': [0.10249042510986328, 0.090073514...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2374</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>selu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[210, 63]</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>6552</td>\n",
       "      <td>25</td>\n",
       "      <td>{'val_loss': [0.09115772694349289, 0.030247288...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2376</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1512</td>\n",
       "      <td>[210, 63]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.06871934607625008, 0.062969136...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1512</td>\n",
       "      <td>[210, 63]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.0736440010368824, 0.0943159386...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>1512</td>\n",
       "      <td>[210, 63]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.1469312459230423, 0.0765047334...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>linear</td>\n",
       "      <td>1512</td>\n",
       "      <td>[210, 63]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.09426280483603477, 0.085659496...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2392</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>relu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[210, 63]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.12138104811310768, 0.094548139...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1512</td>\n",
       "      <td>[240, 72]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.6929214000701904, 0.6478087306...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2404</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>selu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[240, 72]</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6552</td>\n",
       "      <td>15</td>\n",
       "      <td>{'val_loss': [0.0627257339656353, 0.0736794210...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2406</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1512</td>\n",
       "      <td>[240, 72]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.15661513805389404, 0.077807497...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2411</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>elu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[240, 72]</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.07961174100637436, 0.071388587...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1512</td>\n",
       "      <td>[240, 72]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.10817597061395645, 0.071726363...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2422</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1512</td>\n",
       "      <td>[240, 72]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.21529989689588547, 0.190238513...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2424</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>1512</td>\n",
       "      <td>[240, 72]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.1654612272977829, 0.0820692777...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2427</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softsign</td>\n",
       "      <td>1512</td>\n",
       "      <td>[240, 72]</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.0549391508102417, 0.0499398205...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2429</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>linear</td>\n",
       "      <td>1512</td>\n",
       "      <td>[240, 72]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6552</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.16705023497343063, 0.093512475...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2432</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>relu</td>\n",
       "      <td>1512</td>\n",
       "      <td>[240, 72]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6552</td>\n",
       "      <td>12</td>\n",
       "      <td>{'val_loss': [0.2425340786576271, 0.1009999401...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2435</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softmax</td>\n",
       "      <td>2016</td>\n",
       "      <td>[420, 168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5677637904882431, 0.5505574643...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>lstm</td>\n",
       "      <td>elu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[420, 168]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7056</td>\n",
       "      <td>46</td>\n",
       "      <td>{'val_loss': [0.09696029126644135, 0.086629398...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2443</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softplus</td>\n",
       "      <td>2016</td>\n",
       "      <td>[420, 168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softsign</td>\n",
       "      <td>2016</td>\n",
       "      <td>[420, 168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.18415351957082748, 0.208475463...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2449</th>\n",
       "      <td>lstm</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2016</td>\n",
       "      <td>[420, 168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.23123571276664734, 0.059193661...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2451</th>\n",
       "      <td>lstm</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>2016</td>\n",
       "      <td>[420, 168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.06565298140048981, 0.065692424...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454</th>\n",
       "      <td>lstm</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>2016</td>\n",
       "      <td>[420, 168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.1873912811279297, 0.0778605379...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2458</th>\n",
       "      <td>lstm</td>\n",
       "      <td>selu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[420, 168]</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.05154094658792019, 0.025774080...</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2461</th>\n",
       "      <td>lstm</td>\n",
       "      <td>relu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[420, 168]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [374.7257385253906, 0.24386104941...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2464</th>\n",
       "      <td>gru</td>\n",
       "      <td>softmax</td>\n",
       "      <td>2016</td>\n",
       "      <td>[560, 224]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.7063301801681519, 0.6790731847...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>lstm</td>\n",
       "      <td>linear</td>\n",
       "      <td>2016</td>\n",
       "      <td>[420, 168]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.32356463372707367, 0.343315705...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>gru</td>\n",
       "      <td>selu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[560, 224]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.06448863260447979, 0.070952069...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>gru</td>\n",
       "      <td>elu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[560, 224]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7056</td>\n",
       "      <td>112</td>\n",
       "      <td>{'val_loss': [0.07651127502322197, 0.079492669...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>gru</td>\n",
       "      <td>softplus</td>\n",
       "      <td>2016</td>\n",
       "      <td>[560, 224]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [1.4956951141357422, 0.2025217264...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>gru</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2016</td>\n",
       "      <td>[560, 224]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.12363731861114502, 0.081483285...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>gru</td>\n",
       "      <td>softsign</td>\n",
       "      <td>2016</td>\n",
       "      <td>[560, 224]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7056</td>\n",
       "      <td>13</td>\n",
       "      <td>{'val_loss': [0.09816183149814606, 0.078751999...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>gru</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>2016</td>\n",
       "      <td>[560, 224]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.1718287467956543, 0.3265133798...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2489</th>\n",
       "      <td>gru</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>2016</td>\n",
       "      <td>[560, 224]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.10670722275972366, 0.220568232...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>gru</td>\n",
       "      <td>relu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[560, 224]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7056</td>\n",
       "      <td>14</td>\n",
       "      <td>{'val_loss': [0.1814209669828415, 0.1071994602...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>gru</td>\n",
       "      <td>linear</td>\n",
       "      <td>2016</td>\n",
       "      <td>[560, 224]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7056</td>\n",
       "      <td>7</td>\n",
       "      <td>{'val_loss': [0.23867519199848175, 0.105924654...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>elman</td>\n",
       "      <td>softmax</td>\n",
       "      <td>2016</td>\n",
       "      <td>[1680, 672]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.599197506904602, 0.57545709609...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>elman</td>\n",
       "      <td>elu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[1680, 672]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [93.31765747070312, 64.1185150146...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502</th>\n",
       "      <td>elman</td>\n",
       "      <td>selu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[1680, 672]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2504</th>\n",
       "      <td>elman</td>\n",
       "      <td>softplus</td>\n",
       "      <td>2016</td>\n",
       "      <td>[1680, 672]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [25.44868564605713, 205775.078125...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506</th>\n",
       "      <td>elman</td>\n",
       "      <td>softsign</td>\n",
       "      <td>2016</td>\n",
       "      <td>[1680, 672]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [3.6687450408935547, 0.3913789093...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2508</th>\n",
       "      <td>elman</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2016</td>\n",
       "      <td>[1680, 672]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [117.64476013183594, 4.4763824939...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>elman</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>2016</td>\n",
       "      <td>[1680, 672]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.12322569638490677, 0.822585195...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512</th>\n",
       "      <td>elman</td>\n",
       "      <td>relu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[1680, 672]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>elman</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>2016</td>\n",
       "      <td>[1680, 672]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [1.0610771775245667, 2.2958028316...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softmax</td>\n",
       "      <td>2016</td>\n",
       "      <td>[840, 336]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.6214663088321686, 0.5841623544...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>elman</td>\n",
       "      <td>linear</td>\n",
       "      <td>2016</td>\n",
       "      <td>[1680, 672]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [26899.798828125, 2319893528576.0...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>elu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[840, 336]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [13.64760971069336, 25.7135715484...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>selu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[840, 336]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softplus</td>\n",
       "      <td>2016</td>\n",
       "      <td>[840, 336]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [2.745560646057129, 0.62969821691...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2528</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2016</td>\n",
       "      <td>[840, 336]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [1.0294718146324158, 0.0802628397...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2530</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softsign</td>\n",
       "      <td>2016</td>\n",
       "      <td>[840, 336]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [1.191558599472046, 0.91667765378...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2533</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>2016</td>\n",
       "      <td>[840, 336]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [1.5018829703330994, 0.2236690297...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>2016</td>\n",
       "      <td>[840, 336]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [5.301624536514282, 0.47389495372...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>linear</td>\n",
       "      <td>2016</td>\n",
       "      <td>[840, 336]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [8271384.75, 277970976.0, 6.49942...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2543</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softmax</td>\n",
       "      <td>2016</td>\n",
       "      <td>[210, 84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5716935396194458, 0.5484902560...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2548</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>relu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[840, 336]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7056</td>\n",
       "      <td>2</td>\n",
       "      <td>{'val_loss': [0.18928514420986176, 0.009749777...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>elu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[210, 84]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7056</td>\n",
       "      <td>9</td>\n",
       "      <td>{'val_loss': [0.121856939047575, 0.09877430647...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softplus</td>\n",
       "      <td>2016</td>\n",
       "      <td>[210, 84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2564</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>selu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[210, 84]</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>7056</td>\n",
       "      <td>13</td>\n",
       "      <td>{'val_loss': [0.032288371585309505, 0.02196237...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2016</td>\n",
       "      <td>[210, 84]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.10067905858159065, 0.095259692...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2576</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softsign</td>\n",
       "      <td>2016</td>\n",
       "      <td>[210, 84]</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.05721994675695896, 0.035908428...</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>2016</td>\n",
       "      <td>[210, 84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.20864005386829376, 0.081358764...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2583</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>2016</td>\n",
       "      <td>[210, 84]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.11477350816130638, 0.076861314...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>relu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[210, 84]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7056</td>\n",
       "      <td>13</td>\n",
       "      <td>{'val_loss': [0.12176647409796715, 0.120105225...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2593</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>linear</td>\n",
       "      <td>2016</td>\n",
       "      <td>[210, 84]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7056</td>\n",
       "      <td>29</td>\n",
       "      <td>{'val_loss': [0.09539033845067024, 0.118580173...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softmax</td>\n",
       "      <td>2016</td>\n",
       "      <td>[240, 96]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.585785299539566, 0.54645633697...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>elu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[240, 96]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7056</td>\n",
       "      <td>24</td>\n",
       "      <td>{'val_loss': [0.16169217228889465, 0.106565538...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2604</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>selu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[240, 96]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7056</td>\n",
       "      <td>7</td>\n",
       "      <td>{'val_loss': [0.08349677175283432, 0.087648723...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2609</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softsign</td>\n",
       "      <td>2016</td>\n",
       "      <td>[240, 96]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7056</td>\n",
       "      <td>16</td>\n",
       "      <td>{'val_loss': [0.16145045310258865, 0.103340368...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2613</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softplus</td>\n",
       "      <td>2016</td>\n",
       "      <td>[240, 96]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.15123723447322845, 0.213058620...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2617</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>2016</td>\n",
       "      <td>[240, 96]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.06020905822515488, 0.086765609...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2619</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>2016</td>\n",
       "      <td>[240, 96]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.06364467553794384, 0.064776595...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2016</td>\n",
       "      <td>[240, 96]</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.08361439406871796, 0.066727232...</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>linear</td>\n",
       "      <td>2016</td>\n",
       "      <td>[240, 96]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.08312393724918365, 0.100256085...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2629</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softmax</td>\n",
       "      <td>2520</td>\n",
       "      <td>[420, 210]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5681084394454956, 0.5509952306...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2631</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>relu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[240, 96]</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7056</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.13243379443883896, 0.095593873...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2635</th>\n",
       "      <td>lstm</td>\n",
       "      <td>elu</td>\n",
       "      <td>2520</td>\n",
       "      <td>[420, 210]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.11923468858003616, 0.103030774...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2637</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softplus</td>\n",
       "      <td>2520</td>\n",
       "      <td>[420, 210]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2645</th>\n",
       "      <td>lstm</td>\n",
       "      <td>selu</td>\n",
       "      <td>2520</td>\n",
       "      <td>[420, 210]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7560</td>\n",
       "      <td>33</td>\n",
       "      <td>{'val_loss': [0.11084724590182304, 0.113700579...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2648</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softsign</td>\n",
       "      <td>2520</td>\n",
       "      <td>[420, 210]</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.15507736429572105, 0.107112381...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2651</th>\n",
       "      <td>lstm</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2520</td>\n",
       "      <td>[420, 210]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7560</td>\n",
       "      <td>26</td>\n",
       "      <td>{'val_loss': [0.3203085660934448, 0.3383859843...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2653</th>\n",
       "      <td>lstm</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>2520</td>\n",
       "      <td>[420, 210]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.22444338351488113, 0.142343483...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2655</th>\n",
       "      <td>lstm</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>2520</td>\n",
       "      <td>[420, 210]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.06394323334097862, 0.065943783...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2657</th>\n",
       "      <td>lstm</td>\n",
       "      <td>relu</td>\n",
       "      <td>2520</td>\n",
       "      <td>[420, 210]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.2795484662055969, 0.0985789149...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2659</th>\n",
       "      <td>lstm</td>\n",
       "      <td>linear</td>\n",
       "      <td>2520</td>\n",
       "      <td>[420, 210]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.34715236723423004, 0.065966114...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2661</th>\n",
       "      <td>gru</td>\n",
       "      <td>softmax</td>\n",
       "      <td>2520</td>\n",
       "      <td>[560, 280]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5797857344150543, 0.5558061897...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2663</th>\n",
       "      <td>gru</td>\n",
       "      <td>elu</td>\n",
       "      <td>2520</td>\n",
       "      <td>[560, 280]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.20658811926841736, 0.500733226...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2665</th>\n",
       "      <td>gru</td>\n",
       "      <td>selu</td>\n",
       "      <td>2520</td>\n",
       "      <td>[560, 280]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.11079156398773193, 0.078074619...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2668</th>\n",
       "      <td>gru</td>\n",
       "      <td>softplus</td>\n",
       "      <td>2520</td>\n",
       "      <td>[560, 280]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.44771598279476166, 0.062461400...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>gru</td>\n",
       "      <td>softsign</td>\n",
       "      <td>2520</td>\n",
       "      <td>[560, 280]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7560</td>\n",
       "      <td>3</td>\n",
       "      <td>{'val_loss': [0.15202631056308746, 0.081231467...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>gru</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2520</td>\n",
       "      <td>[560, 280]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.10538836941123009, 0.063479054...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675</th>\n",
       "      <td>gru</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>2520</td>\n",
       "      <td>[560, 280]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.18300148099660873, 0.150665886...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2677</th>\n",
       "      <td>gru</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>2520</td>\n",
       "      <td>[560, 280]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.14732852578163147, 0.141183778...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2679</th>\n",
       "      <td>gru</td>\n",
       "      <td>relu</td>\n",
       "      <td>2520</td>\n",
       "      <td>[560, 280]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.15802691131830215, 0.075650744...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2681</th>\n",
       "      <td>gru</td>\n",
       "      <td>linear</td>\n",
       "      <td>2520</td>\n",
       "      <td>[560, 280]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.11360560357570648, 0.062505710...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2683</th>\n",
       "      <td>elman</td>\n",
       "      <td>softmax</td>\n",
       "      <td>2520</td>\n",
       "      <td>[1680, 840]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.6341591775417328, 0.6096932291...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2685</th>\n",
       "      <td>elman</td>\n",
       "      <td>elu</td>\n",
       "      <td>2520</td>\n",
       "      <td>[1680, 840]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [311.29534912109375, 83.049873352...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2687</th>\n",
       "      <td>elman</td>\n",
       "      <td>selu</td>\n",
       "      <td>2520</td>\n",
       "      <td>[1680, 840]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [9606.82861328125, 150.2508926391...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2689</th>\n",
       "      <td>elman</td>\n",
       "      <td>softplus</td>\n",
       "      <td>2520</td>\n",
       "      <td>[1680, 840]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [33.5136661529541, 25.83872795104...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2692</th>\n",
       "      <td>elman</td>\n",
       "      <td>softsign</td>\n",
       "      <td>2520</td>\n",
       "      <td>[1680, 840]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [45.45520782470703, 22.5477180480...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>elman</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>2520</td>\n",
       "      <td>[1680, 840]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7560</td>\n",
       "      <td>24</td>\n",
       "      <td>{'val_loss': [0.07544935494661331, 1.062725126...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>elman</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>2520</td>\n",
       "      <td>[1680, 840]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [1.4712646007537842, 3.2041640281...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>elman</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2520</td>\n",
       "      <td>[1680, 840]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.7690152823925018, 0.0958209224...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2703</th>\n",
       "      <td>elman</td>\n",
       "      <td>relu</td>\n",
       "      <td>2520</td>\n",
       "      <td>[1680, 840]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.060299960896372795, 0.08596496...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softmax</td>\n",
       "      <td>2520</td>\n",
       "      <td>[840, 420]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.4234108030796051, 0.3934638947...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2709</th>\n",
       "      <td>elman</td>\n",
       "      <td>linear</td>\n",
       "      <td>2520</td>\n",
       "      <td>[1680, 840]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2711</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>selu</td>\n",
       "      <td>2520</td>\n",
       "      <td>[840, 420]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softplus</td>\n",
       "      <td>2520</td>\n",
       "      <td>[840, 420]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [18.912104606628418, 0.2935480773...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2717</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softsign</td>\n",
       "      <td>2520</td>\n",
       "      <td>[840, 420]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5376138985157013, 0.0736353956...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2719</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>elu</td>\n",
       "      <td>2520</td>\n",
       "      <td>[840, 420]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [32.876644134521484, 729.66119384...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2721</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2520</td>\n",
       "      <td>[840, 420]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [2.5868664979934692, 0.3647451996...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>2520</td>\n",
       "      <td>[840, 420]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.18790309876203537, 0.079225167...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2730</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>2520</td>\n",
       "      <td>[840, 420]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7560</td>\n",
       "      <td>37</td>\n",
       "      <td>{'val_loss': [0.8809223175048828, 1.2616017460...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>linear</td>\n",
       "      <td>2520</td>\n",
       "      <td>[840, 420]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [69682520.0, 296032.0, 6338318827...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2734</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softmax</td>\n",
       "      <td>2520</td>\n",
       "      <td>[210, 105]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.6185149550437927, 0.5943638682...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2737</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>elu</td>\n",
       "      <td>2520</td>\n",
       "      <td>[210, 105]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7560</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.05965292267501354, 0.062329966...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>selu</td>\n",
       "      <td>2520</td>\n",
       "      <td>[210, 105]</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>7560</td>\n",
       "      <td>14</td>\n",
       "      <td>{'val_loss': [0.035311589017510414, 0.01039189...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>822 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         nn_type activation_func  parameters nodes_in_layer  largest_retained  smallest_not_retained  model_params  num_epochs                                        model_score  highest_F1  diff_small_large\n",
       "2           lstm             elu         504           [42]                 1                      2           504         699  {'val_loss': [0.4946219176054001, 0.2408708184...    0.500000                 1\n",
       "6           lstm            selu         504           [42]                 3                      4           504           7  {'val_loss': [0.0819605402648449, 0.0693724751...    1.000000                 1\n",
       "8           lstm        softplus         504           [42]                 1                      2           504         699  {'val_loss': [0.20116198807954788, 0.206449702...    0.500000                 1\n",
       "12          lstm        softsign         504           [42]                 2                      3           504         699  {'val_loss': [0.40316881239414215, 0.251443207...    0.666667                 1\n",
       "16          lstm            tanh         504           [42]                 3                      4           504          44  {'val_loss': [0.3318553566932678, 0.1949969530...    1.000000                 1\n",
       "18          lstm         sigmoid         504           [42]                 1                      2           504         699  {'val_loss': [0.08133256807923317, 0.071514669...    0.500000                 1\n",
       "20          lstm    hard_sigmoid         504           [42]                 1                      2           504         699  {'val_loss': [0.07580393180251122, 0.075959742...    0.500000                 1\n",
       "26          lstm            relu         504           [42]                 4                      5           504         699  {'val_loss': [0.25778841227293015, 0.227367028...    0.200000                 1\n",
       "30          lstm          linear         504           [42]                 2                      3           504         699  {'val_loss': [0.3624194860458374, 0.1538776010...    0.333333                 1\n",
       "32           gru         softmax         504           [56]                 1                      2           504         699  {'val_loss': [0.5448723286390305, 0.5204579234...    0.500000                 1\n",
       "34           gru             elu         504           [56]                 1                      2           504         699  {'val_loss': [0.4465404450893402, 0.2424310073...    0.500000                 1\n",
       "36           gru            selu         504           [56]                 1                      2           504         699  {'val_loss': [0.3945378214120865, 0.0874072089...    0.500000                 1\n",
       "38           gru        softplus         504           [56]                 1                      2           504         699  {'val_loss': [0.5819623172283173, 0.0856886133...    0.500000                 1\n",
       "42           gru        softsign         504           [56]                 2                      3           504         699  {'val_loss': [0.36055484414100647, 0.208033062...    0.333333                 1\n",
       "44           gru            tanh         504           [56]                 1                      2           504         699  {'val_loss': [0.4152391701936722, 0.1948228254...    0.500000                 1\n",
       "48           gru         sigmoid         504           [56]                 2                      3           504         699  {'val_loss': [0.34265419840812683, 0.085719957...    0.333333                 1\n",
       "50           gru    hard_sigmoid         504           [56]                 1                      2           504         699  {'val_loss': [0.26553022116422653, 0.064528800...    0.500000                 1\n",
       "54           gru            relu         504           [56]                 2                      3           504         699  {'val_loss': [0.3832283616065979, 0.2987566590...    0.666667                 1\n",
       "58           gru          linear         504           [56]                 3                      4           504          43  {'val_loss': [0.31459513306617737, 0.157367624...    1.000000                 1\n",
       "60         elman         softmax         504          [168]                 1                      2           504         699  {'val_loss': [0.7038005292415619, 0.6762956678...    0.500000                 1\n",
       "68         elman             elu         504          [168]                 9                     10           504          35  {'val_loss': [0.01022288529202342, 0.004784897...    1.000000                 1\n",
       "70         elman            selu         504          [168]                 1                      2           504         699  {'val_loss': [nan, nan, nan, nan, nan, nan, na...    0.500000                 1\n",
       "72         elman        softplus         504          [168]                 1                      2           504         699  {'val_loss': [0.11724359542131424, 0.067714590...    0.500000                 1\n",
       "80         elman        softsign         504          [168]                10                     11           504         699  {'val_loss': [0.0036327834241092205, 0.0023907...    0.545455                 1\n",
       "88         elman            tanh         504          [168]                11                     12           504          16  {'val_loss': [0.006719990400597453, 0.00462339...    1.000000                 1\n",
       "92         elman         sigmoid         504          [168]                 2                      3           504         699  {'val_loss': [0.09701669961214066, 0.126788254...    0.333333                 1\n",
       "94         elman    hard_sigmoid         504          [168]                 1                      2           504         699  {'val_loss': [0.08693477883934975, 0.089432314...    0.500000                 1\n",
       "98         elman            relu         504          [168]                 3                      4           504          26  {'val_loss': [0.21049391478300095, 0.160464845...    1.000000                 1\n",
       "106        elman          linear         504          [168]                 8                      9           504         699  {'val_loss': [0.07618581131100655, 0.023449786...    0.444444                 1\n",
       "108   bidirelamn         softmax         504           [84]                 1                      2           504         699  {'val_loss': [0.5991988778114319, 0.5611424148...    0.500000                 1\n",
       "116   bidirelamn             elu         504           [84]                 8                      9           504         699  {'val_loss': [0.038599710911512375, 0.00683762...    0.555556                 1\n",
       "122   bidirelamn            selu         504           [84]                 4                      5           504         699  {'val_loss': [nan, nan, nan, nan, nan, nan, na...    0.200000                 1\n",
       "124   bidirelamn        softplus         504           [84]                 1                      2           504         699  {'val_loss': [0.11677606776356697, 0.247338593...    0.500000                 1\n",
       "130   bidirelamn        softsign         504           [84]                 4                      5           504         699  {'val_loss': [0.05220537260174751, 0.007052829...    0.800000                 1\n",
       "136   bidirelamn            tanh         504           [84]                 5                      6           504          16  {'val_loss': [0.0015075012343004346, 0.0012468...    1.000000                 1\n",
       "138   bidirelamn         sigmoid         504           [84]                 1                      2           504         699  {'val_loss': [0.09947529435157776, 0.067808486...    0.500000                 1\n",
       "142   bidirelamn    hard_sigmoid         504           [84]                 2                      3           504         699  {'val_loss': [0.09018612280488014, 0.084832493...    0.333333                 1\n",
       "146   bidirelamn            relu         504           [84]                 3                      4           504          16  {'val_loss': [0.2869787886738777, 0.1159043312...    1.000000                 1\n",
       "152   bidirelamn          linear         504           [84]                 7                      8           504          26  {'val_loss': [0.04190049506723881, 0.013597493...    1.000000                 1\n",
       "154    bidirlstm         softmax         504           [21]                 1                      2           504         699  {'val_loss': [0.663487434387207, 0.63724201917...    0.500000                 1\n",
       "158    bidirlstm             elu         504           [21]                 2                      3           504         699  {'val_loss': [0.37372808158397675, 0.234386362...    0.333333                 1\n",
       "164    bidirlstm            selu         504           [21]                 5                      6           504          20  {'val_loss': [0.08483178168535233, 0.083788037...    1.000000                 1\n",
       "168    bidirlstm        softplus         504           [21]                 2                      3           504         699  {'val_loss': [1.1596860885620117, 0.6694509088...    0.333333                 1\n",
       "172    bidirlstm        softsign         504           [21]                 3                      4           504          26  {'val_loss': [0.38953451812267303, 0.287065491...    1.000000                 1\n",
       "176    bidirlstm            tanh         504           [21]                 3                      4           504          21  {'val_loss': [0.36916880309581757, 0.244283460...    1.000000                 1\n",
       "180    bidirlstm         sigmoid         504           [21]                 2                      3           504         699  {'val_loss': [0.08764307200908661, 0.093582563...    0.333333                 1\n",
       "182    bidirlstm    hard_sigmoid         504           [21]                 1                      2           504         699  {'val_loss': [0.06540227681398392, 0.072437830...    0.500000                 1\n",
       "184    bidirlstm            relu         504           [21]                 1                      2           504         699  {'val_loss': [0.5630137622356415, 0.5116415321...    0.500000                 1\n",
       "188    bidirlstm          linear         504           [21]                 3                      4           504          24  {'val_loss': [0.3195510804653168, 0.2121522054...    1.000000                 1\n",
       "190     bidirgru         softmax         504           [24]                 1                      2           504         699  {'val_loss': [0.5863576531410217, 0.5471096634...    0.500000                 1\n",
       "196     bidirgru             elu         504           [24]                 4                      5           504         699  {'val_loss': [0.21432245522737503, 0.148047141...    0.600000                 1\n",
       "202     bidirgru            selu         504           [24]                 5                      6           504          42  {'val_loss': [0.16468828171491623, 0.084260262...    1.000000                 1\n",
       "204     bidirgru        softplus         504           [24]                 1                      2           504         699  {'val_loss': [0.14249546825885773, 0.081475466...    0.500000                 1\n",
       "210     bidirgru        softsign         504           [24]                 4                      5           504         699  {'val_loss': [0.23640096187591553, 0.172316953...    0.400000                 1\n",
       "216     bidirgru            tanh         504           [24]                 4                      5           504         699  {'val_loss': [0.22417141497135162, 0.159498237...    0.400000                 1\n",
       "218     bidirgru         sigmoid         504           [24]                 1                      2           504         699  {'val_loss': [1.2608646154403687, 0.6526324152...    0.500000                 1\n",
       "220     bidirgru    hard_sigmoid         504           [24]                 1                      2           504         699  {'val_loss': [0.062262656167149544, 0.06187883...    0.500000                 1\n",
       "224     bidirgru            relu         504           [24]                 3                      4           504          32  {'val_loss': [0.3938422203063965, 0.3493473976...    1.000000                 1\n",
       "228     bidirgru          linear         504           [24]                 2                      3           504         699  {'val_loss': [0.39541734755039215, 0.286482445...    0.666667                 1\n",
       "230         lstm         softmax        1008           [84]                 1                      2          1008         699  {'val_loss': [0.5860611498355865, 0.5686147511...    0.500000                 1\n",
       "232         lstm             elu        1008           [84]                 1                      2          1008         699  {'val_loss': [0.3213348537683487, 0.0622036941...    0.500000                 1\n",
       "236         lstm            selu        1008           [84]                 2                      3          1008         699  {'val_loss': [0.082134660333395, 0.07523649185...    0.333333                 1\n",
       "238         lstm        softplus        1008           [84]                 1                      2          1008         699  {'val_loss': [268828656.0, 2638.9259033203125,...    0.500000                 1\n",
       "244         lstm        softsign        1008           [84]                 6                      7          1008         699  {'val_loss': [0.12340161576867104, 0.087142843...    0.428571                 1\n",
       "246         lstm            tanh        1008           [84]                 1                      2          1008         699  {'val_loss': [0.4119742661714554, 0.0623351633...    0.500000                 1\n",
       "248         lstm         sigmoid        1008           [84]                 1                      2          1008         699  {'val_loss': [0.24947072565555573, 0.177885144...    0.500000                 1\n",
       "252         lstm    hard_sigmoid        1008           [84]                 2                      3          1008         699  {'val_loss': [0.08953189849853516, 0.084065947...    0.333333                 1\n",
       "258         lstm            relu        1008           [84]                 4                      5          1008         699  {'val_loss': [0.28199198842048645, 0.172666959...    0.400000                 1\n",
       "260         lstm          linear        1008           [84]                 1                      2          1008         699  {'val_loss': [0.5073779076337814, 0.1312993690...    0.500000                 1\n",
       "264          gru         softmax        1008          [112]                 2                      3          1008         699  {'val_loss': [0.4611859917640686, 0.4403687864...    0.333333                 1\n",
       "270          gru             elu        1008          [112]                 5                      6          1008          57  {'val_loss': [0.15789251774549484, 0.100181289...    1.000000                 1\n",
       "272          gru            selu        1008          [112]                 1                      2          1008         699  {'val_loss': [0.2656393200159073, 0.0625933408...    0.500000                 1\n",
       "274          gru        softplus        1008          [112]                 1                      2          1008         699  {'val_loss': [0.19934426248073578, 0.164807543...    0.500000                 1\n",
       "280          gru        softsign        1008          [112]                 4                      5          1008         699  {'val_loss': [0.1598307117819786, 0.1143907159...    0.200000                 1\n",
       "282          gru            tanh        1008          [112]                 1                      2          1008         699  {'val_loss': [0.36135047674179077, 0.153671763...    0.500000                 1\n",
       "286          gru         sigmoid        1008          [112]                 2                      3          1008         699  {'val_loss': [0.18420275300741196, 0.219889968...    0.333333                 1\n",
       "290          gru    hard_sigmoid        1008          [112]                 2                      3          1008         699  {'val_loss': [0.09764796495437622, 0.106708198...    0.333333                 1\n",
       "296          gru            relu        1008          [112]                 4                      5          1008         699  {'val_loss': [0.2867846190929413, 0.2018932849...    0.200000                 1\n",
       "300          gru          linear        1008          [112]                 3                      4          1008          13  {'val_loss': [0.3135805055499077, 0.1072222068...    1.000000                 1\n",
       "302        elman         softmax        1008          [336]                 1                      2          1008         699  {'val_loss': [0.5816648006439209, 0.5579436123...    0.500000                 1\n",
       "310        elman             elu        1008          [336]                10                     11          1008         699  {'val_loss': [0.020651287399232388, 0.02092381...    0.463636                 1\n",
       "314        elman            selu        1008          [336]                 3                      4          1008         111  {'val_loss': [5.416930913925171, 6.54799103736...    1.000000                 1\n",
       "316        elman        softplus        1008          [336]                 1                      2          1008         699  {'val_loss': [0.06226687505841255, 0.085654135...    0.500000                 1\n",
       "318        elman        softsign        1008          [336]                 1                      2          1008         699  {'val_loss': [0.19459501653909683, 0.090871986...    0.500000                 1\n",
       "320        elman            tanh        1008          [336]                 1                      2          1008         699  {'val_loss': [0.19768443703651428, 0.112147681...    0.500000                 1\n",
       "322        elman         sigmoid        1008          [336]                 1                      2          1008         699  {'val_loss': [0.31805236637592316, 0.123786017...    0.500000                 1\n",
       "324        elman    hard_sigmoid        1008          [336]                 1                      2          1008         699  {'val_loss': [0.1331797093153, 0.2433587089180...    0.500000                 1\n",
       "330        elman            relu        1008          [336]                 5                      6          1008          27  {'val_loss': [0.19364318996667862, 0.281179100...    1.000000                 1\n",
       "336        elman          linear        1008          [336]                 7                      8          1008          25  {'val_loss': [0.10409671068191528, 0.011606377...    1.000000                 1\n",
       "338   bidirelamn         softmax        1008          [168]                 1                      2          1008         699  {'val_loss': [0.5831093788146973, 0.5467988848...    0.500000                 1\n",
       "344   bidirelamn             elu        1008          [168]                 7                      8          1008           7  {'val_loss': [0.00752157554961741, 0.002374779...    1.000000                 1\n",
       "346   bidirelamn            selu        1008          [168]                 1                      2          1008         699  {'val_loss': [nan, nan, nan, nan, nan, nan, na...    0.500000                 1\n",
       "348   bidirelamn        softplus        1008          [168]                 1                      2          1008         699  {'val_loss': [0.38378164172172546, 0.167550429...    0.500000                 1\n",
       "354   bidirelamn        softsign        1008          [168]                 7                      8          1008          20  {'val_loss': [0.11835330352187157, 0.016519774...    1.000000                 1\n",
       "362   bidirelamn            tanh        1008          [168]                10                     11          1008         699  {'val_loss': [0.013515153899788857, 0.00489697...    0.636364                 1\n",
       "364   bidirelamn         sigmoid        1008          [168]                 1                      2          1008         699  {'val_loss': [0.07628345862030983, 0.075613573...    0.500000                 1\n",
       "368   bidirelamn    hard_sigmoid        1008          [168]                 2                      3          1008         699  {'val_loss': [0.08203767612576485, 0.081810921...    0.333333                 1\n",
       "376   bidirelamn            relu        1008          [168]                11                     12          1008          26  {'val_loss': [0.08343203365802765, 0.061957057...    1.000000                 1\n",
       "382   bidirelamn          linear        1008          [168]                 7                      8          1008          10  {'val_loss': [0.031909072771668434, 0.01060177...    1.000000                 1\n",
       "384    bidirlstm         softmax        1008           [42]                 1                      2          1008         699  {'val_loss': [0.5742955207824707, 0.5506151318...    0.500000                 1\n",
       "390    bidirlstm             elu        1008           [42]                 4                      5          1008         699  {'val_loss': [0.19192027300596237, 0.080607317...    0.400000                 1\n",
       "396    bidirlstm            selu        1008           [42]                 5                      6          1008          14  {'val_loss': [0.08378606662154198, 0.045127406...    1.000000                 1\n",
       "398    bidirlstm        softplus        1008           [42]                 1                      2          1008         699  {'val_loss': [1.956240952014923, 1.18634587526...    0.500000                 1\n",
       "402    bidirlstm        softsign        1008           [42]                 3                      4          1008          34  {'val_loss': [0.3328246772289276, 0.1508720666...    1.000000                 1\n",
       "408    bidirlstm            tanh        1008           [42]                 5                      6          1008          41  {'val_loss': [0.23154982924461365, 0.099558405...    1.000000                 1\n",
       "412    bidirlstm         sigmoid        1008           [42]                 2                      3          1008         699  {'val_loss': [0.08095728978514671, 0.079912036...    0.333333                 1\n",
       "414    bidirlstm    hard_sigmoid        1008           [42]                 1                      2          1008         699  {'val_loss': [0.090056411921978, 0.06298577971...    0.500000                 1\n",
       "418    bidirlstm            relu        1008           [42]                 3                      4          1008          23  {'val_loss': [0.4220045804977417, 0.3409764468...    1.000000                 1\n",
       "422    bidirlstm          linear        1008           [42]                 3                      4          1008          25  {'val_loss': [0.35160012543201447, 0.162914074...    1.000000                 1\n",
       "424     bidirgru         softmax        1008           [48]                 1                      2          1008         699  {'val_loss': [0.52736896276474, 0.491251945495...    0.500000                 1\n",
       "430     bidirgru             elu        1008           [48]                 4                      5          1008         699  {'val_loss': [0.1889338567852974, 0.0947050563...    0.800000                 1\n",
       "436     bidirgru            selu        1008           [48]                 5                      6          1008          23  {'val_loss': [0.1820697784423828, 0.0868976265...    1.000000                 1\n",
       "438     bidirgru        softplus        1008           [48]                 1                      2          1008         699  {'val_loss': [0.17352259159088135, 0.250410512...    0.500000                 1\n",
       "440     bidirgru        softsign        1008           [48]                 1                      2          1008         699  {'val_loss': [0.4706859290599823, 0.2493391856...    0.500000                 1\n",
       "442     bidirgru            tanh        1008           [48]                 1                      2          1008         699  {'val_loss': [0.48316994309425354, 0.220022402...    0.500000                 1\n",
       "446     bidirgru         sigmoid        1008           [48]                 2                      3          1008         699  {'val_loss': [0.08081924915313721, 0.081035375...    0.333333                 1\n",
       "450     bidirgru    hard_sigmoid        1008           [48]                 2                      3          1008         699  {'val_loss': [0.0731609147042036, 0.0796012505...    0.666667                 1\n",
       "456     bidirgru            relu        1008           [48]                 4                      5          1008         699  {'val_loss': [0.2339080199599266, 0.1816009655...    0.800000                 1\n",
       "458     bidirgru          linear        1008           [48]                 1                      2          1008         699  {'val_loss': [0.523583322763443, 0.26535367965...    0.500000                 1\n",
       "460         lstm         softmax        1512          [126]                 1                      2          1512         699  {'val_loss': [0.7079771757125854, 0.6884715557...    0.500000                 1\n",
       "466         lstm             elu        1512          [126]                 4                      5          1512         699  {'val_loss': [0.12273064255714417, 0.133944019...    0.200000                 1\n",
       "474         lstm            selu        1512          [126]                 8                      9          1512         699  {'val_loss': [0.06311207823455334, 0.056659523...    0.555556                 1\n",
       "476         lstm        softplus        1512          [126]                 1                      2          1512         699  {'val_loss': [0.07627357542514801, 0.069885056...    0.500000                 1\n",
       "482         lstm        softsign        1512          [126]                 4                      5          1512         699  {'val_loss': [0.11888939514756203, 0.075811943...    0.600000                 1\n",
       "486         lstm            tanh        1512          [126]                 3                      4          1512          14  {'val_loss': [0.21564581245183945, 0.128354802...    1.000000                 1\n",
       "490         lstm         sigmoid        1512          [126]                 2                      3          1512         699  {'val_loss': [0.0816057026386261, 0.0817841328...    0.666667                 1\n",
       "492         lstm    hard_sigmoid        1512          [126]                 1                      2          1512         699  {'val_loss': [0.14025737345218658, 0.084550738...    0.500000                 1\n",
       "496         lstm            relu        1512          [126]                 3                      4          1512          27  {'val_loss': [0.29207732528448105, 0.065406829...    1.000000                 1\n",
       "500         lstm          linear        1512          [126]                 2                      3          1512         699  {'val_loss': [0.2260839343070984, 0.1597735956...    0.666667                 1\n",
       "502          gru         softmax        1512          [168]                 1                      2          1512         699  {'val_loss': [0.55178302526474, 0.528354778885...    0.500000                 1\n",
       "504          gru             elu        1512          [168]                 1                      2          1512         699  {'val_loss': [0.24351449310779572, 0.062652064...    0.500000                 1\n",
       "508          gru            selu        1512          [168]                 3                      4          1512          21  {'val_loss': [0.07909475639462471, 0.078506682...    1.000000                 1\n",
       "510          gru        softplus        1512          [168]                 1                      2          1512         699  {'val_loss': [0.09527260810136795, 0.064762115...    0.500000                 1\n",
       "514          gru        softsign        1512          [168]                 3                      4          1512          19  {'val_loss': [0.15457211807370186, 0.074653293...    1.000000                 1\n",
       "516          gru            tanh        1512          [168]                 1                      2          1512         699  {'val_loss': [0.2985825389623642, 0.0906578712...    0.500000                 1\n",
       "518          gru         sigmoid        1512          [168]                 1                      2          1512         699  {'val_loss': [0.3303014785051346, 0.0683123171...    0.500000                 1\n",
       "522          gru    hard_sigmoid        1512          [168]                 2                      3          1512         699  {'val_loss': [0.18618952482938766, 0.086407568...    0.666667                 1\n",
       "528          gru            relu        1512          [168]                 4                      5          1512         699  {'val_loss': [0.19655141234397888, 0.089618325...    0.600000                 1\n",
       "532          gru          linear        1512          [168]                 3                      4          1512          44  {'val_loss': [0.15859699994325638, 0.082411210...    1.000000                 1\n",
       "534        elman         softmax        1512          [504]                 1                      2          1512         699  {'val_loss': [0.6385711133480072, 0.6138663291...    0.500000                 1\n",
       "536        elman             elu        1512          [504]                 1                      2          1512         699  {'val_loss': [0.5868909955024719, 0.0408654585...    0.500000                 1\n",
       "538        elman            selu        1512          [504]                 1                      2          1512         699  {'val_loss': [0.21002423763275146, 3.544219255...    0.500000                 1\n",
       "540        elman        softplus        1512          [504]                 1                      2          1512         699  {'val_loss': [0.14464852958917618, 1.424128174...    0.500000                 1\n",
       "544        elman        softsign        1512          [504]                 2                      3          1512         699  {'val_loss': [0.60403011739254, 2.137657582759...    0.333333                 1\n",
       "548        elman            tanh        1512          [504]                 3                      4          1512          32  {'val_loss': [0.4077098071575165, 0.3493980020...    1.000000                 1\n",
       "552        elman         sigmoid        1512          [504]                 2                      3          1512         699  {'val_loss': [0.36824576556682587, 0.426040157...    0.333333                 1\n",
       "554        elman    hard_sigmoid        1512          [504]                 1                      2          1512         699  {'val_loss': [0.10015429183840752, 0.236748464...    0.500000                 1\n",
       "558        elman            relu        1512          [504]                 3                      4          1512          23  {'val_loss': [0.23025226593017578, 0.223041549...    1.000000                 1\n",
       "562        elman          linear        1512          [504]                 3                      4          1512           7  {'val_loss': [0.5303019285202026, 0.1517066881...    1.000000                 1\n",
       "564   bidirelamn         softmax        1512          [252]                 1                      2          1512         699  {'val_loss': [0.6727247834205627, 0.6337536573...    0.500000                 1\n",
       "570   bidirelamn             elu        1512          [252]                 7                      8          1512          20  {'val_loss': [0.015925960149616003, 0.00527865...    1.000000                 1\n",
       "572   bidirelamn            selu        1512          [252]                 1                      2          1512         699  {'val_loss': [5.224201202392578, 1.22818577289...    0.500000                 1\n",
       "576   bidirelamn        softplus        1512          [252]                 2                      3          1512         699  {'val_loss': [0.33148498833179474, 0.088401209...    0.333333                 1\n",
       "584   bidirelamn        softsign        1512          [252]                10                     11          1512         699  {'val_loss': [0.006480877287685871, 0.00360835...    0.718182                 1\n",
       "590   bidirelamn            tanh        1512          [252]                 6                      7          1512         699  {'val_loss': [0.5083888918161392, 1.3063552975...    0.571429                 1\n",
       "594   bidirelamn         sigmoid        1512          [252]                 2                      3          1512         699  {'val_loss': [0.33735139667987823, 0.135450154...    0.333333                 1\n",
       "596   bidirelamn    hard_sigmoid        1512          [252]                 1                      2          1512         699  {'val_loss': [0.1081976555287838, 0.0705663934...    0.500000                 1\n",
       "600   bidirelamn            relu        1512          [252]                 3                      4          1512          14  {'val_loss': [0.35353904962539673, 9.345939636...    1.000000                 1\n",
       "606   bidirelamn          linear        1512          [252]                 5                      6          1512           7  {'val_loss': [0.0900944322347641, 0.0164098795...    1.000000                 1\n",
       "608    bidirlstm         softmax        1512           [63]                 1                      2          1512         699  {'val_loss': [0.5915727019309998, 0.5678694546...    0.500000                 1\n",
       "612    bidirlstm             elu        1512           [63]                 3                      4          1512          14  {'val_loss': [0.33732305467128754, 0.094319980...    1.000000                 1\n",
       "618    bidirlstm            selu        1512           [63]                 6                      7          1512         699  {'val_loss': [0.05769358202815056, 0.057522859...    0.571429                 1\n",
       "620    bidirlstm        softplus        1512           [63]                 1                      2          1512         699  {'val_loss': [0.1571088656783104, 0.2060238346...    0.500000                 1\n",
       "626    bidirlstm        softsign        1512           [63]                 6                      7          1512         699  {'val_loss': [0.11059226095676422, 0.094340045...    0.571429                 1\n",
       "630    bidirlstm            tanh        1512           [63]                 3                      4          1512          13  {'val_loss': [0.257699191570282, 0.11426969245...    1.000000                 1\n",
       "632    bidirlstm         sigmoid        1512           [63]                 1                      2          1512         699  {'val_loss': [0.2906939685344696, 0.1470634713...    0.500000                 1\n",
       "634    bidirlstm    hard_sigmoid        1512           [63]                 1                      2          1512         699  {'val_loss': [0.10220537707209587, 0.085428446...    0.500000                 1\n",
       "638    bidirlstm            relu        1512           [63]                 3                      4          1512          36  {'val_loss': [0.38034193217754364, 0.239430114...    1.000000                 1\n",
       "644    bidirlstm          linear        1512           [63]                 6                      7          1512         699  {'val_loss': [0.14405367150902748, 0.098101798...    0.428571                 1\n",
       "646     bidirgru         softmax        1512           [72]                 1                      2          1512         699  {'val_loss': [0.555176854133606, 0.51963733136...    0.500000                 1\n",
       "650     bidirgru             elu        1512           [72]                 2                      3          1512         699  {'val_loss': [0.3632999509572983, 0.1286262869...    0.333333                 1\n",
       "656     bidirgru            selu        1512           [72]                 4                      5          1512         699  {'val_loss': [0.12293258681893349, 0.091081894...    0.800000                 1\n",
       "658     bidirgru        softplus        1512           [72]                 1                      2          1512         699  {'val_loss': [0.0650656707584858, 0.0627639796...    0.500000                 1\n",
       "660     bidirgru        softsign        1512           [72]                 1                      2          1512         699  {'val_loss': [0.4623904675245285, 0.1463238522...    0.500000                 1\n",
       "664     bidirgru            tanh        1512           [72]                 2                      3          1512         699  {'val_loss': [0.17595795542001724, 0.066540349...    0.333333                 1\n",
       "668     bidirgru         sigmoid        1512           [72]                 3                      4          1512          81  {'val_loss': [0.11252160742878914, 0.090491417...    1.000000                 1\n",
       "672     bidirgru    hard_sigmoid        1512           [72]                 3                      4          1512          83  {'val_loss': [0.10815582796931267, 0.101258069...    1.000000                 1\n",
       "674     bidirgru            relu        1512           [72]                 1                      2          1512         699  {'val_loss': [0.5921664535999298, 0.4735741168...    0.500000                 1\n",
       "680     bidirgru          linear        1512           [72]                 5                      6          1512          43  {'val_loss': [0.13811229169368744, 0.076083686...    1.000000                 1\n",
       "682         lstm         softmax        2016          [168]                 1                      2          2016         699  {'val_loss': [0.5310638248920441, 0.5145939588...    0.500000                 1\n",
       "684         lstm             elu        2016          [168]                 1                      2          2016         699  {'val_loss': [0.25635115802288055, 0.112963806...    0.500000                 1\n",
       "686         lstm            selu        2016          [168]                 1                      2          2016         699  {'val_loss': [0.12132997810840607, 0.098686829...    0.500000                 1\n",
       "688         lstm        softplus        2016          [168]                 1                      2          2016         699  {'val_loss': [nan, nan, nan, nan, nan, nan, na...    0.500000                 1\n",
       "694         lstm        softsign        2016          [168]                 5                      6          2016          34  {'val_loss': [0.08660119771957397, 0.101037941...    1.000000                 1\n",
       "696         lstm            tanh        2016          [168]                 1                      2          2016         699  {'val_loss': [0.16473206132650375, 0.067782949...    0.500000                 1\n",
       "698         lstm         sigmoid        2016          [168]                 1                      2          2016         699  {'val_loss': [0.11378348618745804, 0.121088098...    0.500000                 1\n",
       "700         lstm    hard_sigmoid        2016          [168]                 1                      2          2016         699  {'val_loss': [0.09497181326150894, 0.097594346...    0.500000                 1\n",
       "702         lstm            relu        2016          [168]                 1                      2          2016         699  {'val_loss': [0.4853818565607071, 0.2198217511...    0.500000                 1\n",
       "706         lstm          linear        2016          [168]                 2                      3          2016         699  {'val_loss': [0.8070533573627472, 0.2166182845...    0.333333                 1\n",
       "708          gru         softmax        2016          [224]                 1                      2          2016         699  {'val_loss': [0.5738425850868225, 0.5500681102...    0.500000                 1\n",
       "710          gru             elu        2016          [224]                 1                      2          2016         699  {'val_loss': [0.12236658483743668, 0.080177463...    0.500000                 1\n",
       "712          gru            selu        2016          [224]                 1                      2          2016         699  {'val_loss': [0.10072934255003929, 0.178373135...    0.500000                 1\n",
       "714          gru        softplus        2016          [224]                 1                      2          2016         699  {'val_loss': [0.366757869720459, 0.15220645070...    0.500000                 1\n",
       "718          gru        softsign        2016          [224]                 2                      3          2016         699  {'val_loss': [0.10945373773574829, 0.106763426...    0.666667                 1\n",
       "720          gru            tanh        2016          [224]                 1                      2          2016         699  {'val_loss': [0.12065264582633972, 0.090794235...    0.500000                 1\n",
       "722          gru         sigmoid        2016          [224]                 1                      2          2016         699  {'val_loss': [0.43898291885852814, 0.135307580...    0.500000                 1\n",
       "728          gru    hard_sigmoid        2016          [224]                 4                      5          2016         699  {'val_loss': [0.1364227756857872, 0.1014339849...    0.200000                 1\n",
       "730          gru            relu        2016          [224]                 1                      2          2016         699  {'val_loss': [0.5105425715446472, 0.0659330114...    0.500000                 1\n",
       "736          gru          linear        2016          [224]                 4                      5          2016         699  {'val_loss': [0.07688941434025764, 0.091145664...    0.600000                 1\n",
       "738        elman         softmax        2016          [672]                 1                      2          2016         699  {'val_loss': [0.5403292775154114, 0.5178883969...    0.500000                 1\n",
       "744        elman             elu        2016          [672]                 4                      5          2016         699  {'val_loss': [0.7729886770248413, 2.8914053440...    0.200000                 1\n",
       "746        elman            selu        2016          [672]                 1                      2          2016         699  {'val_loss': [3.69827401638031, 0.522785633802...    0.500000                 1\n",
       "748        elman        softplus        2016          [672]                 1                      2          2016         699  {'val_loss': [1.2315192222595215, 2.0352772474...    0.500000                 1\n",
       "752        elman        softsign        2016          [672]                 2                      3          2016         699  {'val_loss': [0.08825328573584557, 0.266041800...    0.333333                 1\n",
       "754        elman            tanh        2016          [672]                 1                      2          2016         699  {'val_loss': [0.18953587114810944, 0.084268633...    0.500000                 1\n",
       "758        elman         sigmoid        2016          [672]                 2                      3          2016         699  {'val_loss': [0.7230202555656433, 0.6256767511...    0.666667                 1\n",
       "762        elman    hard_sigmoid        2016          [672]                 2                      3          2016         699  {'val_loss': [0.44950659573078156, 0.591275930...    0.333333                 1\n",
       "770        elman            relu        2016          [672]                 8                      9          2016         699  {'val_loss': [0.061833128333091736, 0.04938700...    0.444444                 1\n",
       "776        elman          linear        2016          [672]                 5                      6          2016          11  {'val_loss': [0.015212945640087128, 0.01460808...    1.000000                 1\n",
       "782   bidirelamn         softmax        2016          [336]                 1                      2          2016         699  {'val_loss': [0.5613326728343964, 0.5266576111...    0.500000                 1\n",
       "784   bidirelamn            selu        2016          [336]                 1                      2          2016         699  {'val_loss': [nan, nan, nan, nan, nan, nan, na...    0.500000                 1\n",
       "789   bidirelamn        softplus        2016          [336]                 2                      3          2016         699  {'val_loss': [0.07410337775945663, 0.074415724...    0.333333                 1\n",
       "794   bidirelamn             elu        2016          [336]                11                     12          2016           9  {'val_loss': [0.05427826754748821, 0.007906206...    1.000000                 1\n",
       "797   bidirelamn        softsign        2016          [336]                 3                      4          2016          13  {'val_loss': [0.04462978430092335, 0.028002463...    1.000000                 1\n",
       "800   bidirelamn         sigmoid        2016          [336]                 1                      2          2016         699  {'val_loss': [0.5871401727199554, 0.3280586153...    0.500000                 1\n",
       "803   bidirelamn            tanh        2016          [336]                 3                      4          2016          30  {'val_loss': [0.29632212221622467, 0.050634915...    1.000000                 1\n",
       "807   bidirelamn    hard_sigmoid        2016          [336]                 1                      2          2016         699  {'val_loss': [0.4878322333097458, 0.0719946511...    0.500000                 1\n",
       "814   bidirelamn            relu        2016          [336]                 6                      7          2016         699  {'val_loss': [0.08910251781344414, 0.072274720...    0.571429                 1\n",
       "817   bidirelamn          linear        2016          [336]                 5                      6          2016          19  {'val_loss': [0.1273687407374382, 0.0232365578...    1.000000                 1\n",
       "821    bidirlstm         softmax        2016           [84]                 1                      2          2016         699  {'val_loss': [0.5862846374511719, 0.5628803968...    0.500000                 1\n",
       "828    bidirlstm            selu        2016           [84]                 7                      8          2016          12  {'val_loss': [0.08488580211997032, 0.065190382...    1.000000                 1\n",
       "831    bidirlstm             elu        2016           [84]                 5                      6          2016          48  {'val_loss': [0.11712664738297462, 0.080607995...    1.000000                 1\n",
       "834    bidirlstm        softplus        2016           [84]                 1                      2          2016         699  {'val_loss': [4746356.25, 26787851.0, nan, nan...    0.500000                 1\n",
       "839    bidirlstm        softsign        2016           [84]                 3                      4          2016          24  {'val_loss': [0.26589587330818176, 0.122616596...    1.000000                 1\n",
       "845    bidirlstm         sigmoid        2016           [84]                 2                      3          2016         699  {'val_loss': [0.0991985835134983, 0.0838311053...    0.333333                 1\n",
       "847    bidirlstm            tanh        2016           [84]                 4                      5          2016         699  {'val_loss': [0.11625007167458534, 0.088152725...    0.800000                 1\n",
       "850    bidirlstm    hard_sigmoid        2016           [84]                 1                      2          2016         699  {'val_loss': [0.1918892338871956, 0.0804009027...    0.500000                 1\n",
       "853    bidirlstm          linear        2016           [84]                 1                      2          2016         699  {'val_loss': [0.38908204436302185, 0.140204340...    0.500000                 1\n",
       "855     bidirgru         softmax        2016           [96]                 1                      2          2016         699  {'val_loss': [0.5315047353506088, 0.4967368692...    0.500000                 1\n",
       "859    bidirlstm            relu        2016           [84]                 2                      3          2016         699  {'val_loss': [0.3540915548801422, 0.2288026511...    0.333333                 1\n",
       "861     bidirgru            selu        2016           [96]                 1                      2          2016         699  {'val_loss': [0.19112471491098404, 0.062748592...    0.500000                 1\n",
       "868     bidirgru             elu        2016           [96]                 4                      5          2016         699  {'val_loss': [0.14729488641023636, 0.101810671...    0.800000                 1\n",
       "872     bidirgru        softplus        2016           [96]                 5                      6          2016         102  {'val_loss': [0.31372465193271637, 0.543935537...    1.000000                 1\n",
       "877     bidirgru        softsign        2016           [96]                 3                      4          2016          20  {'val_loss': [0.21943537890911102, 0.099840700...    1.000000                 1\n",
       "880     bidirgru         sigmoid        2016           [96]                 1                      2          2016         699  {'val_loss': [0.15585985779762268, 0.066754486...    0.500000                 1\n",
       "885     bidirgru            tanh        2016           [96]                 5                      6          2016          31  {'val_loss': [0.1623019203543663, 0.1118274591...    1.000000                 1\n",
       "890     bidirgru            relu        2016           [96]                 3                      4          2016          19  {'val_loss': [0.33869603276252747, 0.202489979...    1.000000                 1\n",
       "896     bidirgru    hard_sigmoid        2016           [96]                 4                      5          2016         699  {'val_loss': [0.08537391945719719, 0.085241772...    0.600000                 1\n",
       "899         lstm         softmax        2520          [210]                 1                      2          2520         699  {'val_loss': [0.624767541885376, 0.60677421092...    0.500000                 1\n",
       "901     bidirgru          linear        2016           [96]                 4                      5          2016         699  {'val_loss': [0.1515767052769661, 0.1162242256...    0.200000                 1\n",
       "905         lstm             elu        2520          [210]                 1                      2          2520         699  {'val_loss': [0.06147446669638157, 0.119858343...    0.500000                 1\n",
       "907         lstm        softplus        2520          [210]                 1                      2          2520         699  {'val_loss': [nan, nan, nan, nan, nan, nan, na...    0.500000                 1\n",
       "911         lstm            selu        2520          [210]                 7                      8          2520          21  {'val_loss': [0.08853099122643471, 0.069400615...    1.000000                 1\n",
       "914         lstm        softsign        2520          [210]                 1                      2          2520         699  {'val_loss': [0.12820779532194138, 0.156860418...    0.500000                 1\n",
       "917         lstm         sigmoid        2520          [210]                 1                      2          2520         699  {'val_loss': [0.15856315195560455, 0.138273537...    0.500000                 1\n",
       "919         lstm            tanh        2520          [210]                 2                      3          2520         699  {'val_loss': [0.11786993965506554, 0.440768748...    0.333333                 1\n",
       "922         lstm    hard_sigmoid        2520          [210]                 1                      2          2520         699  {'val_loss': [0.160988487303257, 0.13620035722...    0.500000                 1\n",
       "925         lstm          linear        2520          [210]                 1                      2          2520         699  {'val_loss': [0.07479841262102127, 0.419018417...    0.500000                 1\n",
       "927         lstm            relu        2520          [210]                 2                      3          2520         699  {'val_loss': [0.3286455124616623, 0.0831447616...    0.666667                 1\n",
       "930          gru         softmax        2520          [280]                 1                      2          2520         699  {'val_loss': [0.6408434212207794, 0.6159963011...    0.500000                 1\n",
       "...          ...             ...         ...            ...               ...                    ...           ...         ...                                                ...         ...               ...\n",
       "1937  bidirelamn        softplus         504      [840, 84]                 1                      2          5544         699  {'val_loss': [0.6966229975223541, 0.7000716626...    0.500000                 1\n",
       "1939  bidirelamn        softsign         504      [840, 84]                 1                      2          5544         699  {'val_loss': [0.18096768110990524, 0.215132914...    0.500000                 1\n",
       "1941  bidirelamn         sigmoid         504      [840, 84]                 1                      2          5544         699  {'val_loss': [0.12306655198335648, 0.092874780...    0.500000                 1\n",
       "1944  bidirelamn            tanh         504      [840, 84]                 1                      2          5544         699  {'val_loss': [3.3048731088638306, 0.5179111212...    0.500000                 1\n",
       "1949  bidirelamn            relu         504      [840, 84]                 3                      4          5544          32  {'val_loss': [0.3678734302520752, 0.3776267766...    1.000000                 1\n",
       "1951  bidirelamn    hard_sigmoid         504      [840, 84]                 2                      3          5544         699  {'val_loss': [0.48851917684078217, 0.885215461...    0.333333                 1\n",
       "1953  bidirelamn          linear         504      [840, 84]                 1                      2          5544         699  {'val_loss': [14.296613693237305, 43.580410003...    0.500000                 1\n",
       "1956   bidirlstm         softmax         504      [210, 21]                 1                      2          5544         699  {'val_loss': [0.5020935088396072, 0.4786742031...    0.500000                 1\n",
       "1963   bidirlstm             elu         504      [210, 21]                 2                      3          5544         699  {'val_loss': [0.14650917053222656, 0.228505104...    0.333333                 1\n",
       "1965   bidirlstm        softplus         504      [210, 21]                 1                      2          5544         699  {'val_loss': [nan, nan, nan, nan, nan, nan, na...    0.500000                 1\n",
       "1970   bidirlstm            selu         504      [210, 21]                 6                      7          5544         699  {'val_loss': [0.056628936901688576, 0.05869577...    0.571429                 1\n",
       "1981   bidirlstm        softsign         504      [210, 21]                10                     11          5544         699  {'val_loss': [0.07241494208574295, 0.046022083...    0.545455                 1\n",
       "1983   bidirlstm         sigmoid         504      [210, 21]                 1                      2          5544         699  {'val_loss': [0.21714766323566437, 0.124829865...    0.500000                 1\n",
       "1984   bidirlstm            tanh         504      [210, 21]                 8                      9          5544         699  {'val_loss': [0.07277422025799751, 0.060436032...    0.555556                 1\n",
       "1987   bidirlstm    hard_sigmoid         504      [210, 21]                 1                      2          5544         699  {'val_loss': [0.08768287301063538, 0.064077872...    0.500000                 1\n",
       "1990   bidirlstm    hard_sigmoid         504      [210, 21]                 1                      2          5544         699  {'val_loss': [0.15714696049690247, 0.092264004...    0.500000                 1\n",
       "1997   bidirlstm            relu         504      [210, 21]                 2                      3          5544         699  {'val_loss': [0.36303824186325073, 0.151833266...    0.333333                 1\n",
       "1999    bidirgru         softmax         504      [240, 24]                 1                      2          5544         699  {'val_loss': [0.45490314066410065, 0.415591105...    0.500000                 1\n",
       "2002   bidirlstm          linear         504      [210, 21]                 6                      7          5544         699  {'val_loss': [0.07830138131976128, 0.068730324...    0.571429                 1\n",
       "2007    bidirgru             elu         504      [240, 24]                 3                      4          5544           9  {'val_loss': [0.14139603078365326, 0.124228831...    1.000000                 1\n",
       "2009    bidirgru        softplus         504      [240, 24]                 1                      2          5544         699  {'val_loss': [0.5270393788814545, 0.1848405227...    0.500000                 1\n",
       "2014    bidirgru            selu         504      [240, 24]                 7                      8          5544          44  {'val_loss': [0.07983892410993576, 0.052296468...    1.000000                 1\n",
       "2019    bidirgru        softsign         504      [240, 24]                 3                      4          5544          11  {'val_loss': [0.10343407094478607, 0.061098249...    1.000000                 1\n",
       "2021    bidirgru         sigmoid         504      [240, 24]                 1                      2          5544         699  {'val_loss': [0.07101438567042351, 0.064784955...    0.500000                 1\n",
       "2025    bidirgru    hard_sigmoid         504      [240, 24]                 1                      2          5544         699  {'val_loss': [0.12143271416425705, 0.112146645...    0.500000                 1\n",
       "2029    bidirgru            tanh         504      [240, 24]                 6                      7          5544         699  {'val_loss': [0.09674326330423355, 0.084594491...    0.428571                 1\n",
       "2036    bidirgru            relu         504      [240, 24]                 5                      6          5544          19  {'val_loss': [0.13548076152801514, 0.099030070...    1.000000                 1\n",
       "2039        lstm         softmax        1008      [420, 84]                 1                      2          6048         699  {'val_loss': [0.6068264245986938, 0.5888428390...    0.500000                 1\n",
       "2042        lstm             elu        1008      [420, 84]                 1                      2          6048         699  {'val_loss': [0.1187330037355423, 0.0635951720...    0.500000                 1\n",
       "2048    bidirgru          linear         504      [240, 24]                 8                      9          5544         699  {'val_loss': [0.07061218097805977, 0.051096862...    0.444444                 1\n",
       "2051        lstm            selu        1008      [420, 84]                 5                      6          6048          16  {'val_loss': [0.10412943363189697, 0.074244044...    1.000000                 1\n",
       "2053        lstm        softplus        1008      [420, 84]                 1                      2          6048         699  {'val_loss': [nan, nan, nan, nan, nan, nan, na...    0.500000                 1\n",
       "2056        lstm        softsign        1008      [420, 84]                 1                      2          6048         699  {'val_loss': [0.11680077388882637, 0.064519202...    0.500000                 1\n",
       "2059        lstm         sigmoid        1008      [420, 84]                 1                      2          6048         699  {'val_loss': [0.1260082609951496, 0.0731949545...    0.500000                 1\n",
       "2061        lstm            tanh        1008      [420, 84]                 2                      3          6048         699  {'val_loss': [0.1954302415251732, 0.0875136386...    0.333333                 1\n",
       "2064        lstm    hard_sigmoid        1008      [420, 84]                 1                      2          6048         699  {'val_loss': [0.06562408804893494, 0.125232353...    0.500000                 1\n",
       "2069        lstm          linear        1008      [420, 84]                 2                      3          6048         699  {'val_loss': [0.11236365884542465, 0.103507582...    0.333333                 1\n",
       "2071        lstm            relu        1008      [420, 84]                 2                      3          6048         699  {'val_loss': [11.243340492248535, 0.3278637602...    0.333333                 1\n",
       "2073         gru         softmax        1008     [560, 112]                 1                      2          6048         699  {'val_loss': [0.5207083225250244, 0.4966490864...    0.500000                 1\n",
       "2077         gru             elu        1008     [560, 112]                 1                      2          6048         699  {'val_loss': [0.17723175138235092, 0.344463855...    0.500000                 1\n",
       "2080         gru        softplus        1008     [560, 112]                 1                      2          6048         699  {'val_loss': [0.11349379643797874, 0.500800535...    0.500000                 1\n",
       "2085         gru        softsign        1008     [560, 112]                 2                      3          6048         699  {'val_loss': [0.14544736593961716, 0.240502096...    0.333333                 1\n",
       "2087         gru            tanh        1008     [560, 112]                 1                      2          6048         699  {'val_loss': [0.18071196228265762, 0.296192735...    0.500000                 1\n",
       "2089         gru         sigmoid        1008     [560, 112]                 1                      2          6048         699  {'val_loss': [0.19926133751869202, 0.132511824...    0.500000                 1\n",
       "2092         gru    hard_sigmoid        1008     [560, 112]                 1                      2          6048         699  {'val_loss': [0.23749250918626785, 0.122110757...    0.500000                 1\n",
       "2094         gru            relu        1008     [560, 112]                 1                      2          6048         699  {'val_loss': [0.37027251720428467, 0.087137483...    0.500000                 1\n",
       "2097         gru          linear        1008     [560, 112]                 1                      2          6048         699  {'val_loss': [0.12047366052865982, 0.073414426...    0.500000                 1\n",
       "2099         gru            selu        1008     [560, 112]                 8                      9          6048         699  {'val_loss': [0.061819326132535934, 0.06218323...    0.444444                 1\n",
       "2102       elman         softmax        1008    [1680, 336]                 1                      2          6048         699  {'val_loss': [0.6571272313594818, 0.6314687728...    0.500000                 1\n",
       "2107       elman             elu        1008    [1680, 336]                 2                      3          6048         699  {'val_loss': [475.8356628417969, 2.59876072406...    0.333333                 1\n",
       "2109       elman        softplus        1008    [1680, 336]                 1                      2          6048         699  {'val_loss': [30.458255767822266, 6295.1337890...    0.500000                 1\n",
       "2111       elman            selu        1008    [1680, 336]                 2                      3          6048         699  {'val_loss': [38.51159477233887, 345.633377075...    0.633333                 1\n",
       "2113       elman        softsign        1008    [1680, 336]                 1                      2          6048         699  {'val_loss': [0.5293747186660767, 0.0578305795...    0.500000                 1\n",
       "2115       elman            tanh        1008    [1680, 336]                 1                      2          6048         699  {'val_loss': [0.1649644449353218, 0.0772733949...    0.500000                 1\n",
       "2117       elman         sigmoid        1008    [1680, 336]                 1                      2          6048         699  {'val_loss': [0.16216256469488144, 0.159378886...    0.500000                 1\n",
       "2120       elman    hard_sigmoid        1008    [1680, 336]                 1                      2          6048         699  {'val_loss': [0.6222150325775146, 0.9391079246...    0.500000                 1\n",
       "2123       elman          linear        1008    [1680, 336]                 1                      2          6048         699  {'val_loss': [nan, nan, nan, nan, nan, nan, na...    0.500000                 1\n",
       "2125  bidirelamn         softmax        1008     [840, 168]                 1                      2          6048         699  {'val_loss': [0.5706239342689514, 0.5330109894...    0.500000                 1\n",
       "2127       elman            relu        1008    [1680, 336]                 2                      3          6048         699  {'val_loss': [nan, nan, nan, nan, nan, nan, na...    0.333333                 1\n",
       "2129  bidirelamn             elu        1008     [840, 168]                 1                      2          6048         699  {'val_loss': [55.58534240722656, 2309.71716308...    0.500000                 1\n",
       "2131  bidirelamn            selu        1008     [840, 168]                 1                      2          6048         699  {'val_loss': [nan, nan, nan, nan, nan, nan, na...    0.500000                 1\n",
       "2134  bidirelamn        softplus        1008     [840, 168]                 1                      2          6048         699  {'val_loss': [4.576709270477295, 4.18876028060...    0.500000                 1\n",
       "2137  bidirelamn            tanh        1008     [840, 168]                 1                      2          6048         699  {'val_loss': [15.524348258972168, 0.0989822000...    0.500000                 1\n",
       "2139  bidirelamn        softsign        1008     [840, 168]                 2                      3          6048         699  {'val_loss': [0.18358035385608673, 0.177182152...    0.333333                 1\n",
       "2141  bidirelamn         sigmoid        1008     [840, 168]                 1                      2          6048         699  {'val_loss': [1.349938154220581, 0.36193910241...    0.500000                 1\n",
       "2147  bidirelamn    hard_sigmoid        1008     [840, 168]                 1                      2          6048         699  {'val_loss': [0.6198358535766602, 1.4053142070...    0.500000                 1\n",
       "2149  bidirelamn          linear        1008     [840, 168]                 1                      2          6048         699  {'val_loss': [4.787649631500244, 453.822784423...    0.500000                 1\n",
       "2151   bidirlstm         softmax        1008      [210, 42]                 1                      2          6048         699  {'val_loss': [0.671904444694519, 0.64560319483...    0.500000                 1\n",
       "2157   bidirlstm             elu        1008      [210, 42]                 5                      6          6048          15  {'val_loss': [0.1149747408926487, 0.1343164779...    1.000000                 1\n",
       "2163   bidirlstm            selu        1008      [210, 42]                 7                      8          6048          27  {'val_loss': [0.08483482524752617, 0.044388677...    1.000000                 1\n",
       "2165   bidirlstm        softplus        1008      [210, 42]                 1                      2          6048         699  {'val_loss': [nan, nan, nan, nan, nan, nan, na...    0.500000                 1\n",
       "2172   bidirlstm        softsign        1008      [210, 42]                 5                      6          6048          20  {'val_loss': [0.11547976732254028, 0.077761843...    1.000000                 1\n",
       "2176   bidirlstm            tanh        1008      [210, 42]                 3                      4          6048           8  {'val_loss': [0.09921572729945183, 0.111231882...    1.000000                 1\n",
       "2178   bidirlstm         sigmoid        1008      [210, 42]                 1                      2          6048         699  {'val_loss': [0.0998789630830288, 0.0897136703...    0.500000                 1\n",
       "2180   bidirlstm    hard_sigmoid        1008      [210, 42]                 1                      2          6048         699  {'val_loss': [0.06154952198266983, 0.124688014...    0.500000                 1\n",
       "2183   bidirlstm            relu        1008      [210, 42]                 1                      2          6048         699  {'val_loss': [0.48099716007709503, 0.099537793...    0.500000                 1\n",
       "2189   bidirlstm          linear        1008      [210, 42]                 6                      7          6048         699  {'val_loss': [0.10198316723108292, 0.083399645...    0.428571                 1\n",
       "2191    bidirgru         softmax        1008      [240, 48]                 1                      2          6048         699  {'val_loss': [0.600701779127121, 0.55793493986...    0.500000                 1\n",
       "2193    bidirgru             elu        1008      [240, 48]                 1                      2          6048         699  {'val_loss': [0.13975191488862038, 0.067907575...    0.500000                 1\n",
       "2202  bidirelamn            relu        1008     [840, 168]                16                     17          6048         699  {'val_loss': [0.009454482700675726, 0.00280793...    0.352941                 1\n",
       "2206    bidirgru            selu        1008      [240, 48]                12                     13          6048         699  {'val_loss': [0.05465235933661461, 0.033692337...    0.461538                 1\n",
       "2214    bidirgru        softplus        1008      [240, 48]                 4                      5          6048         699  {'val_loss': [0.47333911061286926, 0.095392327...    0.600000                 1\n",
       "2222    bidirgru        softsign        1008      [240, 48]                 8                      9          6048         699  {'val_loss': [0.07203998789191246, 0.062921402...    0.444444                 1\n",
       "2224    bidirgru            tanh        1008      [240, 48]                 6                      7          6048         699  {'val_loss': [0.090444166213274, 0.06542074494...    0.285714                 1\n",
       "2227    bidirgru    hard_sigmoid        1008      [240, 48]                 1                      2          6048         699  {'val_loss': [0.06618020497262478, 0.067799944...    0.500000                 1\n",
       "2232    bidirgru         sigmoid        1008      [240, 48]                 2                      3          6048         699  {'val_loss': [0.0820370614528656, 0.1000803373...    0.333333                 1\n",
       "2238    bidirgru            relu        1008      [240, 48]                 7                      8          6048          22  {'val_loss': [0.11357834935188293, 0.086937371...    1.000000                 1\n",
       "2242        lstm         softmax        1512     [420, 126]                 1                      2          6552         699  {'val_loss': [0.47188612818717957, 0.456277340...    0.500000                 1\n",
       "2244    bidirgru          linear        1008      [240, 48]                 6                      7          6048         699  {'val_loss': [0.08894367516040802, 0.080607678...    0.285714                 1\n",
       "2248        lstm             elu        1512     [420, 126]                 1                      2          6552         699  {'val_loss': [0.10369211062788963, 0.063938289...    0.500000                 1\n",
       "2251        lstm        softplus        1512     [420, 126]                 1                      2          6552         699  {'val_loss': [nan, nan, nan, nan, nan, nan, na...    0.500000                 1\n",
       "2256        lstm            selu        1512     [420, 126]                 7                      8          6552          24  {'val_loss': [0.06291420944035053, 0.022522545...    1.000000                 1\n",
       "2258        lstm            tanh        1512     [420, 126]                 1                      2          6552         699  {'val_loss': [0.06750988587737083, 0.086313582...    0.500000                 1\n",
       "2262        lstm         sigmoid        1512     [420, 126]                 1                      2          6552         699  {'val_loss': [0.17722100764513016, 0.087378371...    0.500000                 1\n",
       "2264        lstm    hard_sigmoid        1512     [420, 126]                 1                      2          6552         699  {'val_loss': [0.13087519630789757, 0.111823756...    0.500000                 1\n",
       "2266        lstm        softsign        1512     [420, 126]                 6                      7          6552         699  {'val_loss': [0.07547434791922569, 0.073706272...    0.571429                 1\n",
       "2270        lstm            relu        1512     [420, 126]                 1                      2          6552         699  {'val_loss': [0.0789199024438858, 0.3463283181...    0.500000                 1\n",
       "2273         gru         softmax        1512     [560, 168]                 1                      2          6552         699  {'val_loss': [0.6827925145626068, 0.6555613279...    0.500000                 1\n",
       "2278         gru             elu        1512     [560, 168]                 3                      4          6552           7  {'val_loss': [0.11210501194000244, 0.067371591...    1.000000                 1\n",
       "2281        lstm          linear        1512     [420, 126]                 4                      5          6552         699  {'val_loss': [0.1825798749923706, 0.1694765761...    0.600000                 1\n",
       "2284         gru            selu        1512     [560, 168]                 3                      4          6552           4  {'val_loss': [0.12242581322789192, 0.052730539...    1.000000                 1\n",
       "2286         gru        softplus        1512     [560, 168]                 1                      2          6552         699  {'val_loss': [0.24126195162534714, 0.562865778...    0.500000                 1\n",
       "2288         gru        softsign        1512     [560, 168]                 1                      2          6552         699  {'val_loss': [0.15728703141212463, 0.323601275...    0.500000                 1\n",
       "2291         gru            tanh        1512     [560, 168]                 1                      2          6552         699  {'val_loss': [0.15788646042346954, 0.405916213...    0.500000                 1\n",
       "2294         gru    hard_sigmoid        1512     [560, 168]                 1                      2          6552         699  {'val_loss': [0.45355117321014404, 0.128906067...    0.500000                 1\n",
       "2296         gru         sigmoid        1512     [560, 168]                 2                      3          6552         699  {'val_loss': [0.24089817702770233, 0.129290848...    0.333333                 1\n",
       "2298         gru            relu        1512     [560, 168]                 1                      2          6552         699  {'val_loss': [0.2542557641863823, 0.0878030247...    0.500000                 1\n",
       "2300         gru          linear        1512     [560, 168]                 1                      2          6552         699  {'val_loss': [0.0965939536690712, 0.0841231979...    0.500000                 1\n",
       "2302       elman             elu        1512    [1680, 504]                 1                      2          6552         699  {'val_loss': [47.95561218261719, 0.05938814207...    0.500000                 1\n",
       "2304       elman         softmax        1512    [1680, 504]                 1                      2          6552         699  {'val_loss': [0.6548601388931274, 0.6296121776...    0.500000                 1\n",
       "2306       elman            selu        1512    [1680, 504]                 1                      2          6552         699  {'val_loss': [633.37060546875, 1179.9948730468...    0.500000                 1\n",
       "2308       elman        softplus        1512    [1680, 504]                 1                      2          6552         699  {'val_loss': [23.538007736206055, 7.6927015781...    0.500000                 1\n",
       "2310       elman        softsign        1512    [1680, 504]                 1                      2          6552         699  {'val_loss': [7.023441314697266, 0.55131703615...    0.500000                 1\n",
       "2313       elman            tanh        1512    [1680, 504]                 1                      2          6552         699  {'val_loss': [0.0625697672367096, 0.0757897570...    0.500000                 1\n",
       "2318       elman         sigmoid        1512    [1680, 504]                 2                      3          6552         699  {'val_loss': [1.3756086826324463, 0.2213354110...    0.333333                 1\n",
       "2320       elman    hard_sigmoid        1512    [1680, 504]                 2                      3          6552         699  {'val_loss': [1.227897822856903, 1.64721822738...    0.333333                 1\n",
       "2322       elman            relu        1512    [1680, 504]                 1                      2          6552         699  {'val_loss': [nan, nan, nan, nan, nan, nan, na...    0.500000                 1\n",
       "2324  bidirelamn         softmax        1512     [840, 252]                 1                      2          6552         699  {'val_loss': [0.6027048528194427, 0.5654954016...    0.500000                 1\n",
       "2326  bidirelamn             elu        1512     [840, 252]                 1                      2          6552         699  {'val_loss': [64.48777389526367, 3262.76245117...    0.500000                 1\n",
       "2328       elman          linear        1512    [1680, 504]                 1                      2          6552         699  {'val_loss': [24504.8173828125, nan, nan, nan,...    0.500000                 1\n",
       "2330  bidirelamn            selu        1512     [840, 252]                 1                      2          6552         699  {'val_loss': [120.33261108398438, 2329.1933593...    0.500000                 1\n",
       "2333  bidirelamn        softsign        1512     [840, 252]                 1                      2          6552         699  {'val_loss': [0.3565644323825836, 1.5945081710...    0.500000                 1\n",
       "2336  bidirelamn            tanh        1512     [840, 252]                 1                      2          6552         699  {'val_loss': [11.646546363830566, 0.2651017233...    0.500000                 1\n",
       "2339  bidirelamn        softplus        1512     [840, 252]                 2                      3          6552         699  {'val_loss': [9.022808074951172, 0.27727264165...    0.333333                 1\n",
       "2343  bidirelamn         sigmoid        1512     [840, 252]                 2                      3          6552         699  {'val_loss': [0.15803233534097672, 0.083446612...    0.333333                 1\n",
       "2348  bidirelamn    hard_sigmoid        1512     [840, 252]                 2                      3          6552         699  {'val_loss': [1.3304511904716492, 1.9834116101...    0.333333                 1\n",
       "2350  bidirelamn            relu        1512     [840, 252]                 2                      3          6552         699  {'val_loss': [0.44165556132793427, 0.391929775...    0.333333                 1\n",
       "2352   bidirlstm         softmax        1512      [210, 63]                 1                      2          6552         699  {'val_loss': [0.6187992691993713, 0.5943061709...    0.500000                 1\n",
       "2355  bidirelamn          linear        1512     [840, 252]                 1                      2          6552         699  {'val_loss': [3390.8712158203125, 958.81076049...    0.500000                 1\n",
       "2361   bidirlstm             elu        1512      [210, 63]                 3                      4          6552          10  {'val_loss': [0.06434760615229607, 0.058221271...    1.000000                 1\n",
       "2363   bidirlstm        softplus        1512      [210, 63]                 1                      2          6552         699  {'val_loss': [nan, nan, nan, nan, nan, nan, na...    0.500000                 1\n",
       "2370   bidirlstm        softsign        1512      [210, 63]                 5                      6          6552           9  {'val_loss': [0.10249042510986328, 0.090073514...    1.000000                 1\n",
       "2374   bidirlstm            selu        1512      [210, 63]                11                     12          6552          25  {'val_loss': [0.09115772694349289, 0.030247288...    1.000000                 1\n",
       "2376   bidirlstm            tanh        1512      [210, 63]                 1                      2          6552         699  {'val_loss': [0.06871934607625008, 0.062969136...    0.500000                 1\n",
       "2378   bidirlstm         sigmoid        1512      [210, 63]                 1                      2          6552         699  {'val_loss': [0.0736440010368824, 0.0943159386...    0.500000                 1\n",
       "2382   bidirlstm    hard_sigmoid        1512      [210, 63]                 1                      2          6552         699  {'val_loss': [0.1469312459230423, 0.0765047334...    0.500000                 1\n",
       "2390   bidirlstm          linear        1512      [210, 63]                 4                      5          6552         699  {'val_loss': [0.09426280483603477, 0.085659496...    0.200000                 1\n",
       "2392   bidirlstm            relu        1512      [210, 63]                 4                      5          6552         699  {'val_loss': [0.12138104811310768, 0.094548139...    0.600000                 1\n",
       "2396    bidirgru         softmax        1512      [240, 72]                 1                      2          6552         699  {'val_loss': [0.6929214000701904, 0.6478087306...    0.500000                 1\n",
       "2404    bidirgru            selu        1512      [240, 72]                 7                      8          6552          15  {'val_loss': [0.0627257339656353, 0.0736794210...    1.000000                 1\n",
       "2406    bidirgru        softplus        1512      [240, 72]                 1                      2          6552         699  {'val_loss': [0.15661513805389404, 0.077807497...    0.500000                 1\n",
       "2411    bidirgru             elu        1512      [240, 72]                 6                      7          6552         699  {'val_loss': [0.07961174100637436, 0.071388587...    0.571429                 1\n",
       "2419    bidirgru            tanh        1512      [240, 72]                 4                      5          6552         699  {'val_loss': [0.10817597061395645, 0.071726363...    0.400000                 1\n",
       "2422    bidirgru         sigmoid        1512      [240, 72]                 1                      2          6552         699  {'val_loss': [0.21529989689588547, 0.190238513...    0.500000                 1\n",
       "2424    bidirgru    hard_sigmoid        1512      [240, 72]                 1                      2          6552         699  {'val_loss': [0.1654612272977829, 0.0820692777...    0.500000                 1\n",
       "2427    bidirgru        softsign        1512      [240, 72]                 8                      9          6552         699  {'val_loss': [0.0549391508102417, 0.0499398205...    0.333333                 1\n",
       "2429    bidirgru          linear        1512      [240, 72]                 1                      2          6552         699  {'val_loss': [0.16705023497343063, 0.093512475...    0.500000                 1\n",
       "2432    bidirgru            relu        1512      [240, 72]                 3                      4          6552          12  {'val_loss': [0.2425340786576271, 0.1009999401...    1.000000                 1\n",
       "2435        lstm         softmax        2016     [420, 168]                 1                      2          7056         699  {'val_loss': [0.5677637904882431, 0.5505574643...    0.500000                 1\n",
       "2441        lstm             elu        2016     [420, 168]                 3                      4          7056          46  {'val_loss': [0.09696029126644135, 0.086629398...    1.000000                 1\n",
       "2443        lstm        softplus        2016     [420, 168]                 1                      2          7056         699  {'val_loss': [nan, nan, nan, nan, nan, nan, na...    0.500000                 1\n",
       "2445        lstm        softsign        2016     [420, 168]                 1                      2          7056         699  {'val_loss': [0.18415351957082748, 0.208475463...    0.500000                 1\n",
       "2449        lstm            tanh        2016     [420, 168]                 1                      2          7056         699  {'val_loss': [0.23123571276664734, 0.059193661...    0.500000                 1\n",
       "2451        lstm         sigmoid        2016     [420, 168]                 1                      2          7056         699  {'val_loss': [0.06565298140048981, 0.065692424...    0.500000                 1\n",
       "2454        lstm    hard_sigmoid        2016     [420, 168]                 1                      2          7056         699  {'val_loss': [0.1873912811279297, 0.0778605379...    0.500000                 1\n",
       "2458        lstm            selu        2016     [420, 168]                12                     13          7056         699  {'val_loss': [0.05154094658792019, 0.025774080...    0.461538                 1\n",
       "2461        lstm            relu        2016     [420, 168]                 2                      3          7056         699  {'val_loss': [374.7257385253906, 0.24386104941...    0.333333                 1\n",
       "2464         gru         softmax        2016     [560, 224]                 1                      2          7056         699  {'val_loss': [0.7063301801681519, 0.6790731847...    0.500000                 1\n",
       "2467        lstm          linear        2016     [420, 168]                 2                      3          7056         699  {'val_loss': [0.32356463372707367, 0.343315705...    0.333333                 1\n",
       "2469         gru            selu        2016     [560, 224]                 1                      2          7056         699  {'val_loss': [0.06448863260447979, 0.070952069...    0.500000                 1\n",
       "2472         gru             elu        2016     [560, 224]                 3                      4          7056         112  {'val_loss': [0.07651127502322197, 0.079492669...    1.000000                 1\n",
       "2475         gru        softplus        2016     [560, 224]                 1                      2          7056         699  {'val_loss': [1.4956951141357422, 0.2025217264...    0.500000                 1\n",
       "2477         gru            tanh        2016     [560, 224]                 1                      2          7056         699  {'val_loss': [0.12363731861114502, 0.081483285...    0.500000                 1\n",
       "2481         gru        softsign        2016     [560, 224]                 3                      4          7056          13  {'val_loss': [0.09816183149814606, 0.078751999...    1.000000                 1\n",
       "2486         gru         sigmoid        2016     [560, 224]                 2                      3          7056         699  {'val_loss': [0.1718287467956543, 0.3265133798...    0.333333                 1\n",
       "2489         gru    hard_sigmoid        2016     [560, 224]                 2                      3          7056         699  {'val_loss': [0.10670722275972366, 0.220568232...    0.333333                 1\n",
       "2493         gru            relu        2016     [560, 224]                 3                      4          7056          14  {'val_loss': [0.1814209669828415, 0.1071994602...    1.000000                 1\n",
       "2496         gru          linear        2016     [560, 224]                 3                      4          7056           7  {'val_loss': [0.23867519199848175, 0.105924654...    1.000000                 1\n",
       "2498       elman         softmax        2016    [1680, 672]                 1                      2          7056         699  {'val_loss': [0.599197506904602, 0.57545709609...    0.500000                 1\n",
       "2500       elman             elu        2016    [1680, 672]                 1                      2          7056         699  {'val_loss': [93.31765747070312, 64.1185150146...    0.500000                 1\n",
       "2502       elman            selu        2016    [1680, 672]                 1                      2          7056         699  {'val_loss': [nan, nan, nan, nan, nan, nan, na...    0.500000                 1\n",
       "2504       elman        softplus        2016    [1680, 672]                 1                      2          7056         699  {'val_loss': [25.44868564605713, 205775.078125...    0.500000                 1\n",
       "2506       elman        softsign        2016    [1680, 672]                 1                      2          7056         699  {'val_loss': [3.6687450408935547, 0.3913789093...    0.500000                 1\n",
       "2508       elman            tanh        2016    [1680, 672]                 1                      2          7056         699  {'val_loss': [117.64476013183594, 4.4763824939...    0.500000                 1\n",
       "2510       elman         sigmoid        2016    [1680, 672]                 1                      2          7056         699  {'val_loss': [0.12322569638490677, 0.822585195...    0.500000                 1\n",
       "2512       elman            relu        2016    [1680, 672]                 1                      2          7056         699  {'val_loss': [nan, nan, nan, nan, nan, nan, na...    0.500000                 1\n",
       "2514       elman    hard_sigmoid        2016    [1680, 672]                 1                      2          7056         699  {'val_loss': [1.0610771775245667, 2.2958028316...    0.500000                 1\n",
       "2516  bidirelamn         softmax        2016     [840, 336]                 1                      2          7056         699  {'val_loss': [0.6214663088321686, 0.5841623544...    0.500000                 1\n",
       "2518       elman          linear        2016    [1680, 672]                 1                      2          7056         699  {'val_loss': [26899.798828125, 2319893528576.0...    0.500000                 1\n",
       "2520  bidirelamn             elu        2016     [840, 336]                 1                      2          7056         699  {'val_loss': [13.64760971069336, 25.7135715484...    0.500000                 1\n",
       "2522  bidirelamn            selu        2016     [840, 336]                 1                      2          7056         699  {'val_loss': [nan, nan, nan, nan, nan, nan, na...    0.500000                 1\n",
       "2525  bidirelamn        softplus        2016     [840, 336]                 1                      2          7056         699  {'val_loss': [2.745560646057129, 0.62969821691...    0.500000                 1\n",
       "2528  bidirelamn            tanh        2016     [840, 336]                 1                      2          7056         699  {'val_loss': [1.0294718146324158, 0.0802628397...    0.500000                 1\n",
       "2530  bidirelamn        softsign        2016     [840, 336]                 2                      3          7056         699  {'val_loss': [1.191558599472046, 0.91667765378...    0.333333                 1\n",
       "2533  bidirelamn         sigmoid        2016     [840, 336]                 1                      2          7056         699  {'val_loss': [1.5018829703330994, 0.2236690297...    0.500000                 1\n",
       "2538  bidirelamn    hard_sigmoid        2016     [840, 336]                 2                      3          7056         699  {'val_loss': [5.301624536514282, 0.47389495372...    0.333333                 1\n",
       "2541  bidirelamn          linear        2016     [840, 336]                 1                      2          7056         699  {'val_loss': [8271384.75, 277970976.0, 6.49942...    0.500000                 1\n",
       "2543   bidirlstm         softmax        2016      [210, 84]                 1                      2          7056         699  {'val_loss': [0.5716935396194458, 0.5484902560...    0.500000                 1\n",
       "2548  bidirelamn            relu        2016     [840, 336]                 5                      6          7056           2  {'val_loss': [0.18928514420986176, 0.009749777...    1.000000                 1\n",
       "2555   bidirlstm             elu        2016      [210, 84]                 5                      6          7056           9  {'val_loss': [0.121856939047575, 0.09877430647...    1.000000                 1\n",
       "2557   bidirlstm        softplus        2016      [210, 84]                 1                      2          7056         699  {'val_loss': [nan, nan, nan, nan, nan, nan, na...    0.500000                 1\n",
       "2564   bidirlstm            selu        2016      [210, 84]                15                     16          7056          13  {'val_loss': [0.032288371585309505, 0.02196237...    1.000000                 1\n",
       "2573   bidirlstm            tanh        2016      [210, 84]                 4                      5          7056         699  {'val_loss': [0.10067905858159065, 0.095259692...    0.400000                 1\n",
       "2576   bidirlstm        softsign        2016      [210, 84]                12                     13          7056         699  {'val_loss': [0.05721994675695896, 0.035908428...    0.461538                 1\n",
       "2579   bidirlstm    hard_sigmoid        2016      [210, 84]                 1                      2          7056         699  {'val_loss': [0.20864005386829376, 0.081358764...    0.500000                 1\n",
       "2583   bidirlstm         sigmoid        2016      [210, 84]                 2                      3          7056         699  {'val_loss': [0.11477350816130638, 0.076861314...    0.333333                 1\n",
       "2590   bidirlstm            relu        2016      [210, 84]                 5                      6          7056          13  {'val_loss': [0.12176647409796715, 0.120105225...    1.000000                 1\n",
       "2593   bidirlstm          linear        2016      [210, 84]                 5                      6          7056          29  {'val_loss': [0.09539033845067024, 0.118580173...    1.000000                 1\n",
       "2596    bidirgru         softmax        2016      [240, 96]                 1                      2          7056         699  {'val_loss': [0.585785299539566, 0.54645633697...    0.500000                 1\n",
       "2600    bidirgru             elu        2016      [240, 96]                 3                      4          7056          24  {'val_loss': [0.16169217228889465, 0.106565538...    1.000000                 1\n",
       "2604    bidirgru            selu        2016      [240, 96]                 3                      4          7056           7  {'val_loss': [0.08349677175283432, 0.087648723...    1.000000                 1\n",
       "2609    bidirgru        softsign        2016      [240, 96]                 3                      4          7056          16  {'val_loss': [0.16145045310258865, 0.103340368...    1.000000                 1\n",
       "2613    bidirgru        softplus        2016      [240, 96]                 2                      3          7056         699  {'val_loss': [0.15123723447322845, 0.213058620...    0.333333                 1\n",
       "2617    bidirgru         sigmoid        2016      [240, 96]                 1                      2          7056         699  {'val_loss': [0.06020905822515488, 0.086765609...    0.500000                 1\n",
       "2619    bidirgru    hard_sigmoid        2016      [240, 96]                 1                      2          7056         699  {'val_loss': [0.06364467553794384, 0.064776595...    0.500000                 1\n",
       "2623    bidirgru            tanh        2016      [240, 96]                 6                      7          7056         699  {'val_loss': [0.08361439406871796, 0.066727232...    0.428571                 1\n",
       "2625    bidirgru          linear        2016      [240, 96]                 1                      2          7056         699  {'val_loss': [0.08312393724918365, 0.100256085...    0.500000                 1\n",
       "2629        lstm         softmax        2520     [420, 210]                 1                      2          7560         699  {'val_loss': [0.5681084394454956, 0.5509952306...    0.500000                 1\n",
       "2631    bidirgru            relu        2016      [240, 96]                 6                      7          7056         699  {'val_loss': [0.13243379443883896, 0.095593873...    0.571429                 1\n",
       "2635        lstm             elu        2520     [420, 210]                 1                      2          7560         699  {'val_loss': [0.11923468858003616, 0.103030774...    0.500000                 1\n",
       "2637        lstm        softplus        2520     [420, 210]                 1                      2          7560         699  {'val_loss': [nan, nan, nan, nan, nan, nan, na...    0.500000                 1\n",
       "2645        lstm            selu        2520     [420, 210]                 5                      6          7560          33  {'val_loss': [0.11084724590182304, 0.113700579...    1.000000                 1\n",
       "2648        lstm        softsign        2520     [420, 210]                 6                      7          7560         699  {'val_loss': [0.15507736429572105, 0.107112381...    0.571429                 1\n",
       "2651        lstm            tanh        2520     [420, 210]                 3                      4          7560          26  {'val_loss': [0.3203085660934448, 0.3383859843...    1.000000                 1\n",
       "2653        lstm         sigmoid        2520     [420, 210]                 1                      2          7560         699  {'val_loss': [0.22444338351488113, 0.142343483...    0.500000                 1\n",
       "2655        lstm    hard_sigmoid        2520     [420, 210]                 1                      2          7560         699  {'val_loss': [0.06394323334097862, 0.065943783...    0.500000                 1\n",
       "2657        lstm            relu        2520     [420, 210]                 1                      2          7560         699  {'val_loss': [0.2795484662055969, 0.0985789149...    0.500000                 1\n",
       "2659        lstm          linear        2520     [420, 210]                 1                      2          7560         699  {'val_loss': [0.34715236723423004, 0.065966114...    0.500000                 1\n",
       "2661         gru         softmax        2520     [560, 280]                 1                      2          7560         699  {'val_loss': [0.5797857344150543, 0.5558061897...    0.500000                 1\n",
       "2663         gru             elu        2520     [560, 280]                 1                      2          7560         699  {'val_loss': [0.20658811926841736, 0.500733226...    0.500000                 1\n",
       "2665         gru            selu        2520     [560, 280]                 1                      2          7560         699  {'val_loss': [0.11079156398773193, 0.078074619...    0.500000                 1\n",
       "2668         gru        softplus        2520     [560, 280]                 1                      2          7560         699  {'val_loss': [0.44771598279476166, 0.062461400...    0.500000                 1\n",
       "2671         gru        softsign        2520     [560, 280]                 3                      4          7560           3  {'val_loss': [0.15202631056308746, 0.081231467...    1.000000                 1\n",
       "2673         gru            tanh        2520     [560, 280]                 1                      2          7560         699  {'val_loss': [0.10538836941123009, 0.063479054...    0.500000                 1\n",
       "2675         gru         sigmoid        2520     [560, 280]                 1                      2          7560         699  {'val_loss': [0.18300148099660873, 0.150665886...    0.500000                 1\n",
       "2677         gru    hard_sigmoid        2520     [560, 280]                 1                      2          7560         699  {'val_loss': [0.14732852578163147, 0.141183778...    0.500000                 1\n",
       "2679         gru            relu        2520     [560, 280]                 1                      2          7560         699  {'val_loss': [0.15802691131830215, 0.075650744...    0.500000                 1\n",
       "2681         gru          linear        2520     [560, 280]                 1                      2          7560         699  {'val_loss': [0.11360560357570648, 0.062505710...    0.500000                 1\n",
       "2683       elman         softmax        2520    [1680, 840]                 1                      2          7560         699  {'val_loss': [0.6341591775417328, 0.6096932291...    0.500000                 1\n",
       "2685       elman             elu        2520    [1680, 840]                 1                      2          7560         699  {'val_loss': [311.29534912109375, 83.049873352...    0.500000                 1\n",
       "2687       elman            selu        2520    [1680, 840]                 1                      2          7560         699  {'val_loss': [9606.82861328125, 150.2508926391...    0.500000                 1\n",
       "2689       elman        softplus        2520    [1680, 840]                 1                      2          7560         699  {'val_loss': [33.5136661529541, 25.83872795104...    0.500000                 1\n",
       "2692       elman        softsign        2520    [1680, 840]                 1                      2          7560         699  {'val_loss': [45.45520782470703, 22.5477180480...    0.500000                 1\n",
       "2697       elman         sigmoid        2520    [1680, 840]                 3                      4          7560          24  {'val_loss': [0.07544935494661331, 1.062725126...    1.000000                 1\n",
       "2699       elman    hard_sigmoid        2520    [1680, 840]                 1                      2          7560         699  {'val_loss': [1.4712646007537842, 3.2041640281...    0.500000                 1\n",
       "2701       elman            tanh        2520    [1680, 840]                 2                      3          7560         699  {'val_loss': [0.7690152823925018, 0.0958209224...    0.333333                 1\n",
       "2703       elman            relu        2520    [1680, 840]                 1                      2          7560         699  {'val_loss': [0.060299960896372795, 0.08596496...    0.500000                 1\n",
       "2705  bidirelamn         softmax        2520     [840, 420]                 1                      2          7560         699  {'val_loss': [0.4234108030796051, 0.3934638947...    0.500000                 1\n",
       "2709       elman          linear        2520    [1680, 840]                 1                      2          7560         699  {'val_loss': [nan, nan, nan, nan, nan, nan, na...    0.500000                 1\n",
       "2711  bidirelamn            selu        2520     [840, 420]                 1                      2          7560         699  {'val_loss': [nan, nan, nan, nan, nan, nan, na...    0.500000                 1\n",
       "2714  bidirelamn        softplus        2520     [840, 420]                 1                      2          7560         699  {'val_loss': [18.912104606628418, 0.2935480773...    0.500000                 1\n",
       "2717  bidirelamn        softsign        2520     [840, 420]                 1                      2          7560         699  {'val_loss': [0.5376138985157013, 0.0736353956...    0.500000                 1\n",
       "2719  bidirelamn             elu        2520     [840, 420]                 4                      5          7560         699  {'val_loss': [32.876644134521484, 729.66119384...    0.200000                 1\n",
       "2721  bidirelamn            tanh        2520     [840, 420]                 1                      2          7560         699  {'val_loss': [2.5868664979934692, 0.3647451996...    0.500000                 1\n",
       "2724  bidirelamn         sigmoid        2520     [840, 420]                 1                      2          7560         699  {'val_loss': [0.18790309876203537, 0.079225167...    0.500000                 1\n",
       "2730  bidirelamn    hard_sigmoid        2520     [840, 420]                 3                      4          7560          37  {'val_loss': [0.8809223175048828, 1.2616017460...    1.000000                 1\n",
       "2732  bidirelamn          linear        2520     [840, 420]                 1                      2          7560         699  {'val_loss': [69682520.0, 296032.0, 6338318827...    0.500000                 1\n",
       "2734   bidirlstm         softmax        2520     [210, 105]                 1                      2          7560         699  {'val_loss': [0.6185149550437927, 0.5943638682...    0.500000                 1\n",
       "2737   bidirlstm             elu        2520     [210, 105]                 1                      2          7560         699  {'val_loss': [0.05965292267501354, 0.062329966...    0.500000                 1\n",
       "2744   bidirlstm            selu        2520     [210, 105]                15                     16          7560          14  {'val_loss': [0.035311589017510414, 0.01039189...    1.000000                 1\n",
       "\n",
       "[822 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/danielp/Documents/Masters/Code/memory_capacity_retention_rnns/danny_masters/from_server/100_0_False_longest_sequence.log\", delimiter=\";\")\n",
    "df[\"nn_type\"] = df[\"nn_type\"].apply(lambda x: x.replace(\"INFO:root:\", \"\")) \n",
    "df[\"diff_small_large\"] = df[\"smallest_not_retained\"] - df[\"largest_retained\"]  \n",
    "df[\"model_params\"] = df.apply(lambda row: determine_model_parameters(row), axis=1)\n",
    "df[\"nodes_in_layer\"] = df[\"nodes_in_layer\"].apply(eval)\n",
    "df = df[df[\"diff_small_large\"]  == 1]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nn_type</th>\n",
       "      <th>activation_func</th>\n",
       "      <th>parameters</th>\n",
       "      <th>nodes_in_layer</th>\n",
       "      <th>largest_retained</th>\n",
       "      <th>smallest_not_retained</th>\n",
       "      <th>model_params</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>model_score</th>\n",
       "      <th>highest_F1</th>\n",
       "      <th>diff_small_large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2564</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>selu</td>\n",
       "      <td>2016</td>\n",
       "      <td>[210, 84]</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>7056</td>\n",
       "      <td>13</td>\n",
       "      <td>{'val_loss': [0.032288371585309505, 0.02196237...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>selu</td>\n",
       "      <td>2520</td>\n",
       "      <td>[210, 105]</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>7560</td>\n",
       "      <td>14</td>\n",
       "      <td>{'val_loss': [0.035311589017510414, 0.01039189...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        nn_type activation_func  parameters nodes_in_layer  largest_retained  smallest_not_retained  model_params  num_epochs                                        model_score  highest_F1  diff_small_large\n",
       "2564  bidirlstm            selu        2016      [210, 84]                15                     16          7056          13  {'val_loss': [0.032288371585309505, 0.02196237...         1.0                 1\n",
       "2744  bidirlstm            selu        2520     [210, 105]                15                     16          7560          14  {'val_loss': [0.035311589017510414, 0.01039189...         1.0                 1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df[\"nn_type\"] == \"bidirlstm\") & (df[(df[\"nn_type\"] == \"bidirlstm\")][\"largest_retained\"] == df[(df[\"nn_type\"] == \"bidirlstm\")][\"largest_retained\"].max())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nn_type</th>\n",
       "      <th>activation_func</th>\n",
       "      <th>parameters</th>\n",
       "      <th>nodes_in_layer</th>\n",
       "      <th>largest_retained</th>\n",
       "      <th>smallest_not_retained</th>\n",
       "      <th>model_params</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>model_score</th>\n",
       "      <th>highest_F1</th>\n",
       "      <th>diff_small_large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstm</td>\n",
       "      <td>elu</td>\n",
       "      <td>504</td>\n",
       "      <td>[42]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.4946219176054001, 0.2408708184...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lstm</td>\n",
       "      <td>selu</td>\n",
       "      <td>504</td>\n",
       "      <td>[42]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>504</td>\n",
       "      <td>7</td>\n",
       "      <td>{'val_loss': [0.0819605402648449, 0.0693724751...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softplus</td>\n",
       "      <td>504</td>\n",
       "      <td>[42]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.20116198807954788, 0.206449702...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softsign</td>\n",
       "      <td>504</td>\n",
       "      <td>[42]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.40316881239414215, 0.251443207...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lstm</td>\n",
       "      <td>tanh</td>\n",
       "      <td>504</td>\n",
       "      <td>[42]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>504</td>\n",
       "      <td>44</td>\n",
       "      <td>{'val_loss': [0.3318553566932678, 0.1949969530...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>lstm</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[42]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.08133256807923317, 0.071514669...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lstm</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[42]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.07580393180251122, 0.075959742...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>lstm</td>\n",
       "      <td>relu</td>\n",
       "      <td>504</td>\n",
       "      <td>[42]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.25778841227293015, 0.227367028...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lstm</td>\n",
       "      <td>linear</td>\n",
       "      <td>504</td>\n",
       "      <td>[42]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.3624194860458374, 0.1538776010...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>gru</td>\n",
       "      <td>softmax</td>\n",
       "      <td>504</td>\n",
       "      <td>[56]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5448723286390305, 0.5204579234...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>gru</td>\n",
       "      <td>elu</td>\n",
       "      <td>504</td>\n",
       "      <td>[56]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.4465404450893402, 0.2424310073...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>gru</td>\n",
       "      <td>selu</td>\n",
       "      <td>504</td>\n",
       "      <td>[56]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.3945378214120865, 0.0874072089...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>gru</td>\n",
       "      <td>softplus</td>\n",
       "      <td>504</td>\n",
       "      <td>[56]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5819623172283173, 0.0856886133...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>gru</td>\n",
       "      <td>softsign</td>\n",
       "      <td>504</td>\n",
       "      <td>[56]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.36055484414100647, 0.208033062...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>gru</td>\n",
       "      <td>tanh</td>\n",
       "      <td>504</td>\n",
       "      <td>[56]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.4152391701936722, 0.1948228254...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>gru</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[56]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.34265419840812683, 0.085719957...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>gru</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[56]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.26553022116422653, 0.064528800...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>gru</td>\n",
       "      <td>relu</td>\n",
       "      <td>504</td>\n",
       "      <td>[56]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.3832283616065979, 0.2987566590...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>gru</td>\n",
       "      <td>linear</td>\n",
       "      <td>504</td>\n",
       "      <td>[56]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>504</td>\n",
       "      <td>43</td>\n",
       "      <td>{'val_loss': [0.31459513306617737, 0.157367624...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>elman</td>\n",
       "      <td>softmax</td>\n",
       "      <td>504</td>\n",
       "      <td>[168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.7038005292415619, 0.6762956678...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>elman</td>\n",
       "      <td>elu</td>\n",
       "      <td>504</td>\n",
       "      <td>[168]</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>504</td>\n",
       "      <td>35</td>\n",
       "      <td>{'val_loss': [0.01022288529202342, 0.004784897...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>elman</td>\n",
       "      <td>selu</td>\n",
       "      <td>504</td>\n",
       "      <td>[168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>elman</td>\n",
       "      <td>softplus</td>\n",
       "      <td>504</td>\n",
       "      <td>[168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.11724359542131424, 0.067714590...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>elman</td>\n",
       "      <td>softsign</td>\n",
       "      <td>504</td>\n",
       "      <td>[168]</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.0036327834241092205, 0.0023907...</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>elman</td>\n",
       "      <td>tanh</td>\n",
       "      <td>504</td>\n",
       "      <td>[168]</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>504</td>\n",
       "      <td>16</td>\n",
       "      <td>{'val_loss': [0.006719990400597453, 0.00462339...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>elman</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[168]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.09701669961214066, 0.126788254...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>elman</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.08693477883934975, 0.089432314...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>elman</td>\n",
       "      <td>relu</td>\n",
       "      <td>504</td>\n",
       "      <td>[168]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>504</td>\n",
       "      <td>26</td>\n",
       "      <td>{'val_loss': [0.21049391478300095, 0.160464845...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>elman</td>\n",
       "      <td>linear</td>\n",
       "      <td>504</td>\n",
       "      <td>[168]</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.07618581131100655, 0.023449786...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softmax</td>\n",
       "      <td>504</td>\n",
       "      <td>[84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5991988778114319, 0.5611424148...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>elu</td>\n",
       "      <td>504</td>\n",
       "      <td>[84]</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.038599710911512375, 0.00683762...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>selu</td>\n",
       "      <td>504</td>\n",
       "      <td>[84]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softplus</td>\n",
       "      <td>504</td>\n",
       "      <td>[84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.11677606776356697, 0.247338593...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softsign</td>\n",
       "      <td>504</td>\n",
       "      <td>[84]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.05220537260174751, 0.007052829...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>tanh</td>\n",
       "      <td>504</td>\n",
       "      <td>[84]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>504</td>\n",
       "      <td>16</td>\n",
       "      <td>{'val_loss': [0.0015075012343004346, 0.0012468...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.09947529435157776, 0.067808486...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[84]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.09018612280488014, 0.084832493...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>relu</td>\n",
       "      <td>504</td>\n",
       "      <td>[84]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>504</td>\n",
       "      <td>16</td>\n",
       "      <td>{'val_loss': [0.2869787886738777, 0.1159043312...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>linear</td>\n",
       "      <td>504</td>\n",
       "      <td>[84]</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>504</td>\n",
       "      <td>26</td>\n",
       "      <td>{'val_loss': [0.04190049506723881, 0.013597493...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softmax</td>\n",
       "      <td>504</td>\n",
       "      <td>[21]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.663487434387207, 0.63724201917...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>elu</td>\n",
       "      <td>504</td>\n",
       "      <td>[21]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.37372808158397675, 0.234386362...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>selu</td>\n",
       "      <td>504</td>\n",
       "      <td>[21]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>504</td>\n",
       "      <td>20</td>\n",
       "      <td>{'val_loss': [0.08483178168535233, 0.083788037...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softplus</td>\n",
       "      <td>504</td>\n",
       "      <td>[21]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [1.1596860885620117, 0.6694509088...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softsign</td>\n",
       "      <td>504</td>\n",
       "      <td>[21]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>504</td>\n",
       "      <td>26</td>\n",
       "      <td>{'val_loss': [0.38953451812267303, 0.287065491...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>tanh</td>\n",
       "      <td>504</td>\n",
       "      <td>[21]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>504</td>\n",
       "      <td>21</td>\n",
       "      <td>{'val_loss': [0.36916880309581757, 0.244283460...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[21]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.08764307200908661, 0.093582563...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[21]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.06540227681398392, 0.072437830...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>relu</td>\n",
       "      <td>504</td>\n",
       "      <td>[21]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5630137622356415, 0.5116415321...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>linear</td>\n",
       "      <td>504</td>\n",
       "      <td>[21]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>504</td>\n",
       "      <td>24</td>\n",
       "      <td>{'val_loss': [0.3195510804653168, 0.2121522054...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softmax</td>\n",
       "      <td>504</td>\n",
       "      <td>[24]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5863576531410217, 0.5471096634...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>elu</td>\n",
       "      <td>504</td>\n",
       "      <td>[24]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.21432245522737503, 0.148047141...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>selu</td>\n",
       "      <td>504</td>\n",
       "      <td>[24]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>504</td>\n",
       "      <td>42</td>\n",
       "      <td>{'val_loss': [0.16468828171491623, 0.084260262...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softplus</td>\n",
       "      <td>504</td>\n",
       "      <td>[24]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.14249546825885773, 0.081475466...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softsign</td>\n",
       "      <td>504</td>\n",
       "      <td>[24]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.23640096187591553, 0.172316953...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>tanh</td>\n",
       "      <td>504</td>\n",
       "      <td>[24]</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.22417141497135162, 0.159498237...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[24]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [1.2608646154403687, 0.6526324152...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[24]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.062262656167149544, 0.06187883...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>relu</td>\n",
       "      <td>504</td>\n",
       "      <td>[24]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>504</td>\n",
       "      <td>32</td>\n",
       "      <td>{'val_loss': [0.3938422203063965, 0.3493473976...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>linear</td>\n",
       "      <td>504</td>\n",
       "      <td>[24]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>504</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.39541734755039215, 0.286482445...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>lstm</td>\n",
       "      <td>elu</td>\n",
       "      <td>504</td>\n",
       "      <td>[420, 42]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [1.8565932512283325, 0.3832542300...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softmax</td>\n",
       "      <td>504</td>\n",
       "      <td>[420, 42]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5618335157632828, 0.5442014038...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softplus</td>\n",
       "      <td>504</td>\n",
       "      <td>[420, 42]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>lstm</td>\n",
       "      <td>selu</td>\n",
       "      <td>504</td>\n",
       "      <td>[420, 42]</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5544</td>\n",
       "      <td>26</td>\n",
       "      <td>{'val_loss': [0.11091110482811928, 0.086871236...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softsign</td>\n",
       "      <td>504</td>\n",
       "      <td>[420, 42]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.0774071030318737, 0.0648136138...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>lstm</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[420, 42]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.09813069179654121, 0.073252826...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>lstm</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[420, 42]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.12797389551997185, 0.066876921...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>lstm</td>\n",
       "      <td>tanh</td>\n",
       "      <td>504</td>\n",
       "      <td>[420, 42]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5544</td>\n",
       "      <td>40</td>\n",
       "      <td>{'val_loss': [0.07084476388990879, 0.071869628...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>lstm</td>\n",
       "      <td>relu</td>\n",
       "      <td>504</td>\n",
       "      <td>[420, 42]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.4618387520313263, 0.5346571207...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>lstm</td>\n",
       "      <td>linear</td>\n",
       "      <td>504</td>\n",
       "      <td>[420, 42]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.4069730341434479, 0.2960851788...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>gru</td>\n",
       "      <td>softmax</td>\n",
       "      <td>504</td>\n",
       "      <td>[560, 56]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.6084797382354736, 0.5808486491...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1887</th>\n",
       "      <td>gru</td>\n",
       "      <td>selu</td>\n",
       "      <td>504</td>\n",
       "      <td>[560, 56]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.06250186823308468, 0.062589425...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>gru</td>\n",
       "      <td>softplus</td>\n",
       "      <td>504</td>\n",
       "      <td>[560, 56]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.23560043424367905, 0.353794276...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>gru</td>\n",
       "      <td>elu</td>\n",
       "      <td>504</td>\n",
       "      <td>[560, 56]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5544</td>\n",
       "      <td>32</td>\n",
       "      <td>{'val_loss': [0.07202654331922531, 0.045443765...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>gru</td>\n",
       "      <td>tanh</td>\n",
       "      <td>504</td>\n",
       "      <td>[560, 56]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.20182405412197113, 0.405292540...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>gru</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[560, 56]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.24903764575719833, 0.114875279...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>gru</td>\n",
       "      <td>softsign</td>\n",
       "      <td>504</td>\n",
       "      <td>[560, 56]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.13764698803424835, 0.185492694...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>gru</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[560, 56]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.22322294861078262, 0.161558575...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>gru</td>\n",
       "      <td>relu</td>\n",
       "      <td>504</td>\n",
       "      <td>[560, 56]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5544</td>\n",
       "      <td>15</td>\n",
       "      <td>{'val_loss': [0.1395314373075962, 0.0997895151...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>gru</td>\n",
       "      <td>linear</td>\n",
       "      <td>504</td>\n",
       "      <td>[560, 56]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.1811932548880577, 0.4071804881...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>elman</td>\n",
       "      <td>elu</td>\n",
       "      <td>504</td>\n",
       "      <td>[1680, 168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [552.8197937011719, 7.88656473159...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>elman</td>\n",
       "      <td>softmax</td>\n",
       "      <td>504</td>\n",
       "      <td>[1680, 168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5828298330307007, 0.5575208365...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>elman</td>\n",
       "      <td>selu</td>\n",
       "      <td>504</td>\n",
       "      <td>[1680, 168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [65.59686660766602, 259.921112060...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>elman</td>\n",
       "      <td>softplus</td>\n",
       "      <td>504</td>\n",
       "      <td>[1680, 168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [10.27700138092041, 0.16855748742...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>elman</td>\n",
       "      <td>softsign</td>\n",
       "      <td>504</td>\n",
       "      <td>[1680, 168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.2577574700117111, 0.0892095007...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>elman</td>\n",
       "      <td>tanh</td>\n",
       "      <td>504</td>\n",
       "      <td>[1680, 168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [1.9500762224197388, 0.1750087812...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>elman</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[1680, 168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.8162246942520142, 0.2787006497...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>elman</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[1680, 168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.30943939089775085, 0.325072154...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927</th>\n",
       "      <td>elman</td>\n",
       "      <td>relu</td>\n",
       "      <td>504</td>\n",
       "      <td>[1680, 168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softmax</td>\n",
       "      <td>504</td>\n",
       "      <td>[840, 84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5827813148498535, 0.5414568632...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>elu</td>\n",
       "      <td>504</td>\n",
       "      <td>[840, 84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.10499092936515808, 121.1690979...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>elman</td>\n",
       "      <td>linear</td>\n",
       "      <td>504</td>\n",
       "      <td>[1680, 168]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>selu</td>\n",
       "      <td>504</td>\n",
       "      <td>[840, 84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softplus</td>\n",
       "      <td>504</td>\n",
       "      <td>[840, 84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.6966229975223541, 0.7000716626...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softsign</td>\n",
       "      <td>504</td>\n",
       "      <td>[840, 84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.18096768110990524, 0.215132914...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[840, 84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.12306655198335648, 0.092874780...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>tanh</td>\n",
       "      <td>504</td>\n",
       "      <td>[840, 84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [3.3048731088638306, 0.5179111212...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>relu</td>\n",
       "      <td>504</td>\n",
       "      <td>[840, 84]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5544</td>\n",
       "      <td>32</td>\n",
       "      <td>{'val_loss': [0.3678734302520752, 0.3776267766...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[840, 84]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.48851917684078217, 0.885215461...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>linear</td>\n",
       "      <td>504</td>\n",
       "      <td>[840, 84]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [14.296613693237305, 43.580410003...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softmax</td>\n",
       "      <td>504</td>\n",
       "      <td>[210, 21]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5020935088396072, 0.4786742031...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>elu</td>\n",
       "      <td>504</td>\n",
       "      <td>[210, 21]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.14650917053222656, 0.228505104...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softplus</td>\n",
       "      <td>504</td>\n",
       "      <td>[210, 21]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>selu</td>\n",
       "      <td>504</td>\n",
       "      <td>[210, 21]</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.056628936901688576, 0.05869577...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softsign</td>\n",
       "      <td>504</td>\n",
       "      <td>[210, 21]</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.07241494208574295, 0.046022083...</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[210, 21]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.21714766323566437, 0.124829865...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>tanh</td>\n",
       "      <td>504</td>\n",
       "      <td>[210, 21]</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.07277422025799751, 0.060436032...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[210, 21]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.08768287301063538, 0.064077872...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[210, 21]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.15714696049690247, 0.092264004...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>relu</td>\n",
       "      <td>504</td>\n",
       "      <td>[210, 21]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.36303824186325073, 0.151833266...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softmax</td>\n",
       "      <td>504</td>\n",
       "      <td>[240, 24]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.45490314066410065, 0.415591105...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>linear</td>\n",
       "      <td>504</td>\n",
       "      <td>[210, 21]</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.07830138131976128, 0.068730324...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>elu</td>\n",
       "      <td>504</td>\n",
       "      <td>[240, 24]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5544</td>\n",
       "      <td>9</td>\n",
       "      <td>{'val_loss': [0.14139603078365326, 0.124228831...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softplus</td>\n",
       "      <td>504</td>\n",
       "      <td>[240, 24]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.5270393788814545, 0.1848405227...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>selu</td>\n",
       "      <td>504</td>\n",
       "      <td>[240, 24]</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5544</td>\n",
       "      <td>44</td>\n",
       "      <td>{'val_loss': [0.07983892410993576, 0.052296468...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softsign</td>\n",
       "      <td>504</td>\n",
       "      <td>[240, 24]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5544</td>\n",
       "      <td>11</td>\n",
       "      <td>{'val_loss': [0.10343407094478607, 0.061098249...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[240, 24]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.07101438567042351, 0.064784955...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>504</td>\n",
       "      <td>[240, 24]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.12143271416425705, 0.112146645...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>tanh</td>\n",
       "      <td>504</td>\n",
       "      <td>[240, 24]</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.09674326330423355, 0.084594491...</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>relu</td>\n",
       "      <td>504</td>\n",
       "      <td>[240, 24]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5544</td>\n",
       "      <td>19</td>\n",
       "      <td>{'val_loss': [0.13548076152801514, 0.099030070...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>linear</td>\n",
       "      <td>504</td>\n",
       "      <td>[240, 24]</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>5544</td>\n",
       "      <td>699</td>\n",
       "      <td>{'val_loss': [0.07061218097805977, 0.051096862...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         nn_type activation_func  parameters nodes_in_layer  largest_retained  smallest_not_retained  model_params  num_epochs                                        model_score  highest_F1  diff_small_large\n",
       "2           lstm             elu         504           [42]                 1                      2           504         699  {'val_loss': [0.4946219176054001, 0.2408708184...    0.500000                 1\n",
       "6           lstm            selu         504           [42]                 3                      4           504           7  {'val_loss': [0.0819605402648449, 0.0693724751...    1.000000                 1\n",
       "8           lstm        softplus         504           [42]                 1                      2           504         699  {'val_loss': [0.20116198807954788, 0.206449702...    0.500000                 1\n",
       "12          lstm        softsign         504           [42]                 2                      3           504         699  {'val_loss': [0.40316881239414215, 0.251443207...    0.666667                 1\n",
       "16          lstm            tanh         504           [42]                 3                      4           504          44  {'val_loss': [0.3318553566932678, 0.1949969530...    1.000000                 1\n",
       "18          lstm         sigmoid         504           [42]                 1                      2           504         699  {'val_loss': [0.08133256807923317, 0.071514669...    0.500000                 1\n",
       "20          lstm    hard_sigmoid         504           [42]                 1                      2           504         699  {'val_loss': [0.07580393180251122, 0.075959742...    0.500000                 1\n",
       "26          lstm            relu         504           [42]                 4                      5           504         699  {'val_loss': [0.25778841227293015, 0.227367028...    0.200000                 1\n",
       "30          lstm          linear         504           [42]                 2                      3           504         699  {'val_loss': [0.3624194860458374, 0.1538776010...    0.333333                 1\n",
       "32           gru         softmax         504           [56]                 1                      2           504         699  {'val_loss': [0.5448723286390305, 0.5204579234...    0.500000                 1\n",
       "34           gru             elu         504           [56]                 1                      2           504         699  {'val_loss': [0.4465404450893402, 0.2424310073...    0.500000                 1\n",
       "36           gru            selu         504           [56]                 1                      2           504         699  {'val_loss': [0.3945378214120865, 0.0874072089...    0.500000                 1\n",
       "38           gru        softplus         504           [56]                 1                      2           504         699  {'val_loss': [0.5819623172283173, 0.0856886133...    0.500000                 1\n",
       "42           gru        softsign         504           [56]                 2                      3           504         699  {'val_loss': [0.36055484414100647, 0.208033062...    0.333333                 1\n",
       "44           gru            tanh         504           [56]                 1                      2           504         699  {'val_loss': [0.4152391701936722, 0.1948228254...    0.500000                 1\n",
       "48           gru         sigmoid         504           [56]                 2                      3           504         699  {'val_loss': [0.34265419840812683, 0.085719957...    0.333333                 1\n",
       "50           gru    hard_sigmoid         504           [56]                 1                      2           504         699  {'val_loss': [0.26553022116422653, 0.064528800...    0.500000                 1\n",
       "54           gru            relu         504           [56]                 2                      3           504         699  {'val_loss': [0.3832283616065979, 0.2987566590...    0.666667                 1\n",
       "58           gru          linear         504           [56]                 3                      4           504          43  {'val_loss': [0.31459513306617737, 0.157367624...    1.000000                 1\n",
       "60         elman         softmax         504          [168]                 1                      2           504         699  {'val_loss': [0.7038005292415619, 0.6762956678...    0.500000                 1\n",
       "68         elman             elu         504          [168]                 9                     10           504          35  {'val_loss': [0.01022288529202342, 0.004784897...    1.000000                 1\n",
       "70         elman            selu         504          [168]                 1                      2           504         699  {'val_loss': [nan, nan, nan, nan, nan, nan, na...    0.500000                 1\n",
       "72         elman        softplus         504          [168]                 1                      2           504         699  {'val_loss': [0.11724359542131424, 0.067714590...    0.500000                 1\n",
       "80         elman        softsign         504          [168]                10                     11           504         699  {'val_loss': [0.0036327834241092205, 0.0023907...    0.545455                 1\n",
       "88         elman            tanh         504          [168]                11                     12           504          16  {'val_loss': [0.006719990400597453, 0.00462339...    1.000000                 1\n",
       "92         elman         sigmoid         504          [168]                 2                      3           504         699  {'val_loss': [0.09701669961214066, 0.126788254...    0.333333                 1\n",
       "94         elman    hard_sigmoid         504          [168]                 1                      2           504         699  {'val_loss': [0.08693477883934975, 0.089432314...    0.500000                 1\n",
       "98         elman            relu         504          [168]                 3                      4           504          26  {'val_loss': [0.21049391478300095, 0.160464845...    1.000000                 1\n",
       "106        elman          linear         504          [168]                 8                      9           504         699  {'val_loss': [0.07618581131100655, 0.023449786...    0.444444                 1\n",
       "108   bidirelamn         softmax         504           [84]                 1                      2           504         699  {'val_loss': [0.5991988778114319, 0.5611424148...    0.500000                 1\n",
       "116   bidirelamn             elu         504           [84]                 8                      9           504         699  {'val_loss': [0.038599710911512375, 0.00683762...    0.555556                 1\n",
       "122   bidirelamn            selu         504           [84]                 4                      5           504         699  {'val_loss': [nan, nan, nan, nan, nan, nan, na...    0.200000                 1\n",
       "124   bidirelamn        softplus         504           [84]                 1                      2           504         699  {'val_loss': [0.11677606776356697, 0.247338593...    0.500000                 1\n",
       "130   bidirelamn        softsign         504           [84]                 4                      5           504         699  {'val_loss': [0.05220537260174751, 0.007052829...    0.800000                 1\n",
       "136   bidirelamn            tanh         504           [84]                 5                      6           504          16  {'val_loss': [0.0015075012343004346, 0.0012468...    1.000000                 1\n",
       "138   bidirelamn         sigmoid         504           [84]                 1                      2           504         699  {'val_loss': [0.09947529435157776, 0.067808486...    0.500000                 1\n",
       "142   bidirelamn    hard_sigmoid         504           [84]                 2                      3           504         699  {'val_loss': [0.09018612280488014, 0.084832493...    0.333333                 1\n",
       "146   bidirelamn            relu         504           [84]                 3                      4           504          16  {'val_loss': [0.2869787886738777, 0.1159043312...    1.000000                 1\n",
       "152   bidirelamn          linear         504           [84]                 7                      8           504          26  {'val_loss': [0.04190049506723881, 0.013597493...    1.000000                 1\n",
       "154    bidirlstm         softmax         504           [21]                 1                      2           504         699  {'val_loss': [0.663487434387207, 0.63724201917...    0.500000                 1\n",
       "158    bidirlstm             elu         504           [21]                 2                      3           504         699  {'val_loss': [0.37372808158397675, 0.234386362...    0.333333                 1\n",
       "164    bidirlstm            selu         504           [21]                 5                      6           504          20  {'val_loss': [0.08483178168535233, 0.083788037...    1.000000                 1\n",
       "168    bidirlstm        softplus         504           [21]                 2                      3           504         699  {'val_loss': [1.1596860885620117, 0.6694509088...    0.333333                 1\n",
       "172    bidirlstm        softsign         504           [21]                 3                      4           504          26  {'val_loss': [0.38953451812267303, 0.287065491...    1.000000                 1\n",
       "176    bidirlstm            tanh         504           [21]                 3                      4           504          21  {'val_loss': [0.36916880309581757, 0.244283460...    1.000000                 1\n",
       "180    bidirlstm         sigmoid         504           [21]                 2                      3           504         699  {'val_loss': [0.08764307200908661, 0.093582563...    0.333333                 1\n",
       "182    bidirlstm    hard_sigmoid         504           [21]                 1                      2           504         699  {'val_loss': [0.06540227681398392, 0.072437830...    0.500000                 1\n",
       "184    bidirlstm            relu         504           [21]                 1                      2           504         699  {'val_loss': [0.5630137622356415, 0.5116415321...    0.500000                 1\n",
       "188    bidirlstm          linear         504           [21]                 3                      4           504          24  {'val_loss': [0.3195510804653168, 0.2121522054...    1.000000                 1\n",
       "190     bidirgru         softmax         504           [24]                 1                      2           504         699  {'val_loss': [0.5863576531410217, 0.5471096634...    0.500000                 1\n",
       "196     bidirgru             elu         504           [24]                 4                      5           504         699  {'val_loss': [0.21432245522737503, 0.148047141...    0.600000                 1\n",
       "202     bidirgru            selu         504           [24]                 5                      6           504          42  {'val_loss': [0.16468828171491623, 0.084260262...    1.000000                 1\n",
       "204     bidirgru        softplus         504           [24]                 1                      2           504         699  {'val_loss': [0.14249546825885773, 0.081475466...    0.500000                 1\n",
       "210     bidirgru        softsign         504           [24]                 4                      5           504         699  {'val_loss': [0.23640096187591553, 0.172316953...    0.400000                 1\n",
       "216     bidirgru            tanh         504           [24]                 4                      5           504         699  {'val_loss': [0.22417141497135162, 0.159498237...    0.400000                 1\n",
       "218     bidirgru         sigmoid         504           [24]                 1                      2           504         699  {'val_loss': [1.2608646154403687, 0.6526324152...    0.500000                 1\n",
       "220     bidirgru    hard_sigmoid         504           [24]                 1                      2           504         699  {'val_loss': [0.062262656167149544, 0.06187883...    0.500000                 1\n",
       "224     bidirgru            relu         504           [24]                 3                      4           504          32  {'val_loss': [0.3938422203063965, 0.3493473976...    1.000000                 1\n",
       "228     bidirgru          linear         504           [24]                 2                      3           504         699  {'val_loss': [0.39541734755039215, 0.286482445...    0.666667                 1\n",
       "1855        lstm             elu         504      [420, 42]                 1                      2          5544         699  {'val_loss': [1.8565932512283325, 0.3832542300...    0.500000                 1\n",
       "1857        lstm         softmax         504      [420, 42]                 1                      2          5544         699  {'val_loss': [0.5618335157632828, 0.5442014038...    0.500000                 1\n",
       "1861        lstm        softplus         504      [420, 42]                 1                      2          5544         699  {'val_loss': [nan, nan, nan, nan, nan, nan, na...    0.500000                 1\n",
       "1865        lstm            selu         504      [420, 42]                 7                      8          5544          26  {'val_loss': [0.11091110482811928, 0.086871236...    1.000000                 1\n",
       "1869        lstm        softsign         504      [420, 42]                 1                      2          5544         699  {'val_loss': [0.0774071030318737, 0.0648136138...    0.500000                 1\n",
       "1871        lstm         sigmoid         504      [420, 42]                 1                      2          5544         699  {'val_loss': [0.09813069179654121, 0.073252826...    0.500000                 1\n",
       "1874        lstm    hard_sigmoid         504      [420, 42]                 1                      2          5544         699  {'val_loss': [0.12797389551997185, 0.066876921...    0.500000                 1\n",
       "1877        lstm            tanh         504      [420, 42]                 5                      6          5544          40  {'val_loss': [0.07084476388990879, 0.071869628...    1.000000                 1\n",
       "1879        lstm            relu         504      [420, 42]                 1                      2          5544         699  {'val_loss': [0.4618387520313263, 0.5346571207...    0.500000                 1\n",
       "1881        lstm          linear         504      [420, 42]                 1                      2          5544         699  {'val_loss': [0.4069730341434479, 0.2960851788...    0.500000                 1\n",
       "1885         gru         softmax         504      [560, 56]                 1                      2          5544         699  {'val_loss': [0.6084797382354736, 0.5808486491...    0.500000                 1\n",
       "1887         gru            selu         504      [560, 56]                 1                      2          5544         699  {'val_loss': [0.06250186823308468, 0.062589425...    0.500000                 1\n",
       "1890         gru        softplus         504      [560, 56]                 1                      2          5544         699  {'val_loss': [0.23560043424367905, 0.353794276...    0.500000                 1\n",
       "1894         gru             elu         504      [560, 56]                 5                      6          5544          32  {'val_loss': [0.07202654331922531, 0.045443765...    1.000000                 1\n",
       "1896         gru            tanh         504      [560, 56]                 1                      2          5544         699  {'val_loss': [0.20182405412197113, 0.405292540...    0.500000                 1\n",
       "1899         gru         sigmoid         504      [560, 56]                 1                      2          5544         699  {'val_loss': [0.24903764575719833, 0.114875279...    0.500000                 1\n",
       "1901         gru        softsign         504      [560, 56]                 2                      3          5544         699  {'val_loss': [0.13764698803424835, 0.185492694...    0.333333                 1\n",
       "1904         gru    hard_sigmoid         504      [560, 56]                 1                      2          5544         699  {'val_loss': [0.22322294861078262, 0.161558575...    0.500000                 1\n",
       "1907         gru            relu         504      [560, 56]                 3                      4          5544          15  {'val_loss': [0.1395314373075962, 0.0997895151...    1.000000                 1\n",
       "1909         gru          linear         504      [560, 56]                 1                      2          5544         699  {'val_loss': [0.1811932548880577, 0.4071804881...    0.500000                 1\n",
       "1911       elman             elu         504    [1680, 168]                 1                      2          5544         699  {'val_loss': [552.8197937011719, 7.88656473159...    0.500000                 1\n",
       "1913       elman         softmax         504    [1680, 168]                 1                      2          5544         699  {'val_loss': [0.5828298330307007, 0.5575208365...    0.500000                 1\n",
       "1915       elman            selu         504    [1680, 168]                 1                      2          5544         699  {'val_loss': [65.59686660766602, 259.921112060...    0.500000                 1\n",
       "1917       elman        softplus         504    [1680, 168]                 1                      2          5544         699  {'val_loss': [10.27700138092041, 0.16855748742...    0.500000                 1\n",
       "1919       elman        softsign         504    [1680, 168]                 1                      2          5544         699  {'val_loss': [0.2577574700117111, 0.0892095007...    0.500000                 1\n",
       "1921       elman            tanh         504    [1680, 168]                 1                      2          5544         699  {'val_loss': [1.9500762224197388, 0.1750087812...    0.500000                 1\n",
       "1923       elman         sigmoid         504    [1680, 168]                 1                      2          5544         699  {'val_loss': [0.8162246942520142, 0.2787006497...    0.500000                 1\n",
       "1925       elman    hard_sigmoid         504    [1680, 168]                 1                      2          5544         699  {'val_loss': [0.30943939089775085, 0.325072154...    0.500000                 1\n",
       "1927       elman            relu         504    [1680, 168]                 1                      2          5544         699  {'val_loss': [nan, nan, nan, nan, nan, nan, na...    0.500000                 1\n",
       "1929  bidirelamn         softmax         504      [840, 84]                 1                      2          5544         699  {'val_loss': [0.5827813148498535, 0.5414568632...    0.500000                 1\n",
       "1931  bidirelamn             elu         504      [840, 84]                 1                      2          5544         699  {'val_loss': [0.10499092936515808, 121.1690979...    0.500000                 1\n",
       "1933       elman          linear         504    [1680, 168]                 1                      2          5544         699  {'val_loss': [nan, nan, nan, nan, nan, nan, na...    0.500000                 1\n",
       "1935  bidirelamn            selu         504      [840, 84]                 1                      2          5544         699  {'val_loss': [nan, nan, nan, nan, nan, nan, na...    0.500000                 1\n",
       "1937  bidirelamn        softplus         504      [840, 84]                 1                      2          5544         699  {'val_loss': [0.6966229975223541, 0.7000716626...    0.500000                 1\n",
       "1939  bidirelamn        softsign         504      [840, 84]                 1                      2          5544         699  {'val_loss': [0.18096768110990524, 0.215132914...    0.500000                 1\n",
       "1941  bidirelamn         sigmoid         504      [840, 84]                 1                      2          5544         699  {'val_loss': [0.12306655198335648, 0.092874780...    0.500000                 1\n",
       "1944  bidirelamn            tanh         504      [840, 84]                 1                      2          5544         699  {'val_loss': [3.3048731088638306, 0.5179111212...    0.500000                 1\n",
       "1949  bidirelamn            relu         504      [840, 84]                 3                      4          5544          32  {'val_loss': [0.3678734302520752, 0.3776267766...    1.000000                 1\n",
       "1951  bidirelamn    hard_sigmoid         504      [840, 84]                 2                      3          5544         699  {'val_loss': [0.48851917684078217, 0.885215461...    0.333333                 1\n",
       "1953  bidirelamn          linear         504      [840, 84]                 1                      2          5544         699  {'val_loss': [14.296613693237305, 43.580410003...    0.500000                 1\n",
       "1956   bidirlstm         softmax         504      [210, 21]                 1                      2          5544         699  {'val_loss': [0.5020935088396072, 0.4786742031...    0.500000                 1\n",
       "1963   bidirlstm             elu         504      [210, 21]                 2                      3          5544         699  {'val_loss': [0.14650917053222656, 0.228505104...    0.333333                 1\n",
       "1965   bidirlstm        softplus         504      [210, 21]                 1                      2          5544         699  {'val_loss': [nan, nan, nan, nan, nan, nan, na...    0.500000                 1\n",
       "1970   bidirlstm            selu         504      [210, 21]                 6                      7          5544         699  {'val_loss': [0.056628936901688576, 0.05869577...    0.571429                 1\n",
       "1981   bidirlstm        softsign         504      [210, 21]                10                     11          5544         699  {'val_loss': [0.07241494208574295, 0.046022083...    0.545455                 1\n",
       "1983   bidirlstm         sigmoid         504      [210, 21]                 1                      2          5544         699  {'val_loss': [0.21714766323566437, 0.124829865...    0.500000                 1\n",
       "1984   bidirlstm            tanh         504      [210, 21]                 8                      9          5544         699  {'val_loss': [0.07277422025799751, 0.060436032...    0.555556                 1\n",
       "1987   bidirlstm    hard_sigmoid         504      [210, 21]                 1                      2          5544         699  {'val_loss': [0.08768287301063538, 0.064077872...    0.500000                 1\n",
       "1990   bidirlstm    hard_sigmoid         504      [210, 21]                 1                      2          5544         699  {'val_loss': [0.15714696049690247, 0.092264004...    0.500000                 1\n",
       "1997   bidirlstm            relu         504      [210, 21]                 2                      3          5544         699  {'val_loss': [0.36303824186325073, 0.151833266...    0.333333                 1\n",
       "1999    bidirgru         softmax         504      [240, 24]                 1                      2          5544         699  {'val_loss': [0.45490314066410065, 0.415591105...    0.500000                 1\n",
       "2002   bidirlstm          linear         504      [210, 21]                 6                      7          5544         699  {'val_loss': [0.07830138131976128, 0.068730324...    0.571429                 1\n",
       "2007    bidirgru             elu         504      [240, 24]                 3                      4          5544           9  {'val_loss': [0.14139603078365326, 0.124228831...    1.000000                 1\n",
       "2009    bidirgru        softplus         504      [240, 24]                 1                      2          5544         699  {'val_loss': [0.5270393788814545, 0.1848405227...    0.500000                 1\n",
       "2014    bidirgru            selu         504      [240, 24]                 7                      8          5544          44  {'val_loss': [0.07983892410993576, 0.052296468...    1.000000                 1\n",
       "2019    bidirgru        softsign         504      [240, 24]                 3                      4          5544          11  {'val_loss': [0.10343407094478607, 0.061098249...    1.000000                 1\n",
       "2021    bidirgru         sigmoid         504      [240, 24]                 1                      2          5544         699  {'val_loss': [0.07101438567042351, 0.064784955...    0.500000                 1\n",
       "2025    bidirgru    hard_sigmoid         504      [240, 24]                 1                      2          5544         699  {'val_loss': [0.12143271416425705, 0.112146645...    0.500000                 1\n",
       "2029    bidirgru            tanh         504      [240, 24]                 6                      7          5544         699  {'val_loss': [0.09674326330423355, 0.084594491...    0.428571                 1\n",
       "2036    bidirgru            relu         504      [240, 24]                 5                      6          5544          19  {'val_loss': [0.13548076152801514, 0.099030070...    1.000000                 1\n",
       "2048    bidirgru          linear         504      [240, 24]                 8                      9          5544         699  {'val_loss': [0.07061218097805977, 0.051096862...    0.444444                 1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df[\"diff_small_large\"]  == 1) & (df[\"parameters\"]==504)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Number of parameters $\\varpropto$ pattern length\n",
    "#### Relationship of the number of parameters in network to length of patterns retained "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T06:25:35.597081Z",
     "start_time": "2018-11-16T06:25:34.965416Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x324 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "def plot_by_filter(x_col, \n",
    "                   y_col, \n",
    "                   x_label='Sparsity length',\n",
    "                   y_label='Number of network parameters',\n",
    "                   title=\"Effect of sparsity on the number of parameters \\n in a neural network with activation \", \n",
    "                   hue=\"network_type\", \n",
    "                   filter_col=\"activation_function\", \n",
    "                   filter_val=\"tanh\",\n",
    "                   legend_title=\"NN TYPE\",\n",
    "                  df=None):\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    a4_dims = (12, 4.5)\n",
    "    fig, ax = pyplot.subplots(figsize=a4_dims)\n",
    "    ax.set(xlabel=x_label, \n",
    "       ylabel=y_label )\n",
    "    if filter_val is not None:\n",
    "        ax = sns.pointplot(ax=ax, x=x_col, y=y_col, hue=hue, \n",
    "                          marker='o',  markersize=5, ci=None,\n",
    "                          data = df[df[filter_col] == filter_val])\n",
    "       \n",
    "        ax.axes.set_title(title + filter_val,\n",
    "                          fontsize=12, y=1.05)\n",
    "        ax.legend(title=filter_val.upper(), loc='center right', bbox_to_anchor=(1.37, 0.5), ncol=1)\n",
    "    else:\n",
    "        ax = sns.pointplot(ax=ax, x=x_col, y=y_col, hue=hue, \n",
    "                          marker='o',  markersize=5, ci=None,\n",
    "                          data = df)\n",
    "        ax.axes.set_title(title, fontsize=12, y=1.05)\n",
    "        ax.legend(title=legend_title, loc='center right', bbox_to_anchor=(1.37, 0.5), ncol=1)\n",
    "\n",
    "    # plt.legend()\n",
    "filter_col = \"nn_type\"\n",
    "filter_1 = \"largest_retained\"\n",
    "x_col = \"largest_retained\"\n",
    "x_label = \"Length of Patterns\"\n",
    "plot_by_filter(x_col=x_col, \n",
    "               y_col=\"model_params\",\n",
    "               x_label=\"Length of pattern retained\",\n",
    "               y_label='Number of network parameters',\n",
    "               title=\"Effect of the number of parameters on the ability recognise lengthy patterns\" + \n",
    "                       \"\\n in a neural network over all activation functions\", \n",
    "               hue=\"nn_type\",\n",
    "              filter_col=filter_col, filter_val=None, df=df)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T06:25:41.138543Z",
     "start_time": "2018-11-16T06:25:41.107770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation Between Length of Patterns length and Number of Network Parameters for lstm 0.5521441755525618\n",
      "Pearson Correlation Between Length of Patterns length and Number of Network Parameters for gru 0.35058882564348476\n",
      "Pearson Correlation Between Length of Patterns length and Number of Network Parameters for elman -0.9306980227603925\n",
      "Pearson Correlation Between Length of Patterns length and Number of Network Parameters for bidirelamn -0.03264183447359823\n",
      "Pearson Correlation Between Length of Patterns length and Number of Network Parameters for bidirlstm 0.8559613131203363\n",
      "Pearson Correlation Between Length of Patterns length and Number of Network Parameters for bidirgru 0.7635036673186247\n"
     ]
    }
   ],
   "source": [
    "filter_col = \"nn_type\"\n",
    "filter_col_1 = x_col\n",
    "for filter_val in df[filter_col].unique():\n",
    "    df_temp = df[df[filter_col] == filter_val]\n",
    "    df_temp = df_temp.groupby([x_col, \"nn_type\"]).agg({\"model_params\": \"mean\"}).to_records()\n",
    "    df_temp = pd.DataFrame.from_records(df_temp)\n",
    "    df_temp[x_col] = df_temp[x_col].astype(float)\n",
    "    df_temp[\"model_params\"] = df_temp[\"model_params\"].astype(float)\n",
    "    \n",
    "    print(\"Pearson Correlation Between \"+x_label+\" length and Number of Network Parameters for\", filter_val, df_temp[x_col].corr(df_temp[\"model_params\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern Length retention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_params</th>\n",
       "      <th>largest_retained</th>\n",
       "      <th>capacity_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bidirelamn</th>\n",
       "      <td>546840</td>\n",
       "      <td>331</td>\n",
       "      <td>0.000605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bidirgru</th>\n",
       "      <td>478800</td>\n",
       "      <td>387</td>\n",
       "      <td>0.000808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bidirlstm</th>\n",
       "      <td>507024</td>\n",
       "      <td>430</td>\n",
       "      <td>0.000848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elman</th>\n",
       "      <td>554400</td>\n",
       "      <td>247</td>\n",
       "      <td>0.000446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gru</th>\n",
       "      <td>554400</td>\n",
       "      <td>237</td>\n",
       "      <td>0.000427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lstm</th>\n",
       "      <td>553896</td>\n",
       "      <td>288</td>\n",
       "      <td>0.000520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_params  largest_retained  capacity_ratio\n",
       "nn_type                                                   \n",
       "bidirelamn        546840               331        0.000605\n",
       "bidirgru          478800               387        0.000808\n",
       "bidirlstm         507024               430        0.000848\n",
       "elman             554400               247        0.000446\n",
       "gru               554400               237        0.000427\n",
       "lstm              553896               288        0.000520"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cap = df.groupby([\"nn_type\"]).agg({\"model_params\" : \"sum\", \"largest_retained\": \"sum\"})\n",
    "df_cap[\"capacity_ratio\"] = df_cap[\"largest_retained\"]/df_cap[\"model_params\"]\n",
    "df_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T11:18:46.319240Z",
     "start_time": "2018-11-15T11:18:46.316872Z"
    }
   },
   "source": [
    "## 2. Investigate which activation function lead to the highest retention of length of pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T06:26:16.045722Z",
     "start_time": "2018-11-16T06:26:15.996608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation Between Length of Patterns and Number of Network Parameters for elu -0.638942046490701\n",
      "Pearson Correlation Between Length of Patterns and Number of Network Parameters for selu 0.7911496950414489\n",
      "Pearson Correlation Between Length of Patterns and Number of Network Parameters for softplus -0.21105081405195908\n",
      "Pearson Correlation Between Length of Patterns and Number of Network Parameters for softsign 0.2966279068699606\n",
      "Pearson Correlation Between Length of Patterns and Number of Network Parameters for tanh -0.5194180491618763\n",
      "Pearson Correlation Between Length of Patterns and Number of Network Parameters for sigmoid -0.07320777904770723\n",
      "Pearson Correlation Between Length of Patterns and Number of Network Parameters for hard_sigmoid -0.8017581948081903\n",
      "Pearson Correlation Between Length of Patterns and Number of Network Parameters for relu 0.06935552527457106\n",
      "Pearson Correlation Between Length of Patterns and Number of Network Parameters for linear -0.47696963940195564\n",
      "Pearson Correlation Between Length of Patterns and Number of Network Parameters for softmax -1.0\n"
     ]
    }
   ],
   "source": [
    "filter_col = \"activation_func\"\n",
    "filter_col_1 = x_col\n",
    "for filter_val in df[filter_col].unique():\n",
    "    df_temp = df[(df[filter_col] == filter_val)]\n",
    "    df_temp = df_temp.groupby([filter_col_1]).agg({\"model_params\": \"mean\"}).to_records()\n",
    "    df_temp = pd.DataFrame.from_records(df_temp)\n",
    "    df_temp[filter_col_1] = df_temp[filter_col_1].astype(float)\n",
    "    df_temp[\"model_params\"] = df_temp[\"model_params\"].astype(float)\n",
    "    \n",
    "    print(\"Pearson Correlation Between \"+x_label+\" and Number of Network Parameters for\", filter_val, df_temp[filter_col_1].corr(df_temp[\"model_params\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x324 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter_col = \"activation_func\"\n",
    "filter_1 = \"largest_retained\"\n",
    "x_col = \"largest_retained\"\n",
    "x_label = \"Number of Patterns\"\n",
    "plot_by_filter(x_col=x_col, \n",
    "               y_col=\"model_params\",\n",
    "               x_label=x_label,\n",
    "               y_label='Number of network parameters',\n",
    "               title=\"Effect of the number of parameters on the ability to retain patterns\" + \n",
    "                       \"\\n in a neural network over all activation functions\", \n",
    "               hue=\"activation_func\",\n",
    "              filter_col=filter_col, filter_val=None, df=df)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation of activation functions   length of pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['elu', 'selu', 'softplus', 'softsign', 'tanh', 'sigmoid',\n",
       "       'hard_sigmoid', 'relu', 'linear', 'softmax'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[filter_col].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for lstm elu -0.19518001458970663\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for gru elu -0.16217933707133886\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for elman elu -0.9183350106368162\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for bidirelamn elu -0.6444470260675302\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for bidirlstm elu -0.5613878915519948\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for bidirgru elu 0.4102154420154356\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for lstm selu 0.7402031389199023\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for gru selu 0.9975159147229784\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for elman selu -0.5960395606792698\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for bidirelamn selu -1.0\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for bidirlstm selu 0.92370146918725\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for bidirgru selu 0.41801814162142487\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for lstm softplus nan\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for gru softplus -1.0\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for elman softplus nan\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for bidirelamn softplus -1.0\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for bidirlstm softplus -0.9999999999999998\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for bidirgru softplus -0.42114398353823207\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for lstm softsign 0.009370750774807847\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for gru softsign -0.6476390405981239\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for elman softsign -0.798128251162776\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for bidirelamn softsign -0.829177786046393\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for bidirlstm softsign 0.8703422259728094\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for bidirgru softsign 0.6142310078909803\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for lstm tanh 0.7422004211742292\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for gru tanh -1.0\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for elman tanh -0.8058780197235663\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for bidirelamn tanh -0.7107276838520844\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for bidirlstm tanh 0.09399014205293706\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for bidirgru tanh 0.8053994993553067\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for lstm sigmoid -1.0\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for gru sigmoid -1.0\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for elman sigmoid 0.7307182524812804\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for bidirelamn sigmoid 1.0\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for bidirlstm sigmoid 0.22300081615414039\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for bidirgru sigmoid -0.6105634184937697\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for lstm hard_sigmoid -1.0\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for gru hard_sigmoid -0.9811984581945274\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for elman hard_sigmoid 1.0\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for bidirelamn hard_sigmoid 0.8803675481573489\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for bidirlstm hard_sigmoid -1.0\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for bidirgru hard_sigmoid -0.3484008250395982\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for lstm relu -0.8444444444444446\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for gru relu -0.5323372607947117\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for elman relu -0.7066034338012563\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for bidirelamn relu 0.015561462768435133\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for bidirlstm relu -0.0025962905774829\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for bidirgru relu 0.7168944513739076\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for lstm linear 0.8341918721972287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/numpy/lib/function_base.py:2522: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar)\n",
      "/usr/lib/python3/dist-packages/numpy/lib/function_base.py:2451: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for gru linear -0.9326733179802502\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for elman linear -0.8863710206858474\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for bidirelamn linear -0.94881030376583\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for bidirlstm linear 0.6684281010312038\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for bidirgru linear 0.45087558423639906\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for lstm softmax nan\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for gru softmax -0.9999999999999998\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for elman softmax nan\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for bidirelamn softmax nan\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for bidirlstm softmax nan\n",
      "Pearson Correlation Between Number of Patterns and Number of Network Parameters for bidirgru softmax nan\n"
     ]
    }
   ],
   "source": [
    "filter_col = \"activation_func\"\n",
    "df_correlation_matrix = pd.DataFrame(columns=df[\"nn_type\"].unique())\n",
    "df_correlation_matrix[\"activation_func\"] = df[filter_col].unique()\n",
    "df_correlation_matrix.index =  df_correlation_matrix[\"activation_func\"]\n",
    "del df_correlation_matrix[\"activation_func\"]\n",
    "for filter_val in df[filter_col].unique():\n",
    "    for filter_val_1 in df[\"nn_type\"].unique():\n",
    "        df_temp = df[(df[\"nn_type\"] == filter_val_1) & (df[\"activation_func\"] == filter_val)]\n",
    "        df_temp = df_temp.groupby([\"largest_retained\"]).agg({\"model_params\": \"mean\"}).to_records()\n",
    "        df_temp = pd.DataFrame.from_records(df_temp)\n",
    "        df_temp[x_col] = df_temp[filter_col_1].astype(float)\n",
    "        df_temp[\"model_params\"] = df_temp[\"model_params\"].astype(float)\n",
    "        df_correlation_matrix.at[filter_val, filter_val_1] =   df_temp[filter_col_1].corr(df_temp[\"model_params\"])\n",
    "        print(\"Pearson Correlation Between \"+x_label+\" and Number of Network Parameters for\", filter_val_1 + \" \"+ filter_val, df_temp[filter_col_1].corr(df_temp[\"model_params\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lstm</th>\n",
       "      <th>gru</th>\n",
       "      <th>elman</th>\n",
       "      <th>bidirelamn</th>\n",
       "      <th>bidirlstm</th>\n",
       "      <th>bidirgru</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activation_func</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>elu</th>\n",
       "      <td>-0.19518</td>\n",
       "      <td>-0.162179</td>\n",
       "      <td>-0.918335</td>\n",
       "      <td>-0.644447</td>\n",
       "      <td>-0.561388</td>\n",
       "      <td>0.410215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selu</th>\n",
       "      <td>0.740203</td>\n",
       "      <td>0.997516</td>\n",
       "      <td>-0.59604</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.923701</td>\n",
       "      <td>0.418018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>softplus</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.421144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>softsign</th>\n",
       "      <td>0.00937075</td>\n",
       "      <td>-0.647639</td>\n",
       "      <td>-0.798128</td>\n",
       "      <td>-0.829178</td>\n",
       "      <td>0.870342</td>\n",
       "      <td>0.614231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tanh</th>\n",
       "      <td>0.7422</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.805878</td>\n",
       "      <td>-0.710728</td>\n",
       "      <td>0.0939901</td>\n",
       "      <td>0.805399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigmoid</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.730718</td>\n",
       "      <td>1</td>\n",
       "      <td>0.223001</td>\n",
       "      <td>-0.610563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard_sigmoid</th>\n",
       "      <td>-1</td>\n",
       "      <td>-0.981198</td>\n",
       "      <td>1</td>\n",
       "      <td>0.880368</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.348401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>-0.844444</td>\n",
       "      <td>-0.532337</td>\n",
       "      <td>-0.706603</td>\n",
       "      <td>0.0155615</td>\n",
       "      <td>-0.00259629</td>\n",
       "      <td>0.716894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>0.834192</td>\n",
       "      <td>-0.932673</td>\n",
       "      <td>-0.886371</td>\n",
       "      <td>-0.94881</td>\n",
       "      <td>0.668428</td>\n",
       "      <td>0.450876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>softmax</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       lstm       gru     elman bidirelamn   bidirlstm  bidirgru\n",
       "activation_func                                                                 \n",
       "elu                -0.19518 -0.162179 -0.918335  -0.644447   -0.561388  0.410215\n",
       "selu               0.740203  0.997516  -0.59604         -1    0.923701  0.418018\n",
       "softplus                NaN        -1       NaN         -1          -1 -0.421144\n",
       "softsign         0.00937075 -0.647639 -0.798128  -0.829178    0.870342  0.614231\n",
       "tanh                 0.7422        -1 -0.805878  -0.710728   0.0939901  0.805399\n",
       "sigmoid                  -1        -1  0.730718          1    0.223001 -0.610563\n",
       "hard_sigmoid             -1 -0.981198         1   0.880368          -1 -0.348401\n",
       "relu              -0.844444 -0.532337 -0.706603  0.0155615 -0.00259629  0.716894\n",
       "linear             0.834192 -0.932673 -0.886371   -0.94881    0.668428  0.450876\n",
       "softmax                 NaN        -1       NaN        NaN         NaN       NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_correlation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Length Capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>nn_type</th>\n",
       "      <th>bidirelamn</th>\n",
       "      <th>bidirgru</th>\n",
       "      <th>bidirlstm</th>\n",
       "      <th>elman</th>\n",
       "      <th>gru</th>\n",
       "      <th>lstm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activation_func</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>elu</th>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.000451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard_sigmoid</th>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.000433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>0.001525</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.000559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selu</th>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.001479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigmoid</th>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>softmax</th>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>softplus</th>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>softsign</th>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.000685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tanh</th>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "nn_type          bidirelamn  bidirgru  bidirlstm     elman       gru      lstm\n",
       "activation_func                                                               \n",
       "elu                0.000902  0.000815   0.000884  0.000649  0.000505  0.000451\n",
       "hard_sigmoid       0.000415  0.000564   0.000299  0.000307  0.000361  0.000307\n",
       "linear             0.000776  0.000835   0.001023  0.000613  0.000469  0.000433\n",
       "relu               0.001525  0.001044   0.000856  0.000722  0.000685  0.000559\n",
       "selu               0.000307  0.001316   0.001966  0.000307  0.000505  0.001479\n",
       "sigmoid            0.000289  0.000480   0.000397  0.000379  0.000343  0.000289\n",
       "softmax            0.000253  0.000272   0.000253  0.000253  0.000271  0.000237\n",
       "softplus           0.000307  0.000564   0.000292  0.000253  0.000289  0.000253\n",
       "softsign           0.000776  0.001170   0.001546  0.000451  0.000559  0.000685\n",
       "tanh               0.000631  0.001023   0.000940  0.000523  0.000289  0.000505"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cap = df.groupby([\"nn_type\", \"activation_func\"]).agg({\"model_params\" : \"sum\", \"largest_retained\": \"sum\"})\n",
    "df_cap[\"capacity_ratio\"] = df_cap[\"largest_retained\"]/df_cap[\"model_params\"]\n",
    "df_cap = pd.DataFrame(df_cap.to_records())\n",
    "df_cap = df_cap.pivot(index=\"activation_func\", columns=\"nn_type\", values=\"capacity_ratio\")\n",
    "df_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "            # TOTOTOTOTOTODOODODODODOODODODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Relationship between the length of pattern and number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T06:26:53.170157Z",
     "start_time": "2018-11-16T06:26:52.906076Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>largest_retained</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_layers</th>\n",
       "      <th>model_params</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">1</th>\n",
       "      <th>504</th>\n",
       "      <td>2.796610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>2.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>2.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>2.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>2.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3024</th>\n",
       "      <td>2.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3528</th>\n",
       "      <td>1.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4032</th>\n",
       "      <td>2.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4536</th>\n",
       "      <td>1.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2</th>\n",
       "      <th>5544</th>\n",
       "      <td>2.213115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6048</th>\n",
       "      <td>2.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6552</th>\n",
       "      <td>2.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7056</th>\n",
       "      <td>2.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7560</th>\n",
       "      <td>1.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         largest_retained\n",
       "num_layers model_params                  \n",
       "1          504                   2.796610\n",
       "           1008                  2.900000\n",
       "           1512                  2.650000\n",
       "           2016                  2.516667\n",
       "           2520                  2.100000\n",
       "           3024                  2.366667\n",
       "           3528                  1.966667\n",
       "           4032                  2.050000\n",
       "           4536                  1.966667\n",
       "2          5544                  2.213115\n",
       "           6048                  2.550000\n",
       "           6552                  2.166667\n",
       "           7056                  2.483333\n",
       "           7560                  1.833333"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"num_layers\"] = df[\"nodes_in_layer\"].apply(len)\n",
    "df.groupby([\"num_layers\", \"model_params\"]).agg({\"largest_retained\": \"mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nn_type</th>\n",
       "      <th>activation_func</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>model_params</th>\n",
       "      <th>largest_retained</th>\n",
       "      <th>capacity_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>elu</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>42</td>\n",
       "      <td>0.001852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>elu</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>38</td>\n",
       "      <td>0.001675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>linear</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>relu</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>47</td>\n",
       "      <td>0.002072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>25200</td>\n",
       "      <td>26</td>\n",
       "      <td>0.001032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>selu</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>selu</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softmax</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softplus</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softsign</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>36</td>\n",
       "      <td>0.001587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>softsign</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>30</td>\n",
       "      <td>0.001323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bidirelamn</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>elu</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>26</td>\n",
       "      <td>0.001146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>elu</td>\n",
       "      <td>2</td>\n",
       "      <td>25200</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>23</td>\n",
       "      <td>0.001014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>2</td>\n",
       "      <td>25200</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>24</td>\n",
       "      <td>0.001058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>linear</td>\n",
       "      <td>2</td>\n",
       "      <td>25200</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>relu</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>29</td>\n",
       "      <td>0.001279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>25200</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>selu</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>34</td>\n",
       "      <td>0.001499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>selu</td>\n",
       "      <td>2</td>\n",
       "      <td>25200</td>\n",
       "      <td>29</td>\n",
       "      <td>0.001151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>2</td>\n",
       "      <td>25200</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softmax</td>\n",
       "      <td>2</td>\n",
       "      <td>25200</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softplus</td>\n",
       "      <td>2</td>\n",
       "      <td>25200</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softsign</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>34</td>\n",
       "      <td>0.001499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>softsign</td>\n",
       "      <td>2</td>\n",
       "      <td>25200</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>bidirgru</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2</td>\n",
       "      <td>25200</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>elu</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>33</td>\n",
       "      <td>0.001455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>elu</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>2</td>\n",
       "      <td>30744</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>28</td>\n",
       "      <td>0.001235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>linear</td>\n",
       "      <td>2</td>\n",
       "      <td>25200</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>relu</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>29</td>\n",
       "      <td>0.001279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>25200</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>selu</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>55</td>\n",
       "      <td>0.002425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>selu</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>54</td>\n",
       "      <td>0.001648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>2</td>\n",
       "      <td>25200</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softmax</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softplus</td>\n",
       "      <td>2</td>\n",
       "      <td>25200</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softsign</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>42</td>\n",
       "      <td>0.001852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>softsign</td>\n",
       "      <td>2</td>\n",
       "      <td>25200</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>29</td>\n",
       "      <td>0.001279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>bidirlstm</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2</td>\n",
       "      <td>25200</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>elman</td>\n",
       "      <td>elu</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>30</td>\n",
       "      <td>0.001323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>elman</td>\n",
       "      <td>elu</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>elman</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>elman</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>elman</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>29</td>\n",
       "      <td>0.001279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>elman</td>\n",
       "      <td>linear</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>elman</td>\n",
       "      <td>relu</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>34</td>\n",
       "      <td>0.001499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>elman</td>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>elman</td>\n",
       "      <td>selu</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>elman</td>\n",
       "      <td>selu</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>elman</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>elman</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>elman</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>elman</td>\n",
       "      <td>softmax</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>elman</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>elman</td>\n",
       "      <td>softplus</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>elman</td>\n",
       "      <td>softsign</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>elman</td>\n",
       "      <td>softsign</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>elman</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>23</td>\n",
       "      <td>0.001014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>elman</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>gru</td>\n",
       "      <td>elu</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>gru</td>\n",
       "      <td>elu</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>gru</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>gru</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>gru</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>gru</td>\n",
       "      <td>linear</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>gru</td>\n",
       "      <td>relu</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>29</td>\n",
       "      <td>0.001279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>gru</td>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>gru</td>\n",
       "      <td>selu</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>gru</td>\n",
       "      <td>selu</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>gru</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>gru</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>gru</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>gru</td>\n",
       "      <td>softmax</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>gru</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>gru</td>\n",
       "      <td>softplus</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>gru</td>\n",
       "      <td>softsign</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>gru</td>\n",
       "      <td>softsign</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>gru</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>gru</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>lstm</td>\n",
       "      <td>elu</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>lstm</td>\n",
       "      <td>elu</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>lstm</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>lstm</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>lstm</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>lstm</td>\n",
       "      <td>linear</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>lstm</td>\n",
       "      <td>relu</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>24</td>\n",
       "      <td>0.001058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>lstm</td>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>lstm</td>\n",
       "      <td>selu</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>46</td>\n",
       "      <td>0.002028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>lstm</td>\n",
       "      <td>selu</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>36</td>\n",
       "      <td>0.001099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>lstm</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>lstm</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softmax</td>\n",
       "      <td>1</td>\n",
       "      <td>22176</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softmax</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softplus</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softsign</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>23</td>\n",
       "      <td>0.001014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>lstm</td>\n",
       "      <td>softsign</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>lstm</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1</td>\n",
       "      <td>22680</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>lstm</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2</td>\n",
       "      <td>32760</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        nn_type activation_func  num_layers  model_params  largest_retained  capacity_ratio\n",
       "0    bidirelamn             elu           1         22680                42        0.001852\n",
       "1    bidirelamn             elu           2         32760                 8        0.000244\n",
       "2    bidirelamn    hard_sigmoid           1         22680                13        0.000573\n",
       "3    bidirelamn    hard_sigmoid           2         32760                10        0.000305\n",
       "4    bidirelamn          linear           1         22680                38        0.001675\n",
       "5    bidirelamn          linear           2         32760                 5        0.000153\n",
       "6    bidirelamn            relu           1         22680                47        0.002072\n",
       "7    bidirelamn            relu           2         25200                26        0.001032\n",
       "8    bidirelamn            selu           1         22680                12        0.000529\n",
       "9    bidirelamn            selu           2         32760                 5        0.000153\n",
       "10   bidirelamn         sigmoid           1         22680                10        0.000441\n",
       "11   bidirelamn         sigmoid           2         32760                 6        0.000183\n",
       "12   bidirelamn         softmax           1         22680                 9        0.000397\n",
       "13   bidirelamn         softmax           2         32760                 5        0.000153\n",
       "14   bidirelamn        softplus           1         22680                11        0.000485\n",
       "15   bidirelamn        softplus           2         32760                 6        0.000183\n",
       "16   bidirelamn        softsign           1         22680                36        0.001587\n",
       "17   bidirelamn        softsign           2         32760                 7        0.000214\n",
       "18   bidirelamn            tanh           1         22680                30        0.001323\n",
       "19   bidirelamn            tanh           2         32760                 5        0.000153\n",
       "20     bidirgru             elu           1         22680                26        0.001146\n",
       "21     bidirgru             elu           2         25200                13        0.000516\n",
       "22     bidirgru    hard_sigmoid           1         22680                23        0.001014\n",
       "23     bidirgru    hard_sigmoid           2         25200                 4        0.000159\n",
       "24     bidirgru          linear           1         22680                24        0.001058\n",
       "25     bidirgru          linear           2         25200                16        0.000635\n",
       "26     bidirgru            relu           1         22680                29        0.001279\n",
       "27     bidirgru            relu           2         25200                21        0.000833\n",
       "28     bidirgru            selu           1         22680                34        0.001499\n",
       "29     bidirgru            selu           2         25200                29        0.001151\n",
       "30     bidirgru         sigmoid           1         22680                18        0.000794\n",
       "31     bidirgru         sigmoid           2         25200                 5        0.000198\n",
       "32     bidirgru         softmax           1         22680                 9        0.000397\n",
       "33     bidirgru         softmax           2         25200                 4        0.000159\n",
       "34     bidirgru        softplus           1         22680                19        0.000838\n",
       "35     bidirgru        softplus           2         25200                 8        0.000317\n",
       "36     bidirgru        softsign           1         22680                34        0.001499\n",
       "37     bidirgru        softsign           2         25200                22        0.000873\n",
       "38     bidirgru            tanh           1         22680                27        0.001190\n",
       "39     bidirgru            tanh           2         25200                22        0.000873\n",
       "40    bidirlstm             elu           1         22680                33        0.001455\n",
       "41    bidirlstm             elu           2         32760                16        0.000488\n",
       "42    bidirlstm    hard_sigmoid           1         22680                11        0.000485\n",
       "43    bidirlstm    hard_sigmoid           2         30744                 5        0.000163\n",
       "44    bidirlstm          linear           1         22680                28        0.001235\n",
       "45    bidirlstm          linear           2         25200                21        0.000833\n",
       "46    bidirlstm            relu           1         22680                29        0.001279\n",
       "47    bidirlstm            relu           2         25200                12        0.000476\n",
       "48    bidirlstm            selu           1         22680                55        0.002425\n",
       "49    bidirlstm            selu           2         32760                54        0.001648\n",
       "50    bidirlstm         sigmoid           1         22680                14        0.000617\n",
       "51    bidirlstm         sigmoid           2         25200                 5        0.000198\n",
       "52    bidirlstm         softmax           1         22680                 9        0.000397\n",
       "53    bidirlstm         softmax           2         32760                 5        0.000153\n",
       "54    bidirlstm        softplus           1         22680                10        0.000441\n",
       "55    bidirlstm        softplus           2         25200                 4        0.000159\n",
       "56    bidirlstm        softsign           1         22680                42        0.001852\n",
       "57    bidirlstm        softsign           2         25200                32        0.001270\n",
       "58    bidirlstm            tanh           1         22680                29        0.001279\n",
       "59    bidirlstm            tanh           2         25200                16        0.000635\n",
       "60        elman             elu           1         22680                30        0.001323\n",
       "61        elman             elu           2         32760                 6        0.000183\n",
       "62        elman    hard_sigmoid           1         22680                11        0.000485\n",
       "63        elman    hard_sigmoid           2         32760                 6        0.000183\n",
       "64        elman          linear           1         22680                29        0.001279\n",
       "65        elman          linear           2         32760                 5        0.000153\n",
       "66        elman            relu           1         22680                34        0.001499\n",
       "67        elman            relu           2         32760                 6        0.000183\n",
       "68        elman            selu           1         22680                11        0.000485\n",
       "69        elman            selu           2         32760                 6        0.000183\n",
       "70        elman         sigmoid           1         22680                13        0.000573\n",
       "71        elman         sigmoid           2         32760                 8        0.000244\n",
       "72        elman         softmax           1         22680                 9        0.000397\n",
       "73        elman         softmax           2         32760                 5        0.000153\n",
       "74        elman        softplus           1         22680                 9        0.000397\n",
       "75        elman        softplus           2         32760                 5        0.000153\n",
       "76        elman        softsign           1         22680                20        0.000882\n",
       "77        elman        softsign           2         32760                 5        0.000153\n",
       "78        elman            tanh           1         22680                23        0.001014\n",
       "79        elman            tanh           2         32760                 6        0.000183\n",
       "80          gru             elu           1         22680                15        0.000661\n",
       "81          gru             elu           2         32760                13        0.000397\n",
       "82          gru    hard_sigmoid           1         22680                14        0.000617\n",
       "83          gru    hard_sigmoid           2         32760                 6        0.000183\n",
       "84          gru          linear           1         22680                19        0.000838\n",
       "85          gru          linear           2         32760                 7        0.000214\n",
       "86          gru            relu           1         22680                29        0.001279\n",
       "87          gru            relu           2         32760                 9        0.000275\n",
       "88          gru            selu           1         22680                14        0.000617\n",
       "89          gru            selu           2         32760                14        0.000427\n",
       "90          gru         sigmoid           1         22680                12        0.000529\n",
       "91          gru         sigmoid           2         32760                 7        0.000214\n",
       "92          gru         softmax           1         22680                10        0.000441\n",
       "93          gru         softmax           2         32760                 5        0.000153\n",
       "94          gru        softplus           1         22680                11        0.000485\n",
       "95          gru        softplus           2         32760                 5        0.000153\n",
       "96          gru        softsign           1         22680                20        0.000882\n",
       "97          gru        softsign           2         32760                11        0.000336\n",
       "98          gru            tanh           1         22680                11        0.000485\n",
       "99          gru            tanh           2         32760                 5        0.000153\n",
       "100        lstm             elu           1         22680                18        0.000794\n",
       "101        lstm             elu           2         32760                 7        0.000214\n",
       "102        lstm    hard_sigmoid           1         22680                12        0.000529\n",
       "103        lstm    hard_sigmoid           2         32760                 5        0.000153\n",
       "104        lstm          linear           1         22680                14        0.000617\n",
       "105        lstm          linear           2         32760                10        0.000305\n",
       "106        lstm            relu           1         22680                24        0.001058\n",
       "107        lstm            relu           2         32760                 7        0.000214\n",
       "108        lstm            selu           1         22680                46        0.002028\n",
       "109        lstm            selu           2         32760                36        0.001099\n",
       "110        lstm         sigmoid           1         22680                11        0.000485\n",
       "111        lstm         sigmoid           2         32760                 5        0.000153\n",
       "112        lstm         softmax           1         22176                 8        0.000361\n",
       "113        lstm         softmax           2         32760                 5        0.000153\n",
       "114        lstm        softplus           1         22680                 9        0.000397\n",
       "115        lstm        softplus           2         32760                 5        0.000153\n",
       "116        lstm        softsign           1         22680                23        0.001014\n",
       "117        lstm        softsign           2         32760                15        0.000458\n",
       "118        lstm            tanh           1         22680                16        0.000705\n",
       "119        lstm            tanh           2         32760                12        0.000366"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cap = df.groupby([\"nn_type\", \"activation_func\", \"num_layers\"]).agg({\"model_params\" : \"sum\", \"largest_retained\": \"sum\"})\n",
    "df_cap = pd.DataFrame(df_cap.to_records())\n",
    "df_cap[\"capacity_ratio\"] = df_cap[\"largest_retained\"]/df_cap[\"model_params\"]\n",
    "# df_cap = df_cap.pivot(index=\"activation_func\", columns=\"nn_type\", values=\"capacity_ratio\")\n",
    "df_cap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>nn_type</th>\n",
       "      <th>bidirelamn</th>\n",
       "      <th>bidirgru</th>\n",
       "      <th>bidirlstm</th>\n",
       "      <th>elman</th>\n",
       "      <th>gru</th>\n",
       "      <th>lstm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activation_func</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>elu</th>\n",
       "      <td>0.001852</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.000794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard_sigmoid</th>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.000529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>0.001675</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.000617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>0.002072</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>0.001499</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>0.001058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selu</th>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.001499</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.002028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigmoid</th>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.000485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>softmax</th>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.000361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>softplus</th>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.000397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>softsign</th>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.001499</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>0.001014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tanh</th>\n",
       "      <td>0.001323</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.000705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "nn_type          bidirelamn  bidirgru  bidirlstm     elman       gru      lstm\n",
       "activation_func                                                               \n",
       "elu                0.001852  0.001146   0.001455  0.001323  0.000661  0.000794\n",
       "hard_sigmoid       0.000573  0.001014   0.000485  0.000485  0.000617  0.000529\n",
       "linear             0.001675  0.001058   0.001235  0.001279  0.000838  0.000617\n",
       "relu               0.002072  0.001279   0.001279  0.001499  0.001279  0.001058\n",
       "selu               0.000529  0.001499   0.002425  0.000485  0.000617  0.002028\n",
       "sigmoid            0.000441  0.000794   0.000617  0.000573  0.000529  0.000485\n",
       "softmax            0.000397  0.000397   0.000397  0.000397  0.000441  0.000361\n",
       "softplus           0.000485  0.000838   0.000441  0.000397  0.000485  0.000397\n",
       "softsign           0.001587  0.001499   0.001852  0.000882  0.000882  0.001014\n",
       "tanh               0.001323  0.001190   0.001279  0.001014  0.000485  0.000705"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cap[df_cap[\"num_layers\"] == 1].pivot(index=\"activation_func\", columns=\"nn_type\", values=\"capacity_ratio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>nn_type</th>\n",
       "      <th>bidirelamn</th>\n",
       "      <th>bidirgru</th>\n",
       "      <th>bidirlstm</th>\n",
       "      <th>elman</th>\n",
       "      <th>gru</th>\n",
       "      <th>lstm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activation_func</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>elu</th>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hard_sigmoid</th>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>0.001032</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selu</th>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.001648</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.001099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigmoid</th>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>softmax</th>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>softplus</th>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>softsign</th>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.000458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tanh</th>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "nn_type          bidirelamn  bidirgru  bidirlstm     elman       gru      lstm\n",
       "activation_func                                                               \n",
       "elu                0.000244  0.000516   0.000488  0.000183  0.000397  0.000214\n",
       "hard_sigmoid       0.000305  0.000159   0.000163  0.000183  0.000183  0.000153\n",
       "linear             0.000153  0.000635   0.000833  0.000153  0.000214  0.000305\n",
       "relu               0.001032  0.000833   0.000476  0.000183  0.000275  0.000214\n",
       "selu               0.000153  0.001151   0.001648  0.000183  0.000427  0.001099\n",
       "sigmoid            0.000183  0.000198   0.000198  0.000244  0.000214  0.000153\n",
       "softmax            0.000153  0.000159   0.000153  0.000153  0.000153  0.000153\n",
       "softplus           0.000183  0.000317   0.000159  0.000153  0.000153  0.000153\n",
       "softsign           0.000214  0.000873   0.001270  0.000153  0.000336  0.000458\n",
       "tanh               0.000153  0.000873   0.000635  0.000183  0.000153  0.000366"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cap[df_cap[\"num_layers\"] == 2].pivot(index=\"activation_func\", columns=\"nn_type\", values=\"capacity_ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T16:34:27.659614Z",
     "start_time": "2018-11-15T16:34:27.654860Z"
    }
   },
   "source": [
    "### Conclusion about capacity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
